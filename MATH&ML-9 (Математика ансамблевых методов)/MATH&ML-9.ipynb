{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Введение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Представьте, что вы выполняете важный проект по машинному обучению. Конечно, вы можете делать всё самостоятельно, но если вы дополнительно узнаете мнение коллег, попросите ментора проверить ваши расчёты, найдёте как можно больше информации по вашей теме, то точно получите наилучший результат, ведь вы учтёте не только свои знания и выводы, но и информацию от других компетентных людей.\n",
    "\n",
    "Составление прогнозов в машинном обучении может следовать такой же логике: один алгоритм часто даёт далёкий от желаемой точности прогноз, ведь у каждого метода есть свои ограничения, и в целом создание модели, которая строит очень близкие к реальности предсказания, — достаточно сложная задача. Однако если мы обучим на наших данных несколько моделей и обобщим результаты определённым образом, то сможем получить куда более точный результат.\n",
    "\n",
    "Такой алгоритм решения задач машинного обучения называется **ансамблем моделей**.\n",
    "\n",
    "**Ансамбль моделей** — это метод, в котором несколько алгоритмов (или вариации одного и того же) обучаются на одних данных, а итоговый прогноз строится на основе всех полученных от моделей прогнозов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_1_1.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы уже встречались с ансамблями, однако последние модули существенно обогатили ваши знания по математике, и теперь вы сможете изучить математическую основу и тонкости данных методов: особенности настройки параметров, различные библиотеки, нюансы применения тех или иных ансамблей. Это сделает вас более компетентными специалистами, глубоко понимающими суть применяемых методов.\n",
    "\n",
    "Чтобы дальнейшее знакомство с ансамблями прошло успешно, давайте повторим ряд понятий из предыдущих модулей. Необходимо вспомнить как математические термины, так и основы машинного обучения, с которыми вы уже сталкивались: это облегчит вам изучение данного модуля. Если вы не очень хорошо помните некоторые из тем, затрагиваемые в заданиях, рекомендуем вам вернуться к соответствующим модулям и освежить знания."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Вы справились с тестированием — поздравляем! Теперь вы точно можете быть уверены, что ваша подготовка достаточна для освоения данного модуля. Прежде чем приступить, давайте обозначим основные цели на следующие семь юнитов:\n",
    "\n",
    "- Изучить основную терминологию, связанную с ансамблями моделей.\n",
    "Мы повторим уже знакомые вам основные понятия, которые используются в ансамблях, и познакомимся с рядом новых.\n",
    "- Подробно разобрать реализацию разных видов ансамблей с математической и смысловой точек зрения.\n",
    "Мы намного подробнее, чем раньше, разберём все алгоритмы и изучим их математическую составляющую, чтобы лучше понимать принцип их работы, уметь более тонко их настраивать и за счёт этого добиваться наилучшей эффективности.\n",
    "- Научиться решать задачи регрессии и классификации с использованием ансамблей моделей.\n",
    "Конечно же, полученные знания мы будем использовать для решения настоящих практических задач.\n",
    "- Научиться настраивать параметры моделей для повышения прогностической точности. Мы рассмотрим параметры алгоритмов, которые можно регулировать, и разберёмся, как менять каждый из них для повышения точности предсказания.\n",
    "\n",
    "Важно обозначить, что мы будем рассматривать три вида построения ансамблей: бэггинг, бустинг и стекинг. Для каждого из них мы изучим популярные вариации, программную реализацию и, конечно же, сравним их эффективность при решении задач.\n",
    "\n",
    "В результате освоения этого модуля вы сможете применять ансамблевые методы для решения задач машинного обучения. Вы не просто будете знать плюсы и минусы ансамблевых методов и то, какие из них уместны в том или ином случае, но также будете понимать их суть и математическую составляющую.\n",
    "\n",
    "Итак, вперёд к ансамблям! →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ансамбли моделей. Бутстреппинг. Бэггинг"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В этом юните вы углубите свои знания ансамблей алгоритмов. Вы познакомитесь с тем, как формируются бутстреп-выборки, а также досконально изучите принцип **бэггинга** — самого простого варианта ансамблей.\n",
    "\n",
    "В основе бэггинга лежит статистический метод, который называется **бутстрепом (bootstrap)**. Идея бутстрепа заключается в генерации выборок размера $n$ из исходного датасета размера $N$ путём случайного выбора элементов с повторениями в каждом из наблюдений."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рассмотрим идею бутстрепа на элементарном примере**.\n",
    "\n",
    "Пусть у нас есть выборка из 12 клиентов компании: у каждого из них есть свой ID (от 1 до 12) и какие-то характеристики. Мы можем создавать из данной выборки множество различных новых выборок клиентов с новым количеством человек (в данном случае представлены выборки из пяти человек). При этом информацию про одного и того же клиента можно использовать повторно."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_2_1.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это намного проще, чем находить новые выборки. По сути, мы собираем данные лишь единожды, а затем на их основе генерируем много выборок для обучения моделей. Это экономит огромные объёмы ресурсов и времени.\n",
    "\n",
    "При некотором приближении можно считать, что получающиеся выборки являются независимыми и репрезентативными — **это важное допущение**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборки можно назвать **независимыми**, если результаты испытаний и измерения, осуществляемые для одной выборки, никак не влияют на результаты, получаемые на другой выборке."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Репрезентативность** заключается в соответствии характеристик выборки всей генеральной совокупности.\n",
    "\n",
    "К примеру, если мы хотим исследовать мнение всех женщин России по какому-то вопросу, то все женщины России — это **генеральная совокупность**.\n",
    "\n",
    "**Репрезентативная выборка** — это такая группа женщин, для которой основные характеристики соответствуют характеристикам для генеральной совокупности. Допустим, если среди всех российских женщин 60 % имеют детей, а 40 % — не имеют, то соотношение в выборке должно быть таким же."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бутстреп-выборки часто используются для оценки различных статистических показателей, например разброса или доверительного интервала.\n",
    "\n",
    "Если вычислять статистические оценки на нескольких независимых выборках, то мы можем, например, оценить их математическое ожидание или разброс. Приведём пример того, как это происходит с точки зрения математики.\n",
    "\n",
    "Допустим, у нас есть некоторая выборка $x=(5,1,3,6,4)$, и мы хотим оценить для неё математическое ожидание. Например, это может быть выборка количества товаров, которые приобретали покупатели нашего магазина, и мы хотим найти ожидаемое количество товаров, которое купит случайный клиент.\n",
    "\n",
    "Конечно, мы без проблем можем его вычислить:\n",
    "\n",
    "$E(x) =E(5,1,3,6,4) = \\frac{1}{5} \\cdot 5 + \\frac{1}{5} \\cdot1 + \\frac{1}{5} \\cdot3 + \\frac{1}{5} \\cdot6 + \\frac{1}{5} \\cdot4 = 1+0.2 +0.6 + 1.2 + 0.8 = 3.8$\n",
    "\n",
    "Однако это значение лишь на одной выборке, а мы хотели бы вычислить эту статистическую оценку на нескольких выборках и затем проанализировать разброс оценок.\n",
    "\n",
    "Создаём несколько выборок с помощью бутстрепа и на каждой оцениваем математическое ожидание:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_2_2.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили ряд значений:  \n",
    "4.4, 3.8, 4.8, 4.0, 3.4, 4.2, 5.2  \n",
    "Теперь давайте найдём дисперсию для этого ряда. Мы с вами делали это в модуле по теории вероятностей — самое время вспомнить!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.2**\n",
    "\n",
    "Вычислите дисперсию для этого ряда. Результат округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31673469387755115"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from scipy.stats import randint\n",
    "# from statistics import variance, pvariance\n",
    "x=[4.4, 3.8, 4.8, 4.0, 3.4, 4.2, 5.2]\n",
    "np.var(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы понимаем, что если мы будем создавать различные новые выборки и вычислять для них средние значения, то для полученных значений дисперсия будет равна найденному вами выше значению. **Заметьте: мы узнали это, не собирая никаких новых данных**.\n",
    "\n",
    "Формализуем только что проделанные действия математически:\n",
    "\n",
    "Генерируем выборки. Необходимо создавать упорядоченные множества элементов, которые мы выбираем с возвратом из некоторого имеющегося у нас множества:\n",
    "\n",
    "$\\left\\{X_{1}, \\ldots, X_{N}\\right\\}$\n",
    "\n",
    "Повторяем несколько раз процедуру генерации выборки:\n",
    "\n",
    "$X_{b}^{*}=\\left(X_{b 1}^{*}, \\ldots, X_{b N}^{*}\\right), \\ где \\ 1 \\leqslant b \\leqslant B$\n",
    "\n",
    "Считаем интересующую нас статистику по каждой выборке:\n",
    "\n",
    "$T_{1}^{*}=T\\left(X_{1}^{*}\\right), \\ldots, T_{B}^{*}=T\\left(X_{B}^{*}\\right)$\n",
    "\n",
    "Получаем бутстрепную оценку для интересующей нас статистики по этой выборке статистик. Например, для дисперсии она будет вычисляться так:\n",
    "\n",
    "$ \\widehat {D}_{\\text {boot }}=\\frac{1}{B} \\sum_{b=1}^{B} T_{b}^{* 2}-\\left(\\frac{1}{B} \\sum_{b=1}^{B} T_{b}^{*}\\right)^{2}$\n",
    "\n",
    "Отлично, мы разобрались с тем, что такое метод бутстрепа. Запомните его идею — совсем скоро она пригодится вам для понимания алгоритма бэггинга."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы понимаем, что если мы будем создавать различные новые выборки и вычислять для них средние значения, то для полученных значений дисперсия будет равна найденному вами выше значению. Заметьте: мы узнали это, не собирая никаких новых данных.\n",
    "\n",
    "Формализуем только что проделанные действия математически:\n",
    "\n",
    "Генерируем выборки. Необходимо создавать упорядоченные множества элементов, которые мы выбираем с возвратом из некоторого имеющегося у нас множества:\n",
    "\n",
    "$\\left\\{X_{1}, \\ldots, X_{N}\\right\\}$\n",
    "\n",
    "Повторяем несколько раз процедуру генерации выборки:\n",
    "\n",
    "$X_{b}^{*}=\\left(X_{b 1}^{*}, \\ldots, X_{b N}^{*}\\right), \\ где \\ 1 \\leqslant b \\leqslant B$\n",
    "\n",
    "Считаем интересующую нас статистику по каждой выборке:\n",
    "\n",
    "$T_{1}^{*}=T\\left(X_{1}^{*}\\right), \\ldots, T_{B}^{*}=T\\left(X_{B}^{*}\\right)$\n",
    "\n",
    "Получаем бутстрепную оценку для интересующей нас статистики по этой выборке статистик. Например, для дисперсии она будет вычисляться так:\n",
    "\n",
    "$\\widehat{D}_{\\text {boot }}=\\frac{1}{B} \\sum_{b=1}^{B} T_{b}^{* 2}-\\left(\\frac{1}{B} \\sum_{b=1}^{B} T_{b}^{*}\\right)^{2}$\n",
    "\n",
    "Отлично, мы разобрались с тем, что такое метод бутстрепа. Запомните его идею — совсем скоро она пригодится вам для понимания алгоритма бэггинга."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIAS И VARIANCE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем перейти непосредственно к ансамблям моделей, нам необходимо повторить bias-variance decomposition, или, как его называют по-русски, «разложение ошибки на смещение и разброс». Оно очень полезно для анализа ансамблей моделей.\n",
    "\n",
    "**Смещение** — это разница между математическим ожиданием для прогноза и реальным значением:\n",
    "\n",
    "$Bias[\\hat{f}(x)] = E[\\hat{f}(x)]-y$\n",
    "\n",
    "Здесь:\n",
    "\n",
    "$E[\\hat{f}(x)]$ — математическое ожидание для прогноза,\n",
    "\n",
    "$y$ — реальное значение функции.\n",
    "\n",
    "**Смысл смещения** — способность получить лучшую среди всех возможных моделей, то есть максимально точные прогнозы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-1.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также значение смещения часто называют **ошибкой смещения** или **ошибкой из-за смещения**.\n",
    "\n",
    "Если у модели большое смещение, это значит, что ошибка будет достаточно велика из-за слишком сильного упрощения модели.\n",
    "\n",
    "**Разброс** — это величина разницы в результатах обучения модели на разных выборках:\n",
    "\n",
    "$\\operatorname{Var}[\\hat{f}(x)]=\\mathrm{E}\\left[\\left(\\mathrm{E}[\\hat{f}(x)]-\\hat{f}(x)\\right)^{2}\\right]$\n",
    "\n",
    "**Примечание**. С математической точки зрения разброс модели определяется как математическое ожидание квадрата разницы ожидаемого прогноза и реализованного прогноза модели.\n",
    "\n",
    "Разброс характеризует устойчивость модели к изменениям в обучающей выборке:\n",
    "\n",
    "- Если результат сильно зависит от того, какие объекты присутствуют в выборке, разброс будет большим.\n",
    "- Если алгоритм работает стабильно вне зависимости от особенностей выборки, разброс будет маленьким."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-2.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте рассмотрим разложение на смещение и разброс для линейной регрессии.\n",
    "\n",
    "Пусть мы хотим предсказать значение $y$ по значениям вектора $x$. Тогда зависимость $y$ от $x$ можно записать следующим образом:\n",
    "\n",
    "$y=f(x)+\\varepsilon$\n",
    "\n",
    "В качестве $f(x)$ здесь выступает истинная зависимость ответов $y$ от характеристик объекта $x$ — мы её не знаем и пытаемся предсказать с помощью модели. Предсказания обозначим как $\\hat{f}(x)$. Символом $\\varepsilon$ обозначается случайная ошибка. Предполагается, что её математическое ожидание равно нулю — это просто шум.\n",
    "\n",
    "Тогда давайте выразим ошибку для какого-то значения х. Она будет равняться математическому ожиданию для квадрата разницы между реальным и предсказанным значениями. По сути, это просто среднеквадратичная ошибка, записанная в немного иной форме:\n",
    "\n",
    "$\\operatorname{Err}(x)=E\\left[(y-\\hat{f}(x))^{2}\\right]$\n",
    "\n",
    "Также мы можем разложить среднеквадратичную ошибку следующим образом:\n",
    "\n",
    "$\\operatorname{Err}(x)=(E[\\hat{f}(x)]-y)^{2}+E\\left[(\\hat{f}(x)-E[\\hat{f}(x)])^{2}\\right]+\\sigma_{\\varepsilon}^{2}$  \n",
    "$\\operatorname{Err}(x)=\\operatorname{Bias}^{2}+Variance+Irreducible Error$\n",
    "\n",
    "**Доказательство равенства**\n",
    "\n",
    "Для начала представим y как сумму значения функции $f$ и ошибки (вместо $f(x)$ будем далее для краткости писать просто $f$):\n",
    "\n",
    "$\\mathrm{E}\\left[(y-\\hat{f})^{2}\\right]=\\mathrm{E}\\left[(f+\\varepsilon-\\hat{f})^{2}\\right]$\n",
    "\n",
    "Теперь в выражение, от которого мы ищем математическое ожидание, добавим математическое ожидание предсказанной функции и вычтем его же (это нужно для того, чтобы далее мы смогли выразить необходимые нам величины). Разумеется, если мы прибавляем какую-то величину, а потом её вычитаем, результат остаётся тем же.\n",
    "\n",
    "$=\\mathrm{E}\\left[(f+\\varepsilon-\\hat{f}+\\mathrm{E}[\\hat{f}]-\\mathrm{E}[\\hat{f}])^{2}\\right]$\n",
    "\n",
    "Далее раскроем скобки, то есть возведём в квадрат сумму трёх слагаемых:\n",
    "\n",
    "$f-\\mathrm{E}[\\hat{f}]$,\n",
    "\n",
    "$\\varepsilon$,\n",
    "\n",
    "$\\mathrm{E}[\\hat{f}]-\\hat{f}$.\n",
    "\n",
    "**Примечание**. Для разложения пользуемся формулой из алгебры:\n",
    "\n",
    "$(a+b+c)^{2}=a^{2}+b^{2}+c^{2}+2 a b+2 a c+2 b c$\n",
    "\n",
    "Получаем:\n",
    "\n",
    "$=\\mathrm{E}\\left[(f-\\mathrm{E}[\\hat{f}])^{2}\\right]+\\mathrm{E}\\left[\\varepsilon^{2}\\right]+\\mathrm{E}\\left[(\\mathrm{E}[\\hat{f}]-\\hat{f})^{2}\\right]+2 \\mathrm{E}[(f-\\mathrm{E}[\\hat{f}]) \\varepsilon]+2 \\mathrm{E}[\\varepsilon(\\mathrm{E}[\\hat{f}]-\\hat{f})]+2 \\mathrm{E}[(\\mathrm{E}[\\hat{f}]-\\hat{f})(f-\\mathrm{E}[\\hat{f}])]\n",
    "=(f-\\mathrm{E}[\\hat{f}])^{2}+\\mathrm{E}\\left[\\varepsilon^{2}\\right]+\\mathrm{E}\\left[(\\mathrm{E}[\\hat{f}]-\\hat{f})^{2}\\right]+2(f-\\mathrm{E}[\\hat{f}]) \\mathrm{E}[\\varepsilon]+2 \\mathrm{E}[\\varepsilon] \\mathrm{E}[\\mathrm{E}[\\hat{f}]-\\hat{f}]+2 \\mathrm{E}[\\mathrm{E}[\\hat{f}]-\\hat{f}](f-\\mathrm{E}[\\hat{f}])$\n",
    "\n",
    "Сокращаем одинаковые слагаемые:\n",
    "\n",
    "$=(f-\\mathrm{E}[\\hat{f}])^{2}+\\mathrm{E}\\left[\\varepsilon^{2}\\right]+\\mathrm{E}\\left[(\\mathrm{E}[\\hat{f}]-\\hat{f})^{2}\\right]$\n",
    "\n",
    "Видим, что у нас есть дисперсия ошибки и дисперсия предсказания:\n",
    "\n",
    "$=(f-\\mathrm{E}[\\hat{f}])^{2}+\\operatorname{Var}[\\varepsilon]+\\operatorname{Var}[\\hat{f}]$  \n",
    "$=\\operatorname{Bias}[\\hat{f}]^{2}+\\sigma^{2}+\\operatorname{Var}[\\hat{f}]$\n",
    "\n",
    "Итак, мы получили, что наша ошибка — это сумма смещения для квадрата прогноза, разброса и неустранимой случайной ошибки. Теперь мы понимаем, из чего состоит ошибка модели. Такое представление помогает нам исследовать с теоретической точки зрения некоторые алгоритмы машинного обучения и часто используется при изучении ансамблей.\n",
    "\n",
    "Рассмотрим иллюстрацию того, как сдвиг и разброс влияют на качество предсказания. На рисунке ниже вы видите цель (красный круг), в которую мы хотим попасть.\n",
    "\n",
    "Есть четыре ситуации:\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-3.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В моделях машинного обучения принцип тот же, только в качестве центра мишени выступает минимально возможная ошибка.\n",
    "\n",
    "Когда говорят про разложение на bias и variance, то часто упоминают некую точку баланса:\n",
    "\n",
    "- Если модель очень простая, с маленьким количеством параметров, то, скорее всего, у неё будет очень большое смещение, но маленький разброс.\n",
    "- Если модель очень сложная, со множеством параметров, у неё будет большой разброс и маленькое смещение.\n",
    "\n",
    "Схематично эти зависимости можно изобразить следующим образом (это схема не для конкретной модели, а лишь иллюстрация тенденций):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_2_4.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На графике выше по оси абсцисс отложена сложность модели (Model Complexity), а по оси ординат — ошибка (Error). Также изображены смещение ($Bias^2$), разброс ($Variance$) и ошибка ($Total Error$ — сумма смещения и разброса).\n",
    "\n",
    "Как вы можете видеть, есть некоторая оптимальная точка, в которой разброс и смещение небольшие, а ошибка минимальна. Именно эта точка нас и интересует."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### БЭГГИНГ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдём к понятию **бэггинг**.\n",
    "\n",
    "При построении моделей всегда есть вероятность, что при обучении на других данных получились бы другие результаты. Для того чтобы нивелировать такую вероятность, можно использовать бэггинг.\n",
    "\n",
    "Его идея состоит в том, что мы берём несколько независимых моделей и усредняем полученные по ним результаты. Таким образом мы получаем модель, имеющую меньший разброс, так как при её построении мы учли несколько моделей.\n",
    "\n",
    "Как уже было сказано, в реальности получить много независимых выборок слишком сложно, так как найти столько данных обычно невозможно. Поэтому мы используем бутстреп-выборки, о которых говорили в начале юнита.\n",
    "\n",
    "Важно отметить, что при бэггинге размер каждой бутстреп-выборки должен совпадать с размером исходной выборки.\n",
    "\n",
    "Схематично процесс бэггинга можно представить следующим образом:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_2_6.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте сформулируем и объясним эту идею математически.\n",
    "\n",
    "Пусть у нас есть некоторая выборка, и мы с помощью бутстрепа генерируем из неё ещё $B$ выборок:\n",
    "\n",
    "$X_{1}, ..., X_{B}$\n",
    "\n",
    "После этого мы определяем много базовых алгоритмов (всего $B$ моделей — по числу выборок) и обучаем каждый базовый алгоритм $a_{i}(x)$ на своей выборке. После этого получаем итоговый результат:\n",
    "\n",
    "$a(x)=\\frac{1}{B} \\sum_{i=1}^{B} a_{i}(x)$\n",
    "\n",
    "Если мы рассматриваем задачу **классификации**, то, по сути, модели «голосуют» за свой класс.\n",
    "Если мы рассматриваем задачу **регрессии**, то результат — просто среднее арифметическое прогнозов по всем моделям.\n",
    "Теперь посмотрим, **насколько применение бэггинга поможет нам улучшить качество модели**.\n",
    "\n",
    "Представим, что мы хотим использовать бэггинг для решения задачи регрессии и берём для этого K базовых алгоритмов:\n",
    "\n",
    "$a_{1}(x), ..., a_{K}(x)$\n",
    "\n",
    "Конечно, если для каждого объекта известно значение целевой переменной, мы можем вычислить ошибку для каждой модели:\n",
    "\n",
    "$\\varepsilon_{i}(x)=a_{i}(x)-y(x), i=1, \\ldots, K$\n",
    "\n",
    "Также мы можем выразить математическое ожидание квадратичной ошибки (т. е., по сути, среднеквадратичную ошибку):\n",
    "\n",
    "$\\mathbb{E}_{x}\\left[\\left(a_{i}(x)-y(x)\\right)^{2}\\right]=\\mathbb{E}_{x}\\left[\\varepsilon_{i}^{2}(x)\\right]$\n",
    "\n",
    "Ошибка здесь обозначается как $\\varepsilon_{i}(x)$.\n",
    "\n",
    "Тогда, если мы усредним значение ошибки по всем моделям регрессии, то получим следующее:\n",
    "\n",
    "$\\mathbb{E}_{1}=\\frac{1}{n} \\mathbb{E}_{x} \\sum_{i=1}^{n} \\varepsilon_{i}^{2}(x)$\n",
    "\n",
    "Будем считать, что математическое ожидание для всех ошибок равно нулю (то есть нет какого-то систематического смещения ошибок, и они случайные) и что все ошибки независимы друг от друга (то есть их коэффициент корреляции равен нулю):\n",
    "\n",
    "$\\begin{aligned} \\mathbb{E}_{x} \\varepsilon_{i}(x) &=0 \\\\ \\mathbb{E}_{x} \\varepsilon_{i}(x) \\varepsilon_{j}(x) &=0, i \\neq j \\end{aligned}$\n",
    "\n",
    "Теперь определим регрессионную функцию, которая будет брать ответы от всех обученных нами регрессионных моделей и просто усреднять их:\n",
    "\n",
    "$f(x)=\\frac{1}{K} \\sum_{i=1}^{K} a_{i}(x)$\n",
    "\n",
    "Теперь найдём для этой модели среднеквадратичную ошибку. Выразим её через математическое ожидание:\n",
    "\n",
    "$\\mathbb{E}_{K}=\\mathbb{E}_{x}\\left(\\frac{1}{K} \\sum_{i=1}^{K} a_{i}(x)-y(x)\\right)^{2}$\n",
    "\n",
    "Упростим часть внутри скобок, воспользовавшись введённым ранее утверждением о том, что $\\mathbb{E}_{x}\\left[\\left(a_{i}(x)-y(x)\\right)^{2}\\right]=\\mathbb{E}_{x}\\left[\\varepsilon_{i}^{2}(x)\\right]$, и получим следующее:\n",
    "\n",
    "$\\mathbb{E}_{x}\\left[\\left(a_{i}(x)-y(x)\\right)^{2}\\right]=\\mathbb{E}_{x}\\left[\\varepsilon_{i}^{2}(x)\\right]\n",
    "=\\mathbb{E}_{x}\\left(\\frac{1}{K} \\sum_{i=1}^{K} \\varepsilon_{i}\\right)^{2}$\n",
    "\n",
    "После этого вынесем за скобку $\\frac{1}{K}$, а также возведём внутреннюю часть скобки в квадрат:\n",
    "\n",
    "$=\\frac{1}{K^{2}} \\mathbb{E}_{x}\\left(\\sum_{i=1}^{K} \\varepsilon_{i}^{2}(x)+\\sum_{i \\neq j} \\varepsilon_{i}(x) \\varepsilon_{j}(x)\\right)$\n",
    "\n",
    "Ранее мы уже выяснили, что $\\sum_{i \\neq j} \\varepsilon_{i}(x) \\varepsilon_{j}(x)$ равняется нулю, так как все ошибки независимы. Сокращаем выражение и получаем в итоге:\n",
    "\n",
    "$\\mathbb{E}_{K}=\\frac{1}{K}\\mathbb{E}_{1}$\n",
    "\n",
    "Получается, что путём усреднения предсказаний линейных регрессий мы смогли уменьшить среднеквадратичную ошибку в K раз.\n",
    "\n",
    "Однако тут важно отметить, что при решении прикладных задач эффект будет не таким выраженным, так как здесь мы использовали предположение о полной независимости ошибок, а в реальной жизни такое случается редко.\n",
    "\n",
    "Также, чтобы иметь полное представление о характеристиках рассматриваемого алгоритма, давайте вспомним про разложение ошибки на смещение и разброс.\n",
    "\n",
    "Доказано, что бэггинг не ухудшает показатель смещения модели, то есть смещение у ансамбля ровно такое же, как и у одного базового алгоритма."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Доказательство**  \n",
    "Выберем из нашей выборки $X$ бутстрепом $K$ раз выборку длиной $N$. Получим выборки $X_{1}, X_{2}, ..., X_{K}$. Обучим базовые модели $a(x)$ на данных подвыборках. Первую модель $a_{1}(x) = a(x,X_{1})$  обучим на первой выборке бутстрепа, вторую $a_{2}(x) = a(x,X_{2})$ — на второй и так далее. Выполнив данную процедуру $n$ раз, мы получим предсказание как усреднение по всем обученным на подвыборках моделях.\n",
    "\n",
    "$f(x,X) = \\frac{1}{K} \\sum_{i=1}^{K} (f_i (x))$\n",
    "\n",
    "Теперь рассмотрим изменение смещения ($bias$) и разброса ($variance$) ансамблирования по отношению к базовым моделям.\n",
    "\n",
    "Смещение (bias) есть не что иное, как математическое ожидание разности между истинными ответами y и предсказаниями ансамбля: \n",
    "\n",
    "<img src=\"data\\dst-3-ml-8-51.png\" alt=\"drawing\" width=\"600\"/>  \n",
    "<img src=\"data\\dst-3-ml-8-52.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Вывод: смещение ансамбля равно смещению базовой модели ансамбля!\n",
    "\n",
    "Разброс (variance, обозначим далее как var) — это дисперсия ответов алгоритма:\n",
    "\n",
    "<img src=\"data\\dst-3-ml-8-53.png\" alt=\"drawing\" width=\"600\"/>  \n",
    "<img src=\"data\\dst-3-ml-8-54.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"data\\dst-3-ml-8-55.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "При условии некоррелированности базовых моделей, которая достигается за счёт обучения на бутстрепе, последнее слагаемое равно нулю. Итого:\n",
    "\n",
    "$var(f(x,X)) = \\frac{1}{K^2} \\sum_{i=1}^{K} E \\left [(a_i (x,X)- E \\left [a_i (x,X) \\right ] )\\right ]^2 = \\frac{1}{K^2} \\sum_{i=1}^{K} var(a(x, X_i))$\n",
    "\n",
    "Тогда, зная, что модели не коррелированы, получаем:\n",
    "\n",
    "<img src=\"data\\dst-3-ml-8-57.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Вывод: разброс ансамбля уменьшается в K раз по сравнению с разбросом базовой модели!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем случае разброс бэггинга будет выражаться следующим образом:\n",
    "\n",
    "$\\frac{1}{K}\\left(\\operatorname{Var} a_{n}(x)\\right)+\\operatorname{Cov}\\left(a_{n}(x), a_{m}(x)\\right)$\n",
    "\n",
    "В данном выражении через $a_{n}(x)$ обозначен один из базовых алгоритмов, а за $a_{m}(x)$ — другой базовый алгоритм.\n",
    "\n",
    "Из этого следует, что если модели (в данной формуле — базовые модели $a_{n}(x)$ и $a_{m}(x)$) независимы, то разброс для ансамбля типа бэггинг будет в K раз меньше, чем разброс у отдельной модели.\n",
    "\n",
    "**Резюмируем**:\n",
    "\n",
    "1. Бэггинг даёт уменьшение ошибки в K раз по сравнению с одиночной моделью.\n",
    "2. Бэггинг не уменьшает смещение по сравнению с одиночной моделью.\n",
    "3. Бэггинг уменьшает разброс в K раз по сравнению с одиночной моделью.  \n",
    "\n",
    "Важно отметить, что эти утверждения выведены и доказаны теоретически и будут выполняться на практике только в том случае, если между ошибками нулевая корреляция.\n",
    "\n",
    "Как видим, бэггинг — очень эффективный и полезный алгоритм, так что есть смысл попрактиковаться с ним."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.7**\n",
    "\n",
    "Объёмная и содержательная практика у нас ещё впереди, но в качестве разминки давайте поработаем с уже известным вам датасетом о вине, который можно скачать здесь https://lms.skillfactory.ru/assets/courseware/v1/805b5c231251e174abb4fdbbd391adc3/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/wineQualityReds.zip.\n",
    "\n",
    "Ранее вы обучали на данных только один алгоритм, а теперь мы попробуем сравнить несколько.\n",
    "\n",
    "- Подготовьте данные к классификации. Условно разделите вино на хорошее и плохое. Хорошим вином будем называть то, параметр quality которого — 6 и более.\n",
    "- Сравните несколько методов классификации: логистическую регрессию, дерево решений и бэггинг. Это позволит вам увидеть, как меняется качество в зависимости от выбора того или иного алгоритма.\n",
    "- Разделите выборку на обучающую и тестовую в соотношении 70/30, в качестве значения параметра random_state возьмите число 42.\n",
    "- Для начала обучите два классификатора: логистическую регрессию (с параметрами по умолчанию) и дерево решений (random_state = 42, максимальная глубина — 10).\n",
    "\n",
    "Введите значение F1-score для классификатора, который показал наилучшее значение. Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fixed.acidity  volatile.acidity  citric.acid  residual.sugar  \\\n",
       "0           1            7.4              0.70         0.00             1.9   \n",
       "1           2            7.8              0.88         0.00             2.6   \n",
       "2           3            7.8              0.76         0.04             2.3   \n",
       "3           4           11.2              0.28         0.56             1.9   \n",
       "4           5            7.4              0.70         0.00             1.9   \n",
       "\n",
       "   chlorides  free.sulfur.dioxide  total.sulfur.dioxide  density    pH  \\\n",
       "0      0.076                 11.0                  34.0   0.9978  3.51   \n",
       "1      0.098                 25.0                  67.0   0.9968  3.20   \n",
       "2      0.092                 15.0                  54.0   0.9970  3.26   \n",
       "3      0.075                 17.0                  60.0   0.9980  3.16   \n",
       "4      0.076                 11.0                  34.0   0.9978  3.51   \n",
       "\n",
       "   sulphates  alcohol  quality  \n",
       "0       0.56      9.4        5  \n",
       "1       0.68      9.8        5  \n",
       "2       0.65      9.8        5  \n",
       "3       0.58      9.8        6  \n",
       "4       0.56      9.4        5  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/wineQualityReds.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['best_mark'] = data.quality.apply(lambda x: 1 if (x > 5) else 0)\n",
    "X = data.drop(columns=['best_mark', 'quality', 'Unnamed: 0']) # обязательно удалаям quality т.к. по нему формировали best_mark (будет утечка), удаляем Unnamed т.к. это дубль индекса\n",
    "y = data['best_mark']\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed.acidity         1599 non-null   float64\n",
      " 1   volatile.acidity      1599 non-null   float64\n",
      " 2   citric.acid           1599 non-null   float64\n",
      " 3   residual.sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free.sulfur.dioxide   1599 non-null   float64\n",
      " 6   total.sulfur.dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 137.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "print(round(f1_score(y_test, y_pred_lr),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(random_state = 42, max_depth = 10).fit(X_train, y_train)\n",
    "y_pred_dtc = dtc.predict(X_test)\n",
    "\n",
    "print(round(f1_score(y_test, y_pred_dtc),3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.8**\n",
    "\n",
    "Обучите модель с использованием бэггинга (класс BaggingClassifier с random_state=42).\n",
    "\n",
    "Возьмите из предыдущего задания алгоритм, показавший наилучшее качество, и укажите для него новое количество моделей — 1500. Вычислите новое значение F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(DecisionTreeClassifier(max_depth=10, random_state = 42), \n",
    "                        n_estimators=1500, random_state = 42).fit(X_train, y_train)\n",
    "y_pred_clf =clf.predict(X_test)\n",
    "\n",
    "print(round(f1_score(y_test, y_pred_clf),3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Прекрасно! Теперь вы разбираетесь в алгоритме бэггинга и знаете, как формируются бутстреп-выборки, и готовы перейти к следующему юниту, где ваш ждёт один из видов бэггинга — случайный лес →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Случайный лес"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы поговорили о бэггинге — одном из видов ансамблей моделей. В этом юните мы будем разбирать модификацию бэггинга — **случайный лес**.\n",
    "\n",
    "Несмотря на то что вам уже известен данный алгоритм, рассмотрим совсем простой пример случайного леса для случая классификации, чтобы вспомнить логику реализации модели.\n",
    "\n",
    "Допустим, у нас есть набор данных с фруктами, для которого мы хотим решить задачу классификации. Известны цвет, диаметр, форма, время созревания и другие особенности каждого объекта.\n",
    "\n",
    "Наша задача состоит в том, чтобы построить модель классификации, которая в будущем сможет по характеристикам фрукта определять его вид."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_3_1.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим три решающих дерева, которые делают предсказания следующим образом:  \n",
    "<img src=\"data\\MATHML_md9_3_2.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Появляется новый фрукт, про который мы пока ничего не знаем, кроме его признаков:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_3_3.png\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш **случайный лес**, состоящий из трёх деревьев, будет классифицировать этот фрукт следующим образом:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_3_4.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что два дерева голосуют за то, что это апельсин, и одно дерево голосует за вишню. Тогда большинством голосов мы решаем, что это апельсин."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_3_5.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот и всё, мы решили задачу классификации с помощью случайного леса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_3_6.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть какое-то количество решающих деревьев, каждое из которых мы обучаем на некоторой подвыборке из данных. Получив вердикты от всех моделей, определяем итоговый результат для каждого объекта.\n",
    "\n",
    "**Для регрессии** правило формирования итогового результата формулируется следующим образом:\n",
    "\n",
    "$f(x)=\\frac{1}{K} \\sum_{i=1}^{K} a_{i}(x)$\n",
    "\n",
    "Здесь:\n",
    "\n",
    "$K$ — количество моделей,  \n",
    "$a_i(x)$ — алгоритм решающего дерева,  \n",
    "$f(x)$ — значение финального предсказания ансамбля. \n",
    "\n",
    "Это означает, что мы просто находим среднее арифметическое для всех полученных предсказаний.\n",
    "\n",
    "Правило формирования итогового результата **для классификации**:\n",
    "\n",
    "$f(x)=\\arg \\max _{y \\in \\mathbb{Y}} \\sum_{i=1}^{K}\\left[a_{i}(x)=y\\right]$\n",
    "\n",
    "Здесь деревья просто голосуют за некоторый класс, и объекту присваивается метка класса, за который было отдано наибольшее количество голосов.\n",
    "\n",
    "Давайте рассмотрим **алгоритм реализации случайного леса**.\n",
    "\n",
    "Одно из важных понятий, которое здесь появляется, — это **метод случайных подпространств**, который используется для построения ансамблей моделей.\n",
    "\n",
    "Кратко опишем его принцип:\n",
    "\n",
    "1. Отбираем обучающую выборку.\n",
    "2. Определяем число моделей, которые войдут в ансамбль.\n",
    "3. Для каждой модели берём не все признаки, а только часть из них и формируем выборку с использованием случайно выбранного набора признаков.\n",
    "4. Объединяем все результаты и определяем итоговое решение по объектам.\n",
    "\n",
    "**Обратите внимание на важную особенность**: здесь выбирается не только обучающая выборка, но ещё и случайная выборка из признаков.\n",
    "\n",
    "**Алгоритм случайного леса** в таком контексте реализуется следующим образом:\n",
    "\n",
    "1. Для того чтобы построить $i$-е дерево леса, из обучающей выборки $X$ берём случайную подвыборку $X_{i}$ того же размера, что и вся обучающая выборка.\n",
    "2. После этого в каждой вершине каждого дерева из $M$ возможных признаков выбираем случайную группу признаков объёма $L$. Для выбранных признаков ищем оптимальное разбиение. Рекомендуется использовать $L=\\sqrt{M}$ в задачах классификации и $\\frac{M}{3}$ — в задачах регрессии.\n",
    "3. Для получения предсказания необходимо воспользоваться обычным принципом бэггинга: взять усреднённый ответ в случае регрессии или самый популярный класс — для классификации.\n",
    "\n",
    "В контексте случайного леса важно обратить внимание на **несколько ключевых аспектов**:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Переобучение**\n",
    "\n",
    "Случайный лес может переобучаться, однако это никак не связано с количеством деревьев. Наоборот, с ростом числа деревьев модель становится всё более эффективной в плане корректных прогнозов. На анимации ниже наглядно показано, что случайный лес не переобучается, а совершенствует своё предсказание.\n",
    "\n",
    "<img src=\"data\\MATHML_md9_3_7.gif\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "Здесь мы видим пространство признаков с объектами, которые относятся к двум классам (красные точки и синие точки). Мы пытаемся построить разделяющую их поверхность, которая корректируется по ходу увеличения числа деревьев (счётчик количества деревьев расположен сверху)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Out-of-Bag Error**\n",
    "\n",
    "**Ошибка Out-of-Bag** — это способ оценить качество случайного леса.  \n",
    "Давайте разберём, как она вычисляется, на примере.  \n",
    "Предположим, что в нашем случайном лесу пять решающих деревьев, и наша обучающая выборка выглядит следующим образом:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-4.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В выборку внесены погодные условия и итоговое решение — подходит ли день для игры в теннис. Итоговое решение при одинаковых погодных условиях может отличаться, так как на него могли повлиять и другие факторы.\n",
    "\n",
    "Для первого дерева мы делаем такую подвыборку (Bootstrap Sample):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-5.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда неучтённая часть выборки носит название подвыборки Out-of-Bag (Out-of-Bag Sample):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-6.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как все деревья будут обучены, эта подвыборка будет передана всем деревьям, для которых она не входила в бутстреп-выборку, для формирования прогноза. Допустим, это были деревья под номерами 1, 3 и 5:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-7.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что большинство деревьев проголосовало, что день подходит для игры в теннис, то есть окончательный прогноз для этого объекта — YES. Это совпадает с реальной меткой. Значит, на этом наблюдении алгоритм дал верный прогноз.\n",
    "\n",
    "Таким же образом все объекты изначальной выборки проходят через все деревья, в подвыборку которых они не попали, и для каждого объекта осуществляется предсказание.\n",
    "\n",
    "Интересно, что можно доказать, что такие объекты составляют примерно 36.8 % от объёма подвыборки, то есть каждое дерево обучается на подвыборке, в которой в среднем 63.2 % уникальных наблюдений.\n",
    "\n",
    "Пусть в нашей выборке есть $N$ наблюдений. На каждом шаге каждое наблюдение попадает в выборку с вероятностью $\\frac{1}{N}$. Тогда вероятность того, что оно не попадает в выборку, — $1-\\frac{1}{N}$. Причём если выборка формируется N раз, то вероятность становится равна $(1-\\frac{1}{N})$^N. Теперь можно применить пределы, чтобы получить итоговый процент:\n",
    "\n",
    "$\\displaystyle \\lim_{N \\to \\infty }(1-\\frac{1}{N})^N=e^{-1}=0.368$\n",
    "\n",
    "**Примечание**. Данный переход напрямую следует из второго замечательного предела. К сожалению, эта часть математического анализа выходит за пределы нашего курса, однако если вам интересно изучить её подробнее, рекомендуем ознакомиться с этим материалом https://math1.ru/education/limits/limitsecond.html.\n",
    "\n",
    "Получается почти 37 %. Out-of-Bag-оценка — это как раз усреднённая оценка базовых алгоритмов на этих ~37% данных, на которых они не обучались.\n",
    "\n",
    "Итак, для того чтобы найти out-of-Bag-оценку:\n",
    "\n",
    "1. Для каждого объекта $x_i$ получаем предсказания всех деревьев $a_b$, обучавшихся на бутстреп-выборках $X_b$, не содержащих $x_i$.  \n",
    "2. Усредняем эти предсказания.  \n",
    "3. Находим значение ошибки для усреднённого предсказания.  \n",
    "4. Усредняем значение функционала ошибки для всех объектов выборки.  \n",
    "\n",
    "Строго математически это можно записать следующим образом:  \n",
    "$\\mathrm{OOB}= \\frac{1}{N}\\sum_{i=1}^{N} L\\left(y_{i}, \\frac{1}{\\sum_{b=1}^{B}\\left[x_{i} \\notin X_{b}\\right]} \\sum_{b=1}^{B}\\left[x_{i} \\notin X_{b}\\right] a_{b}\\left(x_{i}\\right)\\right)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Значимость признаков**\n",
    "\n",
    "Разумеется, нам всегда интересно узнать, какие признаки сильнее всего влияют на результат. Случайный лес даёт нам такую возможность. Посмотрим на схематичное изображение решающего дерева:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_3_9.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что признак «возраст автовладельца > 40 лет» важнее, чем, например, тип автомобиля. Нам хотелось бы не только узнать самый важный признак, но и в целом проранжировать все признаки модели.\n",
    "\n",
    "В случайном лесе мы строим много деревьев, и чем в среднем выше какой-то признак находится в деревьях, тем он важнее. О том, как это вычислить программно, мы узнаем в следующем юните."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Оценка эффективности**\n",
    "\n",
    "В предыдущем модуле мы разобрали решающие деревья, а в этом — бэггинг и случайный лес. Давайте попробуем сравнить эти алгоритмы и понять, какой из них является более эффективным и даёт бóльшую прогностическую точность.\n",
    "\n",
    "Реализуем три варианта моделей для случайно сгенерированных данных:\n",
    "\n",
    "- решающее дерево c глубиной 15;\n",
    "- бэггинг с десятью решающими деревьями:\n",
    "        - по одному — глубины 11, 14, 15, 16,\n",
    "        - четыре — глубины 13,\n",
    "        - два — глубины 12;\n",
    "- случайный лес с десятью решающими деревьями:\n",
    "        - по одному — глубины 12, 18,\n",
    "        - два — глубины 16,\n",
    "        - шесть — глубины 13.\n",
    "\n",
    "Попробуем оценить качество в каждом случае. Результаты представлены на графиках ниже.\n",
    "\n",
    "**Примечание:**\n",
    "\n",
    "- Синей линией показаны истинные значения для выборки.\n",
    "- Точками, которые соединены линиями разных цветов, обозначены предсказания соответствующих моделей: зелёная линия — для решающего дерева, жёлтая — для бэггинга, красная — для случайного леса.\n",
    "\n",
    "<img src=\"data\\MATHML_md9_3_10.png\" alt=\"drawing\" width=\"300\"/>  \n",
    "<img src=\"data\\MATHML_md9_3_11.png\" alt=\"drawing\" width=\"300\"/>   \n",
    "<img src=\"data\\MATHML_md9_3_12.png\" alt=\"drawing\" width=\"300\"/>  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графиков можно увидеть, что ошибка для алгоритма бэггинга над решающими деревьями заметно меньше, чем ошибка для одного случайного дерева. Численные результаты подтверждают это. Случайный лес в данном случае обгоняет по эффективности бэггинг над решающими деревьями (однако это не является правилом, и с другими данными может получиться другой результат).\n",
    "\n",
    "Итак, мы разобрали все основные моменты, которые касаются случайного леса. Нам осталось лишь закрепить полученные знания на практике — этим мы займёмся уже совсем скоро. А пока давайте обобщим плюсы и минусы данного алгоритма, которые были упомянуты в этом юните и ранее."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\happy-icon.png\" alt=\"drawing\" width=\"50\"/>  \n",
    "\n",
    "- Очень высокая точность предсказания (это один из самых эффективных алгоритмов).\n",
    "- Данные не обязательно масштабировать: случайный лес не чувствителен к масштабированию и в принципе к любым монотонным преобразованиям, поэтому в таких манипуляциях нет смысла.\n",
    "- Нет чувствительности к выбросам из-за формирования случайных выборок.\n",
    "- Не требуется тщательно настраивать множество параметров. Даже если реализовывать алгоритм с настройками по умолчанию, результат будет лучше, чем у большинства других моделей.\n",
    "- Нет склонности к переобучению.\n",
    "- Позволяет оценить значимость отдельных признаков.\n",
    "- Может эффективно работать с несбалансированными классами.\n",
    "- Показывает высокую точность на данных с большим количеством пропусков."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\sad-icon.png\" alt=\"drawing\" width=\"50\"/>  \n",
    "\n",
    "- Плохо работает с разрежёнными признаками (т. е. с такими, у которых преимущественно нулевые значения). Это может сказываться, к примеру, на качестве анализа текстов.\n",
    "- Сложно интерпретировать результаты."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Плохо работает с разрежёнными признаками (т. е. с такими, у которых преимущественно нулевые значения). Это может сказываться, к примеру, на качестве анализа текстов.\n",
    "Сложно интерпретировать результаты."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Более подробно рассматривать практическую сторону реализации случайного леса и варьировать различные параметры для получения наилучшего результата мы будем в следующем юните. Но давайте решим небольшую задачу уже сейчас. Все функции из неё вы уже использовали ранее, так что это отличный повод вспомнить их или поработать с документацией.\n",
    "\n",
    "Мы будем анализировать набор данных Boston Houses, в котором объектами являются районы города, признаками — некие социальные и географические характеристики района, а целевой переменной — медианная стоимость домов в районе. Таким образом, мы будем решать задачу регрессии.\n",
    "\n",
    "Как и в предыдущем практическом задании, весь код, который мы напишем, можно применить к любым данным."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание признаков**\n",
    "\n",
    "- crim_rate — уровень преступности в районе;\n",
    "- zn — доля участков площадью более 25 000 кв. футов;\n",
    "- business — уровень развитости бизнеса в районе;\n",
    "- river — наличие реки в районе;\n",
    "- nit_oxiden — концентрация оксидов азота в воздухе;\n",
    "- rooms — среднее число комнат в домах района;\n",
    "- age — процент домов, построенных до 1940 года;\n",
    "- dist — расстояние до центров занятости;\n",
    "- highways_index — индекс доступности крупных дорог;\n",
    "- tax — средняя ставка налога на имущество;\n",
    "- pup_per_teac — среднее число учеников на одного учителя;\n",
    "- lower — процент малообеспеченного населения в районе;\n",
    "- target — медианная стоимость домов в районе (целевая переменная)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.4**\n",
    "\n",
    "1. Разбейте набор данных на обучающую и тестовую выборку в соотношении 70/30, при разбиении задайте параметр random_state = 13.  \n",
    "\n",
    "Какое получилось среднее значение медианных цен на обучающей выборке? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim_rate</th>\n",
       "      <th>zn</th>\n",
       "      <th>business</th>\n",
       "      <th>river</th>\n",
       "      <th>nit_oxiden</th>\n",
       "      <th>rooms</th>\n",
       "      <th>age</th>\n",
       "      <th>dist</th>\n",
       "      <th>highways_index</th>\n",
       "      <th>tax</th>\n",
       "      <th>pup_per_teaс</th>\n",
       "      <th>lower</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   crim_rate    zn  business  river  nit_oxiden  rooms   age    dist  \\\n",
       "0    0.00632  18.0      2.31      0       0.538  6.575  65.2  4.0900   \n",
       "1    0.02731   0.0      7.07      0       0.469  6.421  78.9  4.9671   \n",
       "2    0.02729   0.0      7.07      0       0.469  7.185  61.1  4.9671   \n",
       "3    0.03237   0.0      2.18      0       0.458  6.998  45.8  6.0622   \n",
       "4    0.06905   0.0      2.18      0       0.458  7.147  54.2  6.0622   \n",
       "\n",
       "   highways_index  tax  pup_per_teaс  lower  target  \n",
       "0               1  296          15.3   4.98    24.0  \n",
       "1               2  242          17.8   9.14    21.6  \n",
       "2               2  242          17.8   4.03    34.7  \n",
       "3               3  222          18.7   2.94    33.4  \n",
       "4               3  222          18.7   5.33    36.2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/boston (1).csv', decimal=\",\") # в csv десятичная дробь записывается не с точкой, а с запятой (распознается как object).\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   crim_rate       506 non-null    float64\n",
      " 1   zn              506 non-null    float64\n",
      " 2   business        506 non-null    float64\n",
      " 3   river           506 non-null    int64  \n",
      " 4   nit_oxiden      506 non-null    float64\n",
      " 5   rooms           506 non-null    float64\n",
      " 6   age             506 non-null    float64\n",
      " 7   dist            506 non-null    float64\n",
      " 8   highways_index  506 non-null    int64  \n",
      " 9   tax             506 non-null    int64  \n",
      " 10  pup_per_teaс    506 non-null    float64\n",
      " 11  lower           506 non-null    float64\n",
      " 12  target          506 non-null    float64\n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.77\n"
     ]
    }
   ],
   "source": [
    "print(round(y_train.mean(), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите линейную регрессию с параметрами по умолчанию.\n",
    "\n",
    "В качестве ответа введите ошибку MAE на тестовой выборке. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7222793958561526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import *\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "preds_train = model_lr.predict(X_train)\n",
    "preds_test = model_lr.predict(X_test)\n",
    "print(mean_absolute_error(y_test, preds_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Обучите решающее дерево с параметрами по умолчанию и аргументом random_state = 13.\n",
    "\n",
    "Можно ли, опираясь на результаты, сделать вывод, что алгоритм переобучился?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.8388157894736845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model = DecisionTreeRegressor(random_state=13)\n",
    "model.fit(X_train, y_train)\n",
    "preds_train = model.predict(X_train)\n",
    "preds_test = model.predict(X_test)\n",
    "print(mean_absolute_error(y_train, preds_train))\n",
    "print(mean_absolute_error(y_test, preds_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Обучите четыре случайных леса с числом деревьев 3, 10, 100, 500 и параметром random_state = 13.\n",
    "\n",
    "В качестве ответа введите наименьшую полученную ошибку MAE на тестовой выборке. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9328947368421057\n",
      "2.466315789473684\n",
      "2.2559736842105265\n",
      "2.2365657894736892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "for n in [3, 10, 100, 500]:\n",
    "    model = RandomForestRegressor(n_estimators=n, random_state = 13)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_train = model.predict(X_train)\n",
    "    preds_test = model.predict(X_test)\n",
    "    print(mean_absolute_error(y_test, preds_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Случайный лес. Практика"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы познакомились с теоретической основой случайного леса, а в этом закрепим пройденный материал на практике.\n",
    "\n",
    "Пожалуй, каждый из нас практически ежедневно смотрит прогноз погоды: будет сегодня тепло или холодно, брать ли зонт? Мы расстраиваемся, если внезапно идёт дождь, а мы оказались к этому не готовы. Иногда можно понять, что будет дождь, просто взглянув на небо, но часто такие предположения оказываются неверными. Надёжнее всего пользоваться прогнозами, которые публикуют специалисты. А задумывались ли вы, как формируются эти прогнозы?\n",
    "\n",
    "<img src=\"data\\MATHML_md9_4_1.jpg\" alt=\"drawing\" width=\"400\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, с какими данными нам предстоит работать https://lms.skillfactory.ru/assets/courseware/v1/55a24d3591d52f74426896a40a048041/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/weatherAUS.zip. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_4_2.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные содержат 23 признака и 145 460 наблюдений. Из этих 23 признаков шесть — категориальные, в одном записана дата, а остальные являются непрерывными числовыми данными.\n",
    "\n",
    "- Примеры числовых признаков: температура, скорость ветра, влажность, облачность, атмосферное давление в разное время суток, количество осадков, испарение, количество часов с солнечной погодой.  \n",
    "- Примеры категориальных признаков: местоположение, направление ветра в разное время суток, наличие дождя сегодня или завтра.\n",
    "\n",
    "**Целевой переменной** является столбец RainTomorrow. Значение этой переменной мы и будем пытаться предсказать."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробная расшифровка всех признаков:\n",
    "\n",
    "Date — дата, в которую зафиксировано наблюдение;  \n",
    "Location — местонахождение метеорологической станции;  \n",
    "MinTemp — минимальная температура (℃);  \n",
    "MaxTemp — максимальная температура (℃);  \n",
    "Rainfall — количество осадков (дождь) за сутки (мм);  \n",
    "Evaporation — количество испарений до 9 утра (мм);  \n",
    "Sunshine — количество часов в сутках, когда светило солнце;  \n",
    "WindGustDir — направление самого сильного порыва ветра за последние 24 часа;  \n",
    "WindGustSpeed — скорость самого сильного порыва ветра за последние 24 часа;  \n",
    "WindDir9am — направление ветра в 9 утра;  \n",
    "WindDir3pm — направление ветра в 3 часа дня;  \n",
    "WindSpeed9am — скорость ветра в 9 часов утра;  \n",
    "WindSpeed3pm — скорость ветра в 3 часа дня;  \n",
    "Humidity9am — влажность в 9 утра;  \n",
    "Humidity3pm — влажность в 3 часа дня;  \n",
    "Pressure9am — атмосферное давление в 9 утра;  \n",
    "Pressure3pm — атмосферное давление в 3 часа дня;  \n",
    "Cloud9am — часть неба, закрытая облаками, в 9 утра;  \n",
    "Cloud3pm — часть неба, закрытая облаками, в 3 часа дня;  \n",
    "Temp9am — температура в 9 утра;  \n",
    "Temp3pm — температура в 3 часа дня;  \n",
    "RainToday — наличие дождя в этот день;  \n",
    "RainTomorrow — наличие дождя на следующий день.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.1**\n",
    "\n",
    "Сколько суммарно пропусков в данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  Humidity3pm  \\\n",
       "0           W           44.0          W  ...        71.0         22.0   \n",
       "1         WNW           44.0        NNW  ...        44.0         25.0   \n",
       "2         WSW           46.0          W  ...        38.0         30.0   \n",
       "3          NE           24.0         SE  ...        45.0         16.0   \n",
       "4           W           41.0        ENE  ...        82.0         33.0   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1007.7       1007.1       8.0       NaN     16.9     21.8         No   \n",
       "1       1010.6       1007.8       NaN       NaN     17.2     24.3         No   \n",
       "2       1007.6       1008.7       NaN       2.0     21.0     23.2         No   \n",
       "3       1017.6       1012.8       NaN       NaN     18.1     26.5         No   \n",
       "4       1010.8       1006.0       7.0       8.0     17.8     29.7         No   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/weatherAUS.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343248"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно отметить, что в данных много пропусков, но для нас это не проблема, так как случайный лес прекрасно работает в таких ситуациях, и скоро у нас будет возможность в этом убедиться."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.2**\n",
    "\n",
    "В некоторых признаках пропусков более 40 % — удалите такие признаки. Сколько их было?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             0.000\n",
       "Location         0.000\n",
       "MinTemp          0.010\n",
       "MaxTemp          0.009\n",
       "Rainfall         0.022\n",
       "Evaporation      0.432\n",
       "Sunshine         0.480\n",
       "WindGustDir      0.071\n",
       "WindGustSpeed    0.071\n",
       "WindDir9am       0.073\n",
       "WindDir3pm       0.029\n",
       "WindSpeed9am     0.012\n",
       "WindSpeed3pm     0.021\n",
       "Humidity9am      0.018\n",
       "Humidity3pm      0.031\n",
       "Pressure9am      0.104\n",
       "Pressure3pm      0.103\n",
       "Cloud9am         0.384\n",
       "Cloud3pm         0.408\n",
       "Temp9am          0.012\n",
       "Temp3pm          0.025\n",
       "RainToday        0.022\n",
       "RainTomorrow     0.022\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.isna().sum() / len(df), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Evaporation','Sunshine','Cloud3pm'], axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.3**\n",
    "\n",
    "Теперь обработаем признаки RainToday и RainTomorrow таким образом, чтобы вместо yes было значение 1, а вместо no — значение 0. Обратите внимание на то, что в признаке RainTomorrow присутствуют пропуски, и их трогать не нужно, они должны остаться пропусками. Поэтому обрабатывайте столбцы таким образом, чтобы не видоизменить пропущенные значения.\n",
    "\n",
    "Вычислите среднее арифметическое для преобразованного признака RainToday и запишите его в ответ, предварительно округлив до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.RainToday = df.RainToday.map({'No': 0, 'Yes': 1})\n",
    "df.RainTomorrow = df.RainTomorrow.map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22419285648984874"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.RainToday.mean() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.4**\n",
    "\n",
    "Обработайте признак Date таким образом, чтобы выделить в отдельный признак Month (номер месяца). Изначальный признак Date удалите. Определите, в какой месяц в среднем за день выпадает больше всего дождей. В качестве ответа введите порядковый номер месяца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_6632\\1749877501.py:4: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_season = df.groupby('Month').mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RainToday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.189484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.206746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.217135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.222163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.263638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.270736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.253167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.229135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.196512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.210843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.213037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RainToday\n",
       "Month           \n",
       "1       0.189484\n",
       "2       0.206746\n",
       "3       0.217135\n",
       "4       0.216845\n",
       "5       0.222163\n",
       "6       0.263638\n",
       "7       0.270736\n",
       "8       0.253167\n",
       "9       0.229135\n",
       "10      0.196512\n",
       "11      0.210843\n",
       "12      0.213037"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Date = pd.to_datetime(df.Date)\n",
    "df['Month'] = df.Date.dt.month\n",
    "df.drop('Date', axis = 1, inplace = True)\n",
    "df_season = df.groupby('Month').mean()\n",
    "df_season[['RainToday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.535535</td>\n",
       "      <td>29.532383</td>\n",
       "      <td>2.738478</td>\n",
       "      <td>43.396456</td>\n",
       "      <td>15.335356</td>\n",
       "      <td>20.186773</td>\n",
       "      <td>62.331667</td>\n",
       "      <td>46.443769</td>\n",
       "      <td>1012.794733</td>\n",
       "      <td>1010.613441</td>\n",
       "      <td>4.489372</td>\n",
       "      <td>22.532823</td>\n",
       "      <td>27.637489</td>\n",
       "      <td>0.189484</td>\n",
       "      <td>0.193329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.503588</td>\n",
       "      <td>28.873509</td>\n",
       "      <td>3.188665</td>\n",
       "      <td>41.498998</td>\n",
       "      <td>14.411638</td>\n",
       "      <td>19.234714</td>\n",
       "      <td>67.018111</td>\n",
       "      <td>48.984888</td>\n",
       "      <td>1014.499906</td>\n",
       "      <td>1012.378532</td>\n",
       "      <td>4.508100</td>\n",
       "      <td>21.791693</td>\n",
       "      <td>27.124375</td>\n",
       "      <td>0.206746</td>\n",
       "      <td>0.209691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.913305</td>\n",
       "      <td>26.885273</td>\n",
       "      <td>2.814450</td>\n",
       "      <td>39.599356</td>\n",
       "      <td>13.332753</td>\n",
       "      <td>18.466672</td>\n",
       "      <td>70.816985</td>\n",
       "      <td>50.357165</td>\n",
       "      <td>1016.766232</td>\n",
       "      <td>1014.551846</td>\n",
       "      <td>4.490458</td>\n",
       "      <td>19.888484</td>\n",
       "      <td>25.343573</td>\n",
       "      <td>0.217135</td>\n",
       "      <td>0.213332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.843618</td>\n",
       "      <td>23.625035</td>\n",
       "      <td>2.334823</td>\n",
       "      <td>36.505243</td>\n",
       "      <td>12.877838</td>\n",
       "      <td>17.153968</td>\n",
       "      <td>70.803854</td>\n",
       "      <td>52.219453</td>\n",
       "      <td>1019.641567</td>\n",
       "      <td>1017.043485</td>\n",
       "      <td>4.496956</td>\n",
       "      <td>17.680004</td>\n",
       "      <td>22.239993</td>\n",
       "      <td>0.216845</td>\n",
       "      <td>0.217849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.640925</td>\n",
       "      <td>20.065173</td>\n",
       "      <td>2.001654</td>\n",
       "      <td>35.803096</td>\n",
       "      <td>12.420218</td>\n",
       "      <td>16.356048</td>\n",
       "      <td>74.675386</td>\n",
       "      <td>55.187292</td>\n",
       "      <td>1020.449787</td>\n",
       "      <td>1017.949934</td>\n",
       "      <td>4.459665</td>\n",
       "      <td>14.116108</td>\n",
       "      <td>18.822236</td>\n",
       "      <td>0.222163</td>\n",
       "      <td>0.225278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.818067</td>\n",
       "      <td>17.307648</td>\n",
       "      <td>2.782182</td>\n",
       "      <td>35.560891</td>\n",
       "      <td>12.293303</td>\n",
       "      <td>15.870799</td>\n",
       "      <td>79.406630</td>\n",
       "      <td>60.540855</td>\n",
       "      <td>1021.200465</td>\n",
       "      <td>1018.879716</td>\n",
       "      <td>4.744507</td>\n",
       "      <td>11.565653</td>\n",
       "      <td>16.186395</td>\n",
       "      <td>0.263638</td>\n",
       "      <td>0.261845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.944633</td>\n",
       "      <td>16.744580</td>\n",
       "      <td>2.184209</td>\n",
       "      <td>37.963884</td>\n",
       "      <td>12.977923</td>\n",
       "      <td>17.347654</td>\n",
       "      <td>77.488055</td>\n",
       "      <td>58.005207</td>\n",
       "      <td>1021.121071</td>\n",
       "      <td>1018.730487</td>\n",
       "      <td>4.454439</td>\n",
       "      <td>10.830630</td>\n",
       "      <td>15.631336</td>\n",
       "      <td>0.270736</td>\n",
       "      <td>0.269208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.459653</td>\n",
       "      <td>18.241013</td>\n",
       "      <td>2.034983</td>\n",
       "      <td>40.280165</td>\n",
       "      <td>13.868044</td>\n",
       "      <td>18.911306</td>\n",
       "      <td>71.420059</td>\n",
       "      <td>52.816025</td>\n",
       "      <td>1019.603766</td>\n",
       "      <td>1016.991759</td>\n",
       "      <td>4.094023</td>\n",
       "      <td>12.372772</td>\n",
       "      <td>16.951018</td>\n",
       "      <td>0.253167</td>\n",
       "      <td>0.252508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.466875</td>\n",
       "      <td>20.752012</td>\n",
       "      <td>1.888543</td>\n",
       "      <td>42.294806</td>\n",
       "      <td>15.478037</td>\n",
       "      <td>20.175620</td>\n",
       "      <td>64.944760</td>\n",
       "      <td>50.334514</td>\n",
       "      <td>1018.039954</td>\n",
       "      <td>1015.251349</td>\n",
       "      <td>4.131386</td>\n",
       "      <td>15.350247</td>\n",
       "      <td>19.188121</td>\n",
       "      <td>0.229135</td>\n",
       "      <td>0.229705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.531224</td>\n",
       "      <td>23.537153</td>\n",
       "      <td>1.614732</td>\n",
       "      <td>42.730828</td>\n",
       "      <td>15.435518</td>\n",
       "      <td>20.490943</td>\n",
       "      <td>62.670601</td>\n",
       "      <td>47.406063</td>\n",
       "      <td>1018.338814</td>\n",
       "      <td>1015.883326</td>\n",
       "      <td>4.197266</td>\n",
       "      <td>17.252736</td>\n",
       "      <td>21.796762</td>\n",
       "      <td>0.196512</td>\n",
       "      <td>0.195696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.321606</td>\n",
       "      <td>26.181247</td>\n",
       "      <td>2.268177</td>\n",
       "      <td>42.617647</td>\n",
       "      <td>15.238240</td>\n",
       "      <td>20.080046</td>\n",
       "      <td>61.787145</td>\n",
       "      <td>47.889799</td>\n",
       "      <td>1015.385387</td>\n",
       "      <td>1013.041614</td>\n",
       "      <td>4.637376</td>\n",
       "      <td>19.970794</td>\n",
       "      <td>24.272204</td>\n",
       "      <td>0.210843</td>\n",
       "      <td>0.212547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.811322</td>\n",
       "      <td>27.558321</td>\n",
       "      <td>2.491835</td>\n",
       "      <td>43.071686</td>\n",
       "      <td>15.274989</td>\n",
       "      <td>20.215366</td>\n",
       "      <td>61.568847</td>\n",
       "      <td>47.339779</td>\n",
       "      <td>1013.317432</td>\n",
       "      <td>1011.109731</td>\n",
       "      <td>4.667516</td>\n",
       "      <td>21.225267</td>\n",
       "      <td>25.612047</td>\n",
       "      <td>0.213037</td>\n",
       "      <td>0.208141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         MinTemp    MaxTemp  Rainfall  WindGustSpeed  WindSpeed9am  \\\n",
       "Month                                                                \n",
       "1      17.535535  29.532383  2.738478      43.396456     15.335356   \n",
       "2      17.503588  28.873509  3.188665      41.498998     14.411638   \n",
       "3      15.913305  26.885273  2.814450      39.599356     13.332753   \n",
       "4      12.843618  23.625035  2.334823      36.505243     12.877838   \n",
       "5       9.640925  20.065173  2.001654      35.803096     12.420218   \n",
       "6       7.818067  17.307648  2.782182      35.560891     12.293303   \n",
       "7       6.944633  16.744580  2.184209      37.963884     12.977923   \n",
       "8       7.459653  18.241013  2.034983      40.280165     13.868044   \n",
       "9       9.466875  20.752012  1.888543      42.294806     15.478037   \n",
       "10     11.531224  23.537153  1.614732      42.730828     15.435518   \n",
       "11     14.321606  26.181247  2.268177      42.617647     15.238240   \n",
       "12     15.811322  27.558321  2.491835      43.071686     15.274989   \n",
       "\n",
       "       WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  Pressure3pm  \\\n",
       "Month                                                                     \n",
       "1         20.186773    62.331667    46.443769  1012.794733  1010.613441   \n",
       "2         19.234714    67.018111    48.984888  1014.499906  1012.378532   \n",
       "3         18.466672    70.816985    50.357165  1016.766232  1014.551846   \n",
       "4         17.153968    70.803854    52.219453  1019.641567  1017.043485   \n",
       "5         16.356048    74.675386    55.187292  1020.449787  1017.949934   \n",
       "6         15.870799    79.406630    60.540855  1021.200465  1018.879716   \n",
       "7         17.347654    77.488055    58.005207  1021.121071  1018.730487   \n",
       "8         18.911306    71.420059    52.816025  1019.603766  1016.991759   \n",
       "9         20.175620    64.944760    50.334514  1018.039954  1015.251349   \n",
       "10        20.490943    62.670601    47.406063  1018.338814  1015.883326   \n",
       "11        20.080046    61.787145    47.889799  1015.385387  1013.041614   \n",
       "12        20.215366    61.568847    47.339779  1013.317432  1011.109731   \n",
       "\n",
       "       Cloud9am    Temp9am    Temp3pm  RainToday  RainTomorrow  \n",
       "Month                                                           \n",
       "1      4.489372  22.532823  27.637489   0.189484      0.193329  \n",
       "2      4.508100  21.791693  27.124375   0.206746      0.209691  \n",
       "3      4.490458  19.888484  25.343573   0.217135      0.213332  \n",
       "4      4.496956  17.680004  22.239993   0.216845      0.217849  \n",
       "5      4.459665  14.116108  18.822236   0.222163      0.225278  \n",
       "6      4.744507  11.565653  16.186395   0.263638      0.261845  \n",
       "7      4.454439  10.830630  15.631336   0.270736      0.269208  \n",
       "8      4.094023  12.372772  16.951018   0.253167      0.252508  \n",
       "9      4.131386  15.350247  19.188121   0.229135      0.229705  \n",
       "10     4.197266  17.252736  21.796762   0.196512      0.195696  \n",
       "11     4.637376  19.970794  24.272204   0.210843      0.212547  \n",
       "12     4.667516  21.225267  25.612047   0.213037      0.208141  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_season"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.5**\n",
    "\n",
    "1 point possible (graded)Обработайте оставшиеся категориальные признаки. С помощью метода get_dummies с настройками по умолчанию создайте dummy-переменные для всех категориальных признаков (их пять), которые есть в данных на этот момент.\n",
    "\n",
    "Кодировку признаков важно выполнить именно в следующем порядке: categoricals = ['Month', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']. Это необходимо для того, чтобы ваши дальнейшие ответы сходились с нашим решением, так как алгоритм случайного леса, который мы будем использовать в дальнейшем, чувствителен к порядку столбцов.\n",
    "\n",
    "Сколько теперь признаков в данных, если считать целевую переменную?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145460, 124)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricals = ['Month', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "df_dummies = pd.get_dummies(df, columns=categoricals)\n",
    "df_dummies.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.6**\n",
    "\n",
    "Осталось совсем немного. Удалите все строки, где есть пропуски. Далее разбейте данные на обучающую и тестовую выборки в соотношении 70/30, в качестве значения параметра random_state возьмите число 31.\n",
    "\n",
    "Каково среднее значение целевой переменной на тестовой выборке? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22770253002811142"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.dropna(inplace=True)\n",
    "X = df_dummies.drop('RainTomorrow', axis = 1)\n",
    "Y = df_dummies['RainTomorrow']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 31)\n",
    "Y_test.mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.7**\n",
    "\n",
    "Теперь давайте вспомним про бутстреп. Он не понадобится нам для решения этой задачи, но будет полезно реализовать его «вручную».\n",
    "\n",
    "Сделайте оценку стандартного отклонения для среднего значения минимальной температуры для обучающей выборки (то есть для среднего значения по признаку MinTemp). Для этого сгенерируйте 1000 случайных выборок из наших данных — каждая из них должна быть такого же объёма, как и обучающая выборка. Для генерации выборки используйте np.random.randint(): сгенерируйте необходимое количество индексов и по ним извлеките соответствующие элементы выборки. Случайность фиксируйте с помощью np.random.seed(31).\n",
    "\n",
    "Для каждой выборки вычислите среднее значение, а после найдите стандартное отклонение для этих значений. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02879072820657669"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gbs(data, n):\n",
    "    inds = np.random.randint(0, len(data), (n, len(data))) #определяем индексы случайным образом\n",
    "    numbers = data[inds] #выбираем значения по индексам\n",
    "    return numbers\n",
    "target = X_train['MinTemp'].values #выбираем целевую переменную\n",
    "np.random.seed(31) #задаём параметр генератора случайных чисел\n",
    "mean_values = [np.mean(x) for x in gbs(target, 1000)] #получаем все средние значения\n",
    "np.std(mean_values) #находим для них стандартное отклонение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.8**\n",
    "\n",
    "Теперь можно перейти к обучению прогностических моделей. Начнём с того, что построим простейшую логистическую регрессию (без настройки гиперпараметров). Это будет та модель, с качеством которой мы будем сравнивать результаты, полученные далее, чтобы оценить превосходство случайного леса над простыми методами.\n",
    "\n",
    "В качестве ответа введите значение метрики roc_auc на тестовой выборке. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7261883053393459"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, Y_train)\n",
    "preds_train = clf.predict(X_train)\n",
    "preds_test = clf.predict(X_test)\n",
    "roc_auc_score(Y_test, preds_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.9**\n",
    "\n",
    "Теперь попробуйте обучить на наших данных другой алгоритм — дерево решений. С помощью GridSearchCV сделайте перебор гиперпараметров по следующей сетке:\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 10)), 'min_samples_split': [2, 3, 4], 'max_depth': [5,7,9,11]}\n",
    "Для параметра кросс-валидации cv задайте значение 3. Для решающего дерева определите параметр random_state=42. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "1. Вычислите значение roc_auc для решающего дерева с гиперпараметрами, определёнными в качестве оптимальных. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=2;, score=0.817 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=2;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=3;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=3;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=3;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=4;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=4;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=2, min_samples_split=4;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=3;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=3;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=4;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=4;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=3, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=4, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=5, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=2;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=3;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=4;, score=0.819 total time=   0.2s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=4;, score=0.820 total time=   0.3s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=6, min_samples_split=4;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=2;, score=0.831 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=2;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=2;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=3;, score=0.831 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=3;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=3;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=4;, score=0.831 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=4;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=7, min_samples_split=4;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=2;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=2;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=2;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=3;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=3;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=3;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=4;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=4;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=8, min_samples_split=4;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=2;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=2;, score=0.840 total time=   0.2s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=2;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=3;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=3;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=3;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=4;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=4;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=5, max_leaf_nodes=9, min_samples_split=4;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=2;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=2;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=3;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=3;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=3;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=4;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=4;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=2, min_samples_split=4;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=2;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=3;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=4;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=4;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=3, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=4, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=4;, score=0.820 total time=   0.2s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=5, min_samples_split=4;, score=0.825 total time=   0.2s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=2;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=3;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=6, min_samples_split=4;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=2;, score=0.831 total time=   0.2s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=2;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=2;, score=0.832 total time=   0.2s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=3;, score=0.831 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=3;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=3;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=4;, score=0.831 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=4;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=7, min_samples_split=4;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=2;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=2;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=2;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=3;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=3;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=3;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=4;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=4;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=8, min_samples_split=4;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=2;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=2;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=2;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=3;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=3;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=3;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=4;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=4;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=7, max_leaf_nodes=9, min_samples_split=4;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=2;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=2;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=3;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=3;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=3;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=4;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=2, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=3;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=4;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=3, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=4, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=5, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=2;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=3;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=6, min_samples_split=4;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=2;, score=0.831 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=2;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=2;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=3;, score=0.831 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=3;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=3;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=4;, score=0.831 total time=   0.2s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=4;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=7, min_samples_split=4;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=2;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=2;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=2;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=3;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=3;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=3;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=4;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=4;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=8, min_samples_split=4;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=2;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=2;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=2;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=3;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=3;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=3;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=4;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=4;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=9, max_leaf_nodes=9, min_samples_split=4;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=2;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=2;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=3;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=3;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=3;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=4;, score=0.817 total time=   0.0s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=4;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=2, min_samples_split=4;, score=0.825 total time=   0.0s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=2;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=2;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=3;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=3;, score=0.820 total time=   0.0s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=3;, score=0.825 total time=   0.2s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=4;, score=0.819 total time=   0.0s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=3, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=4, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=2;, score=0.819 total time=   0.2s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=2;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=3;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=3;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=5, min_samples_split=4;, score=0.825 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=2;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=2;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=2;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=3;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=3;, score=0.820 total time=   0.2s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=3;, score=0.832 total time=   0.3s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=4;, score=0.819 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=4;, score=0.820 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=6, min_samples_split=4;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=2;, score=0.831 total time=   0.2s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=2;, score=0.834 total time=   0.2s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=2;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=3;, score=0.831 total time=   0.2s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=3;, score=0.834 total time=   0.2s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=3;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=4;, score=0.831 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=4;, score=0.834 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=7, min_samples_split=4;, score=0.832 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=2;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=2;, score=0.840 total time=   0.2s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=2;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=3;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=3;, score=0.840 total time=   0.2s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=3;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=4;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=4;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=8, min_samples_split=4;, score=0.836 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=2;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=2;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=2;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=3;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=3;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=3;, score=0.837 total time=   0.1s\n",
      "[CV 1/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=4;, score=0.835 total time=   0.1s\n",
      "[CV 2/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=4;, score=0.840 total time=   0.1s\n",
      "[CV 3/3] END max_depth=11, max_leaf_nodes=9, min_samples_split=4;, score=0.837 total time=   0.1s\n",
      "{'max_depth': 5, 'max_leaf_nodes': 9, 'min_samples_split': 2}\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_leaf_nodes': list(range(2, 10)),\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'max_depth': [5,7,9,11]\n",
    "}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, verbose=3, cv=3)\n",
    "grid_search_cv.fit(X_train, Y_train)\n",
    "print(grid_search_cv.best_params_)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth = 5, max_leaf_nodes = 9, min_samples_split = 2,\n",
    "random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "preds_train = clf.predict(X_train)\n",
    "preds_test = clf.predict(X_test)\n",
    "print(round(roc_auc_score(Y_test, preds_test), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.10**\n",
    "\n",
    "К сожалению, деревья решений не помогли нам в улучшении качества модели, так что попробуем ещё уменьшить ошибку с помощью ансамблей.\n",
    "\n",
    "Теперь постройте случайный лес, включающий 100 деревьев. Задайте параметр random_state=31. Остальные параметры оставьте по умолчанию.\n",
    "\n",
    "Какой теперь будет метрика roc_auc на тестовой выборке? Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "clf = ensemble.RandomForestClassifier(n_estimators = 100, random_state=31)\n",
    "clf.fit(X_train, Y_train)\n",
    "preds_train = clf.predict(X_train)\n",
    "preds_test = clf.predict(X_test)\n",
    "print(round(roc_auc_score(Y_test, preds_test), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.11**\n",
    "\n",
    "Основные параметры, которые отвечают за качество обучения в случайном лесе, следующие:'max_features', 'min_samples_leaf', 'max_depth'.\n",
    "\n",
    "Возьмите случайный лес из 100 деревьев и найдите оптимальную комбинацию этих трёх параметров. Сетка для перебора следующая:\n",
    "\n",
    "{'max_features': [ 4, 5, 6, 7], 'min_samples_leaf': [3, 5, 7, 9, 11], 'max_depth': [5, 10, 15]}\n",
    "Перебор осуществите с помощью GridSearchCV. Для параметра кросс-валидации cv задайте значение 3. Случайности фиксируйте параметром random_state = 31. Остальные значения оставьте по умолчанию.\n",
    "\n",
    "Какое значение roc_auc получилось для оптимальных гиперпараметров?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "[CV 1/3] END max_depth=5, max_features=4, min_samples_leaf=3;, score=0.776 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, max_features=4, min_samples_leaf=3;, score=0.775 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, max_features=4, min_samples_leaf=3;, score=0.775 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, max_features=4, min_samples_leaf=5;, score=0.776 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, max_features=4, min_samples_leaf=5;, score=0.775 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, max_features=4, min_samples_leaf=5;, score=0.775 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, max_features=4, min_samples_leaf=7;, score=0.776 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, max_features=4, min_samples_leaf=7;, score=0.775 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, max_features=4, min_samples_leaf=7;, score=0.775 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, max_features=4, min_samples_leaf=9;, score=0.776 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, max_features=4, min_samples_leaf=9;, score=0.775 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, max_features=4, min_samples_leaf=9;, score=0.775 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, max_features=4, min_samples_leaf=11;, score=0.776 total time=   1.1s\n",
      "[CV 2/3] END max_depth=5, max_features=4, min_samples_leaf=11;, score=0.775 total time=   1.1s\n",
      "[CV 3/3] END max_depth=5, max_features=4, min_samples_leaf=11;, score=0.775 total time=   1.1s\n",
      "[CV 1/3] END max_depth=5, max_features=5, min_samples_leaf=3;, score=0.782 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, max_features=5, min_samples_leaf=3;, score=0.780 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, max_features=5, min_samples_leaf=3;, score=0.781 total time=   1.3s\n",
      "[CV 1/3] END max_depth=5, max_features=5, min_samples_leaf=5;, score=0.781 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, max_features=5, min_samples_leaf=5;, score=0.781 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, max_features=5, min_samples_leaf=5;, score=0.781 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, max_features=5, min_samples_leaf=7;, score=0.782 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, max_features=5, min_samples_leaf=7;, score=0.780 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, max_features=5, min_samples_leaf=7;, score=0.782 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, max_features=5, min_samples_leaf=9;, score=0.782 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, max_features=5, min_samples_leaf=9;, score=0.779 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, max_features=5, min_samples_leaf=9;, score=0.781 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, max_features=5, min_samples_leaf=11;, score=0.784 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, max_features=5, min_samples_leaf=11;, score=0.781 total time=   1.3s\n",
      "[CV 3/3] END max_depth=5, max_features=5, min_samples_leaf=11;, score=0.783 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, max_features=6, min_samples_leaf=3;, score=0.795 total time=   1.3s\n",
      "[CV 2/3] END max_depth=5, max_features=6, min_samples_leaf=3;, score=0.793 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, max_features=6, min_samples_leaf=3;, score=0.796 total time=   1.3s\n",
      "[CV 1/3] END max_depth=5, max_features=6, min_samples_leaf=5;, score=0.793 total time=   1.4s\n",
      "[CV 2/3] END max_depth=5, max_features=6, min_samples_leaf=5;, score=0.792 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, max_features=6, min_samples_leaf=5;, score=0.795 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, max_features=6, min_samples_leaf=7;, score=0.798 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, max_features=6, min_samples_leaf=7;, score=0.794 total time=   1.2s\n",
      "[CV 3/3] END max_depth=5, max_features=6, min_samples_leaf=7;, score=0.795 total time=   1.3s\n",
      "[CV 1/3] END max_depth=5, max_features=6, min_samples_leaf=9;, score=0.796 total time=   1.4s\n",
      "[CV 2/3] END max_depth=5, max_features=6, min_samples_leaf=9;, score=0.795 total time=   1.3s\n",
      "[CV 3/3] END max_depth=5, max_features=6, min_samples_leaf=9;, score=0.795 total time=   1.3s\n",
      "[CV 1/3] END max_depth=5, max_features=6, min_samples_leaf=11;, score=0.795 total time=   1.2s\n",
      "[CV 2/3] END max_depth=5, max_features=6, min_samples_leaf=11;, score=0.798 total time=   1.3s\n",
      "[CV 3/3] END max_depth=5, max_features=6, min_samples_leaf=11;, score=0.795 total time=   1.2s\n",
      "[CV 1/3] END max_depth=5, max_features=7, min_samples_leaf=3;, score=0.798 total time=   1.4s\n",
      "[CV 2/3] END max_depth=5, max_features=7, min_samples_leaf=3;, score=0.801 total time=   1.4s\n",
      "[CV 3/3] END max_depth=5, max_features=7, min_samples_leaf=3;, score=0.794 total time=   1.4s\n",
      "[CV 1/3] END max_depth=5, max_features=7, min_samples_leaf=5;, score=0.798 total time=   1.4s\n",
      "[CV 2/3] END max_depth=5, max_features=7, min_samples_leaf=5;, score=0.801 total time=   1.4s\n",
      "[CV 3/3] END max_depth=5, max_features=7, min_samples_leaf=5;, score=0.797 total time=   1.5s\n",
      "[CV 1/3] END max_depth=5, max_features=7, min_samples_leaf=7;, score=0.794 total time=   1.5s\n",
      "[CV 2/3] END max_depth=5, max_features=7, min_samples_leaf=7;, score=0.800 total time=   1.4s\n",
      "[CV 3/3] END max_depth=5, max_features=7, min_samples_leaf=7;, score=0.795 total time=   1.4s\n",
      "[CV 1/3] END max_depth=5, max_features=7, min_samples_leaf=9;, score=0.796 total time=   1.3s\n",
      "[CV 2/3] END max_depth=5, max_features=7, min_samples_leaf=9;, score=0.800 total time=   1.4s\n",
      "[CV 3/3] END max_depth=5, max_features=7, min_samples_leaf=9;, score=0.795 total time=   1.4s\n",
      "[CV 1/3] END max_depth=5, max_features=7, min_samples_leaf=11;, score=0.796 total time=   1.4s\n",
      "[CV 2/3] END max_depth=5, max_features=7, min_samples_leaf=11;, score=0.803 total time=   1.5s\n",
      "[CV 3/3] END max_depth=5, max_features=7, min_samples_leaf=11;, score=0.795 total time=   1.5s\n",
      "[CV 1/3] END max_depth=10, max_features=4, min_samples_leaf=3;, score=0.810 total time=   2.0s\n",
      "[CV 2/3] END max_depth=10, max_features=4, min_samples_leaf=3;, score=0.815 total time=   1.9s\n",
      "[CV 3/3] END max_depth=10, max_features=4, min_samples_leaf=3;, score=0.813 total time=   1.9s\n",
      "[CV 1/3] END max_depth=10, max_features=4, min_samples_leaf=5;, score=0.812 total time=   2.1s\n",
      "[CV 2/3] END max_depth=10, max_features=4, min_samples_leaf=5;, score=0.811 total time=   2.0s\n",
      "[CV 3/3] END max_depth=10, max_features=4, min_samples_leaf=5;, score=0.813 total time=   1.9s\n",
      "[CV 1/3] END max_depth=10, max_features=4, min_samples_leaf=7;, score=0.811 total time=   1.9s\n",
      "[CV 2/3] END max_depth=10, max_features=4, min_samples_leaf=7;, score=0.812 total time=   1.9s\n",
      "[CV 3/3] END max_depth=10, max_features=4, min_samples_leaf=7;, score=0.812 total time=   1.9s\n",
      "[CV 1/3] END max_depth=10, max_features=4, min_samples_leaf=9;, score=0.809 total time=   2.0s\n",
      "[CV 2/3] END max_depth=10, max_features=4, min_samples_leaf=9;, score=0.812 total time=   2.0s\n",
      "[CV 3/3] END max_depth=10, max_features=4, min_samples_leaf=9;, score=0.811 total time=   1.9s\n",
      "[CV 1/3] END max_depth=10, max_features=4, min_samples_leaf=11;, score=0.813 total time=   1.8s\n",
      "[CV 2/3] END max_depth=10, max_features=4, min_samples_leaf=11;, score=0.812 total time=   1.8s\n",
      "[CV 3/3] END max_depth=10, max_features=4, min_samples_leaf=11;, score=0.813 total time=   1.8s\n",
      "[CV 1/3] END max_depth=10, max_features=5, min_samples_leaf=3;, score=0.819 total time=   2.1s\n",
      "[CV 2/3] END max_depth=10, max_features=5, min_samples_leaf=3;, score=0.826 total time=   2.2s\n",
      "[CV 3/3] END max_depth=10, max_features=5, min_samples_leaf=3;, score=0.820 total time=   2.2s\n",
      "[CV 1/3] END max_depth=10, max_features=5, min_samples_leaf=5;, score=0.821 total time=   2.1s\n",
      "[CV 2/3] END max_depth=10, max_features=5, min_samples_leaf=5;, score=0.826 total time=   2.1s\n",
      "[CV 3/3] END max_depth=10, max_features=5, min_samples_leaf=5;, score=0.820 total time=   2.3s\n",
      "[CV 1/3] END max_depth=10, max_features=5, min_samples_leaf=7;, score=0.820 total time=   2.1s\n",
      "[CV 2/3] END max_depth=10, max_features=5, min_samples_leaf=7;, score=0.819 total time=   2.0s\n",
      "[CV 3/3] END max_depth=10, max_features=5, min_samples_leaf=7;, score=0.820 total time=   2.1s\n",
      "[CV 1/3] END max_depth=10, max_features=5, min_samples_leaf=9;, score=0.819 total time=   2.0s\n",
      "[CV 2/3] END max_depth=10, max_features=5, min_samples_leaf=9;, score=0.824 total time=   2.0s\n",
      "[CV 3/3] END max_depth=10, max_features=5, min_samples_leaf=9;, score=0.816 total time=   2.1s\n",
      "[CV 1/3] END max_depth=10, max_features=5, min_samples_leaf=11;, score=0.822 total time=   2.1s\n",
      "[CV 2/3] END max_depth=10, max_features=5, min_samples_leaf=11;, score=0.826 total time=   2.6s\n",
      "[CV 3/3] END max_depth=10, max_features=5, min_samples_leaf=11;, score=0.817 total time=   2.1s\n",
      "[CV 1/3] END max_depth=10, max_features=6, min_samples_leaf=3;, score=0.832 total time=   2.5s\n",
      "[CV 2/3] END max_depth=10, max_features=6, min_samples_leaf=3;, score=0.834 total time=   2.5s\n",
      "[CV 3/3] END max_depth=10, max_features=6, min_samples_leaf=3;, score=0.830 total time=   2.7s\n",
      "[CV 1/3] END max_depth=10, max_features=6, min_samples_leaf=5;, score=0.829 total time=   2.4s\n",
      "[CV 2/3] END max_depth=10, max_features=6, min_samples_leaf=5;, score=0.835 total time=   2.4s\n",
      "[CV 3/3] END max_depth=10, max_features=6, min_samples_leaf=5;, score=0.828 total time=   2.4s\n",
      "[CV 1/3] END max_depth=10, max_features=6, min_samples_leaf=7;, score=0.831 total time=   2.5s\n",
      "[CV 2/3] END max_depth=10, max_features=6, min_samples_leaf=7;, score=0.835 total time=   2.3s\n",
      "[CV 3/3] END max_depth=10, max_features=6, min_samples_leaf=7;, score=0.831 total time=   2.3s\n",
      "[CV 1/3] END max_depth=10, max_features=6, min_samples_leaf=9;, score=0.830 total time=   2.3s\n",
      "[CV 2/3] END max_depth=10, max_features=6, min_samples_leaf=9;, score=0.835 total time=   2.3s\n",
      "[CV 3/3] END max_depth=10, max_features=6, min_samples_leaf=9;, score=0.831 total time=   2.4s\n",
      "[CV 1/3] END max_depth=10, max_features=6, min_samples_leaf=11;, score=0.831 total time=   2.3s\n",
      "[CV 2/3] END max_depth=10, max_features=6, min_samples_leaf=11;, score=0.835 total time=   2.3s\n",
      "[CV 3/3] END max_depth=10, max_features=6, min_samples_leaf=11;, score=0.827 total time=   2.4s\n",
      "[CV 1/3] END max_depth=10, max_features=7, min_samples_leaf=3;, score=0.833 total time=   2.7s\n",
      "[CV 2/3] END max_depth=10, max_features=7, min_samples_leaf=3;, score=0.839 total time=   2.9s\n",
      "[CV 3/3] END max_depth=10, max_features=7, min_samples_leaf=3;, score=0.831 total time=   3.1s\n",
      "[CV 1/3] END max_depth=10, max_features=7, min_samples_leaf=5;, score=0.834 total time=   3.1s\n",
      "[CV 2/3] END max_depth=10, max_features=7, min_samples_leaf=5;, score=0.838 total time=   2.8s\n",
      "[CV 3/3] END max_depth=10, max_features=7, min_samples_leaf=5;, score=0.832 total time=   2.8s\n",
      "[CV 1/3] END max_depth=10, max_features=7, min_samples_leaf=7;, score=0.831 total time=   2.8s\n",
      "[CV 2/3] END max_depth=10, max_features=7, min_samples_leaf=7;, score=0.838 total time=   2.9s\n",
      "[CV 3/3] END max_depth=10, max_features=7, min_samples_leaf=7;, score=0.829 total time=   2.8s\n",
      "[CV 1/3] END max_depth=10, max_features=7, min_samples_leaf=9;, score=0.833 total time=   2.8s\n",
      "[CV 2/3] END max_depth=10, max_features=7, min_samples_leaf=9;, score=0.838 total time=   3.0s\n",
      "[CV 3/3] END max_depth=10, max_features=7, min_samples_leaf=9;, score=0.831 total time=   2.9s\n",
      "[CV 1/3] END max_depth=10, max_features=7, min_samples_leaf=11;, score=0.834 total time=   2.8s\n",
      "[CV 2/3] END max_depth=10, max_features=7, min_samples_leaf=11;, score=0.837 total time=   2.8s\n",
      "[CV 3/3] END max_depth=10, max_features=7, min_samples_leaf=11;, score=0.828 total time=   2.8s\n",
      "[CV 1/3] END max_depth=15, max_features=4, min_samples_leaf=3;, score=0.829 total time=   2.9s\n",
      "[CV 2/3] END max_depth=15, max_features=4, min_samples_leaf=3;, score=0.836 total time=   2.8s\n",
      "[CV 3/3] END max_depth=15, max_features=4, min_samples_leaf=3;, score=0.829 total time=   2.9s\n",
      "[CV 1/3] END max_depth=15, max_features=4, min_samples_leaf=5;, score=0.828 total time=   2.7s\n",
      "[CV 2/3] END max_depth=15, max_features=4, min_samples_leaf=5;, score=0.834 total time=   2.8s\n",
      "[CV 3/3] END max_depth=15, max_features=4, min_samples_leaf=5;, score=0.829 total time=   2.8s\n",
      "[CV 1/3] END max_depth=15, max_features=4, min_samples_leaf=7;, score=0.828 total time=   2.7s\n",
      "[CV 2/3] END max_depth=15, max_features=4, min_samples_leaf=7;, score=0.832 total time=   2.6s\n",
      "[CV 3/3] END max_depth=15, max_features=4, min_samples_leaf=7;, score=0.827 total time=   2.6s\n",
      "[CV 1/3] END max_depth=15, max_features=4, min_samples_leaf=9;, score=0.825 total time=   2.7s\n",
      "[CV 2/3] END max_depth=15, max_features=4, min_samples_leaf=9;, score=0.832 total time=   2.6s\n",
      "[CV 3/3] END max_depth=15, max_features=4, min_samples_leaf=9;, score=0.824 total time=   2.7s\n",
      "[CV 1/3] END max_depth=15, max_features=4, min_samples_leaf=11;, score=0.826 total time=   2.5s\n",
      "[CV 2/3] END max_depth=15, max_features=4, min_samples_leaf=11;, score=0.831 total time=   2.4s\n",
      "[CV 3/3] END max_depth=15, max_features=4, min_samples_leaf=11;, score=0.824 total time=   2.5s\n",
      "[CV 1/3] END max_depth=15, max_features=5, min_samples_leaf=3;, score=0.832 total time=   3.2s\n",
      "[CV 2/3] END max_depth=15, max_features=5, min_samples_leaf=3;, score=0.843 total time=   3.6s\n",
      "[CV 3/3] END max_depth=15, max_features=5, min_samples_leaf=3;, score=0.833 total time=   3.3s\n",
      "[CV 1/3] END max_depth=15, max_features=5, min_samples_leaf=5;, score=0.835 total time=   3.6s\n",
      "[CV 2/3] END max_depth=15, max_features=5, min_samples_leaf=5;, score=0.843 total time=   3.3s\n",
      "[CV 3/3] END max_depth=15, max_features=5, min_samples_leaf=5;, score=0.834 total time=   3.2s\n",
      "[CV 1/3] END max_depth=15, max_features=5, min_samples_leaf=7;, score=0.834 total time=   3.3s\n",
      "[CV 2/3] END max_depth=15, max_features=5, min_samples_leaf=7;, score=0.839 total time=   3.0s\n",
      "[CV 3/3] END max_depth=15, max_features=5, min_samples_leaf=7;, score=0.830 total time=   2.9s\n",
      "[CV 1/3] END max_depth=15, max_features=5, min_samples_leaf=9;, score=0.832 total time=   2.9s\n",
      "[CV 2/3] END max_depth=15, max_features=5, min_samples_leaf=9;, score=0.838 total time=   2.8s\n",
      "[CV 3/3] END max_depth=15, max_features=5, min_samples_leaf=9;, score=0.831 total time=   2.8s\n",
      "[CV 1/3] END max_depth=15, max_features=5, min_samples_leaf=11;, score=0.834 total time=   2.7s\n",
      "[CV 2/3] END max_depth=15, max_features=5, min_samples_leaf=11;, score=0.838 total time=   2.7s\n",
      "[CV 3/3] END max_depth=15, max_features=5, min_samples_leaf=11;, score=0.831 total time=   2.8s\n",
      "[CV 1/3] END max_depth=15, max_features=6, min_samples_leaf=3;, score=0.841 total time=   3.4s\n",
      "[CV 2/3] END max_depth=15, max_features=6, min_samples_leaf=3;, score=0.847 total time=   3.4s\n",
      "[CV 3/3] END max_depth=15, max_features=6, min_samples_leaf=3;, score=0.840 total time=   3.4s\n",
      "[CV 1/3] END max_depth=15, max_features=6, min_samples_leaf=5;, score=0.842 total time=   3.3s\n",
      "[CV 2/3] END max_depth=15, max_features=6, min_samples_leaf=5;, score=0.847 total time=   3.3s\n",
      "[CV 3/3] END max_depth=15, max_features=6, min_samples_leaf=5;, score=0.839 total time=   3.3s\n",
      "[CV 1/3] END max_depth=15, max_features=6, min_samples_leaf=7;, score=0.842 total time=   3.4s\n",
      "[CV 2/3] END max_depth=15, max_features=6, min_samples_leaf=7;, score=0.845 total time=   3.3s\n",
      "[CV 3/3] END max_depth=15, max_features=6, min_samples_leaf=7;, score=0.841 total time=   3.2s\n",
      "[CV 1/3] END max_depth=15, max_features=6, min_samples_leaf=9;, score=0.840 total time=   3.3s\n",
      "[CV 2/3] END max_depth=15, max_features=6, min_samples_leaf=9;, score=0.845 total time=   3.2s\n",
      "[CV 3/3] END max_depth=15, max_features=6, min_samples_leaf=9;, score=0.837 total time=   3.2s\n",
      "[CV 1/3] END max_depth=15, max_features=6, min_samples_leaf=11;, score=0.840 total time=   3.2s\n",
      "[CV 2/3] END max_depth=15, max_features=6, min_samples_leaf=11;, score=0.846 total time=   3.2s\n",
      "[CV 3/3] END max_depth=15, max_features=6, min_samples_leaf=11;, score=0.838 total time=   3.2s\n",
      "[CV 1/3] END max_depth=15, max_features=7, min_samples_leaf=3;, score=0.845 total time=   4.0s\n",
      "[CV 2/3] END max_depth=15, max_features=7, min_samples_leaf=3;, score=0.850 total time=   3.8s\n",
      "[CV 3/3] END max_depth=15, max_features=7, min_samples_leaf=3;, score=0.845 total time=   4.0s\n",
      "[CV 1/3] END max_depth=15, max_features=7, min_samples_leaf=5;, score=0.844 total time=   3.8s\n",
      "[CV 2/3] END max_depth=15, max_features=7, min_samples_leaf=5;, score=0.849 total time=   3.7s\n",
      "[CV 3/3] END max_depth=15, max_features=7, min_samples_leaf=5;, score=0.844 total time=   4.0s\n",
      "[CV 1/3] END max_depth=15, max_features=7, min_samples_leaf=7;, score=0.842 total time=   3.9s\n",
      "[CV 2/3] END max_depth=15, max_features=7, min_samples_leaf=7;, score=0.850 total time=   3.9s\n",
      "[CV 3/3] END max_depth=15, max_features=7, min_samples_leaf=7;, score=0.841 total time=   3.9s\n",
      "[CV 1/3] END max_depth=15, max_features=7, min_samples_leaf=9;, score=0.842 total time=   4.3s\n",
      "[CV 2/3] END max_depth=15, max_features=7, min_samples_leaf=9;, score=0.848 total time=   3.7s\n",
      "[CV 3/3] END max_depth=15, max_features=7, min_samples_leaf=9;, score=0.841 total time=   3.8s\n",
      "[CV 1/3] END max_depth=15, max_features=7, min_samples_leaf=11;, score=0.840 total time=   3.7s\n",
      "[CV 2/3] END max_depth=15, max_features=7, min_samples_leaf=11;, score=0.847 total time=   3.8s\n",
      "[CV 3/3] END max_depth=15, max_features=7, min_samples_leaf=11;, score=0.840 total time=   3.9s\n",
      "{'max_depth': 15, 'max_features': 7, 'min_samples_leaf': 3}\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_features': [4, 5, 6, 7],\n",
    "    'min_samples_leaf': [3, 5, 7, 9, 11],\n",
    "    'max_depth': [5, 10, 15]\n",
    "}\n",
    "grid_search_cv = GridSearchCV(ensemble.RandomForestClassifier(random_state=31), params, verbose=3, cv=3)\n",
    "grid_search_cv.fit(X_train, Y_train)\n",
    "print(grid_search_cv.best_params_)\n",
    "clf = ensemble.RandomForestClassifier(max_depth=15, max_features=7, min_samples_leaf=3, random_state=31)\n",
    "clf.fit(X_train, Y_train)\n",
    "preds_train = clf.predict(X_train)\n",
    "preds_test = clf.predict(X_test)\n",
    "print(round(roc_auc_score(Y_test, preds_test), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.12**\n",
    "\n",
    "Как мы говорили в предыдущем юните, благодаря случайному лесу можно узнать, какие признаки оказывают большее влияние на целевую переменную по сравнению с другими.\n",
    "\n",
    "Оцените значимость признаков. Отметьте три признака, которые дают наибольший вклад в целевую переменную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Humidity3pm</td>\n",
       "      <td>0.250783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rainfall</td>\n",
       "      <td>0.079757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Humidity9am</td>\n",
       "      <td>0.070403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cloud9am</td>\n",
       "      <td>0.067092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pressure3pm</td>\n",
       "      <td>0.065272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Location_Newcastle</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Location_SalmonGums</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Location_Nhil</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Location_NorahHead</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Location_GoldCoast</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feat      coef\n",
       "7           Humidity3pm  0.250783\n",
       "2              Rainfall  0.079757\n",
       "6           Humidity9am  0.070403\n",
       "10             Cloud9am  0.067092\n",
       "9           Pressure3pm  0.065272\n",
       "..                  ...       ...\n",
       "50   Location_Newcastle  0.000000\n",
       "62  Location_SalmonGums  0.000000\n",
       "51        Location_Nhil  0.000000\n",
       "52   Location_NorahHead  0.000000\n",
       "40   Location_GoldCoast  0.000000\n",
       "\n",
       "[123 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = [x for x in df_dummies if x != 'RainTomorrow']\n",
    "pd.DataFrame({'feat': feature_names,\n",
    "    'coef': clf.feature_importances_}).sort_values(by='coef', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Итак, вы потренировались решать задачу классификации с помощью случайного леса, рассмотрели на практике некоторые важные свойства этого ансамбля и узнали, от каких факторов зависит, будет ли завтра дождь — весьма полезная информация.\n",
    "\n",
    "Однако, как вы помните, случайный лес — это не единственный вид ансамблей. Уже в следующем юните мы продолжим наше погружение в этот класс алгоритмов и изучим бустинг →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Бустинг"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущих юнитах мы познакомились с одним из видов ансамблевых методов — бэггингом. Пришло время поговорить ещё об одном типе ансамблей — бустинге.\n",
    "\n",
    "В целом, идеи бустинга и бэггинга очень похожи: в обоих случаях мы берём слабые модели и объединяем их для получения более качественного прогноза. Однако есть одно ключевое различие:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_1.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **бэггинге** все модели обучаются одновременно, независимо и параллельно. В качестве итогового предсказания берётся усреднённый ответ (в задаче регрессии) или делается прогноз по большинству голосов (в задаче классификации)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В **бустинге** все модели обучаются поочерёдно, причём каждая последующая старается исправить ошибки, совершённые предыдущими."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере ниже гольфист сначала пытается забить мяч в лунку в точкe y, но добирается только до координаты f_1 (x). Здесь отверстие в точке y является целевой переменной. После переоценки направления и расстояния до лунки после каждого удара игрок несколько раз бьёт по мячу, более мягко направляя его к лунке, и так до тех пор, пока не попадёт в лунку."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_2.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная концепция бустинга вам знакома, поэтому перейдём к его математической составляющей, но прежде необходимо вспомнить ещё одну особенность бустинга ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.1**\n",
    "\n",
    "Можем ли мы использовать в бустинге модели разных типов, например три логистических регрессии, затем четыре дерева решений, а потом KNN?\n",
    "\n",
    "Ответ:Не можем ни при каких условиях.  \n",
    "Верно:В бустинге мы никогда не можем использовать модели разных типов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем перейти к рассмотрению вариаций бустинга и их математической основы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый ансамбль типа бустинг, который мы рассмотрим, называется **AdaBoost (Adaptive Boosting**).\n",
    "\n",
    "**Бустинг** позволяет из большого количества относительно слабых и простых моделей получить одну сильную. В нашем случае будут рассматриваться деревья решений ограниченной глубины (всего из одного уровня) — их ещё называют **пнями**.\n",
    "\n",
    "Для начала давайте вспомним общую логику реализации данного алгоритма, а уже потом сформулируем его математически.\n",
    "\n",
    "Представим, что у нас есть изначальные данные двух классов: здоровые пациенты (обозначены минусом) и пациенты с диагностированным заболеванием (обозначены плюсом). Мы пытаемся решить задачу классификации. Как можно видеть на графиках ниже, результат первой слабой модели не очень удачный:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_3.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда мы пересчитываем коэффициенты таким образом, чтобы уделить больше всего внимания именно тем наблюдениям, прогнозы для которых были сформированы неверно. На схеме ниже некоторые плюсы и минусы увеличились в размере — это иллюстрирует то, что мы увеличили их веса. После этого мы берём очередную слабую модель и строим новое предсказание (оно справа):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_4.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, результат получился снова не очень хорошим, однако он нивелировал некоторые ошибки, допущенные первым классификатором.  После двух итераций итог следующий:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_5.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь f(x) и g(x) — результаты применения алгоритмов классификации.\n",
    "\n",
    "То, что находится в цветной зоне, мы уже с достаточно высокой точностью можем отнести к верному классу. Однако нам необходимо повторять подключение новых моделей, чтобы классифицировать остальные объекты.\n",
    "\n",
    "Добавляя новые пни, мы в итоге можем добиться достаточно качественного разбиения спустя 30 итераций:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_6.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы повторили смысл алгоритма AdaBoost, давайте обратимся к его математической составляющей и пропишем сам алгоритм:\n",
    "\n",
    "1. Инициализируем веса объектов:\n",
    "\n",
    "$w_{j}=\\frac{1}{N}, j=1,2, \\ldots, N$\n",
    "\n",
    "2. Для всех $i$ от 1 до $K$ (если у нас $K$ базовых моделей):\n",
    "\n",
    "    2.1. Строим классификатор $a_i(x)$, используя веса $w_j$.\n",
    "\n",
    "    2.2. Вычисляем ошибку:\n",
    "\n",
    "    $\\operatorname{err}_{i}=\\sum_{j=1}^{N} w_{j}\\left[y_{j} \\neq a_{i}\\left(x_{j}\\right)\\right]$\n",
    "\n",
    "    2.3. Вычисляем вес нового алгоритма:\n",
    "\n",
    "    $c_{i}=\\frac{1}{2} \\ln \\frac{1-e r r_{i}}{e r r_{i}}$\n",
    "\n",
    "    2.4. Получаем новые веса объектов (классы определяются как -1 и +1):\n",
    "\n",
    "    $w_{j} \\leftarrow w_{j} \\cdot \\exp \\left(c_{i}\\left[y_{j} \\neq a_{i}\\left(x_{j}\\right)\\right]\\right), j=1, \\ldots, N$\n",
    "\n",
    "    2.5. Нормируем веса объектов:\n",
    "\n",
    "    $w_{j} \\longleftarrow \\frac{w_{j}}{\\sum_{j=1}^{N} w_{j}}$\n",
    "\n",
    "3. Группируем полученные модели:\n",
    "\n",
    "$f_{K}(x)=\\operatorname{sign}\\left[\\sum_{i=1}^{K} c_{i} a_{i}(x)\\right]$\n",
    "\n",
    "**Примечание**. sign — это функция знака, которая извлекает знак действительного числа. Определяется следующим образом:\n",
    "\n",
    "$ \\operatorname{sign}(x)=\\left\\{\\begin{aligned} 1, & x>0 \\\\ 0, & x=0 \\\\-1, & x<0 \\end{aligned}\\right. $\n",
    "\n",
    "Для лучшего понимания рассмотрим работу алгоритма на «игрушечном» примере ↓\n",
    "\n",
    "Допустим, у нас есть некоторый набор данных, на котором мы решаем задачу кредитного скоринга:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-8.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь есть три бинарных признака $(x_1, x_2, x_3)$ и бинарная целевая переменная $y$:\n",
    "\n",
    "бинарная целевая переменная y означает, вернёт ли клиент кредит (1 — вернёт, 0 — не вернёт);\n",
    "три бинарных признака $x_1, x_2, x_3$ означают характеристики клиента: есть ли у него залоговая недвижимость, долги по кредитам, постоянная работа.\n",
    "Первоначально все объекты данных будут иметь одинаковый вес w:\n",
    "\n",
    "$w_{j}=\\frac{1}{N}, j=1,2, \\ldots, N,$    \n",
    "где $N$ — общее количество объектов.\n",
    "\n",
    "Можно обобщить всё в одну таблицу:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-9.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее необходимо вычислить, например, значение критерия Джини, чтобы определить, какую переменную использовать для создания первого пня (так как этот коэффициент используется в деревьях решений как критерий качества разбиения). Напомним, что формула критерия Джини выражается следующим образом:\n",
    "\n",
    "$H(Q)=\\sum_{k=0}^{K} P_{k}\\left(1-P_{k}\\right)$,  \n",
    "где $Q=\\{(x, y)\\}$ — обучающая выборка, $P_k$ — вероятность принадлежности к классу $k$, $K$ — количество классов (у нас $K=2$).\n",
    "\n",
    "Преобразуем формулу для нашего случая:\n",
    "\n",
    "$\\begin{aligned} & H(Q)=\\sum_{k=0}^{K} P_{k}\\left(1-P_{k}\\right)=P_{0}\\left(1-P_{0}\\right)+P_{1}\\left(1-P_{1}\\right) \\\\=& P_{0}-\\left(P_{0}\\right)^{2}+P_{1}-\\left(P_{1}\\right)^{2}=1-\\left(P_{0}\\right)^{2}-\\left(P_{1}\\right)^{2} \\end{aligned}$\n",
    "\n",
    "Здесь:  \n",
    "$P_1$ — вероятность принадлежности к классу 1;\n",
    "$P_0$ — вероятность принадлежности к классу  0.\n",
    "\n",
    "После того как вычислен критерий Джини для каждой вершины, **взвешенная неоднородность вычисляется как средневзвешенное значение**.\n",
    "\n",
    "Рассмотрим вычисление критерия на примере решающего правила $[x_2 \\leq 0.5]$. Так как уникальных значений в признаке $x_2$ всего два — 0 и 1, то это решающее правило будет разделять объекты на две категории: ту, для которой $x_2=0$, и ту, для которой $x_2=1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_7.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выше приведена сводная таблица объектов, в которой показано количество наблюдений, попадающих в каждую категорию.\n",
    "\n",
    "Далее мы можем вычислить критерий Джини каждого значения признака $x_2$:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_8.png\" alt=\"drawing\" width=\"550\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного поясним вычисления. Для значения $x_2 = 1$ один раз встречается единица и три раза — ноль, поэтому общее количество элементарных исходов равняется четырём. Мы можем рассчитать вероятности появления единицы и нуля. Ровно то же самое можно сделать и для $x_2 = 0$.\n",
    "\n",
    "После вычисления критерия Джини для каждого значения можно вычислить взвешенную неоднородность, взяв средневзвешенное значение двух критериев:\n",
    "\n",
    "$G = 0.375 \\left (\\frac{4}{4+2}  \\right ) + 0 \\left (\\frac{2}{4+2}  \\right )$\n",
    "$G = 0.25$\n",
    "\n",
    "Получаем, что значение взвешенной неоднородности G при разделении по предикату $[x_2 \\leq 0.5]$ равно 0.25.\n",
    "\n",
    "Вы можете проделать тот же путь для каждого признака и в итоге получите, что у признака $x_2$ будет наименьшее значение взвешенной неоднородности. Это значит, именно $x_2$ будет использоваться для создания первого пня."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы будем использовать общую ошибку, чтобы вычислить вес, который получает этот пень. Общая ошибка равна сумме весов неправильно классифицированных объектов. Тогда получается, что если алгоритм классифицировал первый объект неверно, а остальные — верно, то суммарная ошибка в нашем случае равна 1/6.\n",
    "\n",
    "Так как мы узнали ошибку, то можем рассчитать вес нового алгоритма:\n",
    "\n",
    "$c_{i}=\\frac{1}{2} \\ln \\frac{1-e r r_{i}}{e r r_{i}}$\n",
    "\n",
    "В нашем случае:\n",
    "\n",
    "$\\frac{1}{2} \\ln \\left(\\frac{1-\\frac{1}{6}}{\\frac{1}{6}}\\right)=0.35$\n",
    "\n",
    "Далее мы увеличиваем веса объектов, которые были неправильно классифицированы, и уменьшаем веса объектов, которые были классифицированы правильно, используя следующее правило:\n",
    "\n",
    "$w_{j} \\leftarrow w_{j} \\cdot \\exp \\left(c_{i}\\left[y_{j} \\neq a_{i}\\left(x_{j}\\right)\\right]\\right), j=1, \\ldots, N$\n",
    "\n",
    "Веса нормализуются, чтобы в сумме давать единицу:\n",
    "\n",
    "$w_i \\leftarrow \\frac{w_i}{\\sum_{j=1}^{N} w_i}$\n",
    "\n",
    "В результате получаем следующие данные:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-10.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, мы смогли рассчитать новые веса выборки. Поскольку сумма весов равняется 0.84, мы нормализовали веса выборки, разделив каждый вес на 0.84, чтобы сумма новых весов выборки равнялась 1.\n",
    "\n",
    "Теперь мы формируем новую выборку такого же объёма с повтором.\n",
    "\n",
    "Обратите внимание, что объект, который был классифицирован неправильно, имеет вес, более чем в два раза превышающий вес других объектов. Это означает, что он с большей вероятностью будет выбран несколько раз, и, таким образом, следующий пень будет больше сосредоточен на правильной классификации неправильно классифицированного образца. В этом и состоит идея AdaBoost.\n",
    "\n",
    "Для того чтобы классифицировать новую точку, мы узнаём предсказание для неё на каждом пне. Затем количество голосов за каждый класс суммируется, и класс с наибольшим количеством голосов становится меткой нашей точки.\n",
    "\n",
    "Итак, мы разобрались с **AdaBoost**. **Преимущества и недостатки этого алгоритма** мы изучали, когда только начинали знакомство ним. Давайте вспомним их ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\happy-icon.png\" alt=\"drawing\" width=\"50\"/> \n",
    "\n",
    "- Может идентифицировать шумовые объекты. \n",
    "- Накладные расходы минимальны (время построения AdaBoost определяется временем построения базовых моделей).  \n",
    "- Показывает хорошую обобщающую способность.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\sad-icon.png\" alt=\"drawing\" width=\"50\"/> \n",
    "\n",
    "- Жадное добавление алгоритмов приводит к неоптимальности композиции. \n",
    "- Склонен к переобучению при наличии шума в данных. \n",
    "- Не подкреплён математическим обоснованием.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ГРАДИЕНТНЫЙ БУСТИНГ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переходим к следующему алгоритму, который очень популярен благодаря своей высокой эффективности, — к **градиентному бустингу**.\n",
    "\n",
    "Принцип его работы аналогичен AdaBoost: следующие модели улучшают композицию построенных ранее.\n",
    "\n",
    "Пусть у нас есть некоторая функция потерь $L(y, \\hat{y})$. Она зависит от двух аргументов: y  — истинный ответ, $\\hat{y} = a(x)$ — прогноз модели. \n",
    "\n",
    "Для задачи регрессии это может быть, например, квадратичная ошибка\n",
    "\n",
    "$L(y, \\hat{y})=(y-\\hat{y})^{2}$,\n",
    "\n",
    "а для задачи классификации — логистическая функция потерь (классы определяются как 0 и 1):\n",
    "\n",
    "$-\\frac{1}{N}\\sum^N_{i=1} = y_i \\cdot\\log{p(y_i)} + (1 - y_i) \\cdot\\log{(1 - p(y_i))}$,   \n",
    "где $N$ — количество элементов в выборке, $y_i$ — метка класса, а $p(y_i)$ — предсказанная вероятность этого класса.\n",
    "\n",
    "Пусть к некоторому моменту обучены $K-1$ алгоритмов $a_1 (x), ..., a_{K-1}(x)$, то есть композиция имеет вид:\n",
    "\n",
    "$f_{K-1}(x)=\\sum_{i=1}^{K-1} a_{i}(x)$\n",
    "\n",
    "Теперь добавляем в композицию ещё один алгоритм — $a_K (x)$. Этот алгоритм обучается так, чтобы как можно сильнее уменьшить ошибку композиции на обучающей выборке:\n",
    "\n",
    "$\\sum_{j=1}^{N} L\\left(y_{j}, f_{K-1}\\left(x_{j}\\right)+a_k\\left(x_{j}\\right)\\right) \\rightarrow \\min _{a_k}$\n",
    "\n",
    "Для того чтобы найти a_K, минимизирующее функционал, задачу разбивают на две подзадачи:\n",
    "\n",
    "1. На первом этапе определяем, какие значения $s_1, ..., s_N$ должен принимать алгоритм $a_K (x_j) = s_j$, чтобы на объектах обучающей выборки ошибка была минимальной. Формально это можно представить так:\n",
    "\n",
    "$F(s)=\\sum_{j=1}^{N} L\\left(y_{j}, a_{K-1}\\left(x_{j}\\right)+s_{j}\\right) \\rightarrow \\min _{s}$,\n",
    "где $s = (s_1, ..., s_n)$.\n",
    "\n",
    "Иными словами, необходимо найти такой вектор сдвигов $s$, который будет минимизировать функцию $F(s)$.\n",
    "\n",
    "Вы, вероятно, помните, что направление наискорейшего убывания функции — это антиградиент, так что берём его в качестве вектора $s$:\n",
    "\n",
    "$s=-\\nabla F=\\left[\\begin{array}{c}-L_{\\hat{y}}^{\\prime}\\left(y_{1}, a_{K-1}\\left(x_{1}\\right)\\right) \\\\ -L_{\\hat{y}}^{\\prime}\\left(y_{2}, a_{K-1}\\left(x_{2}\\right)\\right) \\\\ \\vdots \\\\ -L_{\\hat{y}}^{\\prime}\\left(y_{N}, a_{K-1}\\left(x_{N}\\right)\\right)\\end{array}\\right]$\n",
    "\n",
    "Компоненты данного вектора — это те значения, которые должен принимать алгоритм $a_K (x)$ на объектах обучающей выборки, чтобы итоговая ошибка композиции была как можно меньше.\n",
    "\n",
    "2. Второй этап — построение такого алгоритма $a_K (x)$. По сути, задача построения алгоритма $a_K (x)$ — это обычная задача регрессии на размеченных данных. В данном случае у нас есть обучающая выборка $(x_j, s_j)^N_{j=1}$ — нам просто нужно предсказать значения вектора s. Например, используем квадратичную функцию потерь:\n",
    "\n",
    "$a_{K}(x)=\\arg \\min _{a} \\frac{1}{N} \\sum_{j=1}^{N}\\left(a\\left(x_{j}\\right)-s_{j}\\right)^{2}$\n",
    "\n",
    "Запишем **последовательность шагов реализации алгоритма**, которую можно запрограммировать:\n",
    "\n",
    "1. Инициализируем композицию GBM (Gradient Boosting Machine) — $f(x) = a_0 (x)$, то есть добавляем первый базовый алгоритм. Например, можно использовать:\n",
    "\n",
    "алгоритм $a_0 (x) = 0$, который всегда возвращает 0 (в задаче регрессии);\n",
    "более сложный алгоритм $a_0 (x) = \\frac{1}{N} \\sum_{j=1}^N y_i$, который возвращает средний истинный ответ по всем элементам обучающей выборки (в задаче регрессии);\n",
    "алгоритм $a_0 (x) = arg \\ max_{y \\in Y} \\sum_{j=1}^N \\left [y_i = y  \\right ]$, который всегда возвращает метку самого распространённого класса в обучающей выборке (в задаче классификации).\n",
    "\n",
    "2. Итеративно повторяем следующие три шага:\n",
    "\n",
    "2.1. Вычисляем вектор сдвига:\n",
    "\n",
    "$s=-\\nabla F=\\left[\\begin{array}{c}-L_{\\hat{y}}^{\\prime}\\left(y_{1}, a_{K-1}\\left(x_{1}\\right)\\right) \\\\ -L_{\\hat{y}}^{\\prime}\\left(y_{2}, a_{K-1}\\left(x_{2}\\right)\\right) \\\\ \\vdots \\\\ -L_{\\hat{y}}^{\\prime}\\left(y_{N}, a_{K-1}\\left(x_{N}\\right)\\right)\\end{array}\\right]$\n",
    "\n",
    "2.2. Строим очередной базовый алгоритм $a_K (x)$, который предсказывает вектор-сдвиг:\n",
    "\n",
    "$a_{K}(x)=\\arg \\min _{a} \\frac{1}{N} \\sum_{j=1}^{N}\\left(a\\left(x_{j}\\right)-s_{j}\\right)^{2}$\n",
    "\n",
    "2.3. Добавляем $a_K (x)$ в композицию:\n",
    "\n",
    "$a_{K}(x)=\\sum_{i=1}^{K} a_{i}(x)$\n",
    "\n",
    "3. Если выполнен критерий остановки, останавливаем итеративный процесс.\n",
    "\n",
    "Давайте рассмотрим алгоритм на простейшем примере, чтобы лучше усвоить все шаги ↓"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-11.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать данную задачу с помощью градиентного бустинга над решающими деревьями.\n",
    "\n",
    "Для начала, в соответствии с описанным выше алгоритмом, нам необходимо инициализировать GBM базовым алгоритмом. Сделаем это с помощью среднего значения целевой переменной."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-12.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему именно с помощью среднего значения, а не другого константного? Дело в том, что именно в среднем будет минимальное значение функции потерь. Давайте это докажем.\n",
    "\n",
    "Так как мы решаем задачу регрессии, то возьмём классическую для этого случая метрику MSE:\n",
    "\n",
    "$L(y, \\ \\hat{y})=\\frac{1}{N} \\sum_{i}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}$\n",
    "\n",
    "Чтобы найти минимум, необходимо найти производную — вам это уже известно из модулей по математическому анализу. Производная:\n",
    "\n",
    "$\\frac{\\mathrm{dL}}{\\mathrm{d} \\hat{y}}=\\frac{2}{2}\\left(\\sum_{i=0}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)\\right)=-\\sum_{i=0}^{N}\\left(y_{i}-\\hat{y}_{i}\\right)$\n",
    "\n",
    "Мы видим, что здесь антиградиентом является разница между реальным значением функции и предсказываемым — обычно эту разницу называют **псевдоостатками**.\n",
    "\n",
    "Если мы подставим значения из нашего примера, результат будет следующим:\n",
    "\n",
    "$L=\\frac{1}{2}(12000-\\hat{y})^{2}+\\frac{1}{2}(16500-\\hat{y})^{2}+\\frac{1}{2}(15500-\\hat{y})^{2} +\\frac{1}{2}(14000-\\hat{y})^{2}$  \n",
    "$\\frac{d \\mathrm{~L}}{d \\hat{y}}=\\frac{2}{2}(12000-\\hat{y})(-1)+\\frac{2}{2}(16500-\\hat{y})(-1)+\\frac{2}{2}(15500-\\hat{y})(-1)+\\frac{2}{2}(14000-\\hat{y})(-1)$  \n",
    "$-(12000-\\hat{y}+16500-\\hat{y}+15500-\\hat{y}+14000-\\hat{y})=0$  \n",
    "$(58000-4 \\hat{y})=0$  \n",
    "$(58000=4 \\hat{y})$  \n",
    "$\\hat{y}=\\frac{58000}{4}=14500$  \n",
    "\n",
    "Собственно, мы получили как раз среднее арифметическое.\n",
    "\n",
    "Далее вычисляем псевдоостатки:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-13.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующем шаге мы строим регрессионную модель, которая будет предсказывать псевдоостатки.\n",
    "\n",
    "Находим значения для всех листьев нашего дерева решений. Предположим, дерево получилось таким:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_9.png\" alt=\"drawing\" width=\"550\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно оставить в каждом листе по одному значению, которое будет минимизировать функцию: это либо сам остаток, либо среднее арифметическое чисел, если в листе их несколько.\n",
    "\n",
    "Мы берём именно эти значения, так как нам необходимо минимизировать разницу между реальной ценой и предсказанием. В алгоритме градиентного бустинга выше мы прописывали, что таким образом мы будем строить очередной базовый алгоритм, предсказывающий вектор-сдвиг:\n",
    "\n",
    "$\\hat{y}_{1,1}=\\operatorname{argmin} (12000-(14500+\\hat{y}))^{2}$  \n",
    "$\\hat{y}_{1,1}=\\operatorname{argmin} (-2500-\\hat{y})^{2}$  \n",
    "\n",
    "Скорее всего, из модуля по математическому анализу вы помните, что для того, чтобы найти точку минимума функции, необходимо приравнять значение производной к нулю. Давайте сделаем это:\n",
    "\n",
    "$\\frac{d}{d \\hat{y}}(-2500-\\hat{y})^{2}=0$  \n",
    "$-2500-\\hat{y}=0$  \n",
    "$\\hat{y}=-2500$   \n",
    "\n",
    "Для второго листа:\n",
    "\n",
    "$\\hat{y}_{2,1}=\\operatorname{argmin}\\left[(16500-(14500+\\hat{y}))^{2}+(15500-(14500+\\hat{y}))^{2}\\right]$  \n",
    "$\\hat{y}_{2,1}=\\operatorname{argmin}\\left[(2000-\\hat{y})^{2}+(1000-\\hat{y})^{2}\\right]$  \n",
    "$\\frac{d}{d \\hat{y}}\\left[(2000-\\hat{y})^{2}+\\left(1000-\\hat{y}^{2}\\right)]=0\\right.$  \n",
    "$2000-\\hat{y}+1000-\\hat{y}=0$  \n",
    "$3000-2 \\hat{y}=0$  \n",
    "$\\frac{3000}{2}=\\hat{y}$  \n",
    "$\\hat{y}=1500$  \n",
    "\n",
    "Для третьего листа:\n",
    "\n",
    "$\\hat{y}_{1,1}=\\operatorname{argmin}(12000-(14500+\\hat{y}))^{2}$  \n",
    "$\\hat{y}_{1,1}=\\operatorname{argmin}(-2500-\\hat{y})^{2}$  \n",
    "$\\frac{d}{d \\hat{y}}(-500-\\hat{y})^{2}=0$  \n",
    "$-500-\\hat{y}=0$  \n",
    "$\\hat{y}=-500$  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_10.png\" alt=\"drawing\" width=\"550\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, наконец, обновляем нашу модель:\n",
    "\n",
    "$f_{K+1}(x)=f_{K}(x)+\\eta a(x)$\n",
    "\n",
    "За $\\eta$ здесь обозначен темп обучения.\n",
    "\n",
    "По сути, у нас получился уже известный вам алгоритм градиентного спуска, который реализован в пространстве ответов ансамбля.\n",
    "\n",
    "Схематично это можно изобразить так:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_5_10.png\" alt=\"drawing\" width=\"550\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы продолжаем повторять аналогичную процедуру, достраивая новые деревья в модель.\n",
    "\n",
    "Но прежде чем закончить с этим примером, давайте сделаем предсказание хотя бы на такой простой модели. Пусть у нас есть автомобиль, высота которого — 49 и у которого 6 цилиндров. В таком случае мы получаем подходящее для нас значение $\\hat{y}_{2,1} = 1500$ и вычисляем предсказание цены:\n",
    "\n",
    "Цена = 14500 + 0.1*1500 = 14500 + 150 = 14650\n",
    "Но, конечно, это лишь промежуточный результат. В реальности, чтобы прогноз был как можно точнее, должно было бы быть построено ещё много деревьев.\n",
    "\n",
    "Напомним изученные ранее плюсы и минусы бустинга:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\happy-icon.png\" alt=\"drawing\" width=\"50\"/> \n",
    "\n",
    "- модели обучаются последовательно, уточняя друг друга;  \n",
    "- снижается смещение;  \n",
    "- базовые модели — неглубокие деревья.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\sad-icon.png\" alt=\"drawing\" width=\"50\"/> \n",
    "\n",
    "- вычисление плохо параллелится;  \n",
    "- плохо интерпретируемые результаты."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST И CATBOOST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда мы разобрались с градиентным бустингом, необходимо также упомянуть о двух его популярных на данный момент вариациях — **XGBoost** и **CatBoost**.\n",
    "\n",
    "**XGBoost** — одна из самых эффективных реализаций алгоритма Gradient Boosted Trees. Название XGBoost расшифровывается  как eXtreme Gradient Boosting. XGBoost — это улучшение GBM через системную оптимизацию и усовершенствование алгоритма.\n",
    "\n",
    "У XGBoost есть ряд существенных улучшений по сравнению с классической реализацией градиентного бустинга:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\369c74c5-f220-4ee5-8205-e3050fe7430d2.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoost** — это библиотека градиентного бустинга, созданная Яндексом. Её особенность заключается в том, что в ней используются так называемые **небрежные (oblivious) деревья решений**, чтобы «вырастить» сбалансированное дерево.\n",
    "\n",
    "Одно из **главных преимуществ** CatBoost заключается в том, что его можно использовать для данных, где категориальные признаки заранее не были преобразованы.\n",
    "\n",
    "Подробнее узнать о CatBoost можно в видеопрезентации Яндекса https://youtu.be/UYDwhuyWYSo.\n",
    "\n",
    "Итак, мы разобрались с очень важным видом ансамблей — бустингом и рассмотрели несколько его моделей:\n",
    "\n",
    "- AdaBoost — самый простой вариант бустинга;\n",
    "- GBM — классический градиентный бустинг;\n",
    "- XGBoost — улучшенная версия градиентного бустинга;\n",
    "- CatBoost — улучшенная версия градиентного бустинга, адаптированная для работы с категориальными переменными.\n",
    "  \n",
    "Уже в следующем юните мы отработаем полученные знания на практике →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Бустинг. Практика"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущем юните мы разобрали ансамблевый метод под названием бустинг, а также рассмотрели различные его вариации. В этом юните мы решим практический кейс с использованием данного алгоритма, а также сравним изученные модификации бустинга.\n",
    "\n",
    "Мы будем работать c данными, которые содержат результаты опроса клиентов авиакомпании по поводу их удовлетворённости полётом.\n",
    "\n",
    "Нашей задачей будет предсказать удовлетворённость пассажиров.\n",
    "\n",
    "<img src=\"data\\MATHML_md9_6_1.jpg\" alt=\"drawing\" width=\"500\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Признаки в данных\n",
    "\n",
    "Gender — пол пассажира (женский, мужской);  \n",
    "Customer Type — тип клиента (постоянный/непостоянный клиент);  \n",
    "Age — возраст клиента;  \n",
    "Type of Travel — цель перелета (личная/деловая поездка);  \n",
    "Class — туристический класс пассажира (Business, Eco, Eco Plus);  \n",
    "Flight distance — расстояние полета;  \n",
    "Inflight wifi service — уровень удовлетворённости Wi-Fi (0 — не применимо, 1–5);  \n",
    "Departure/Arrival time convenient — уровень удовлетворённости временем отправления и прибытия;  \n",
    "Ease of Online booking — уровень удовлетворённости онлайн-бронированием;  \n",
    "Gate location — уровень удовлетворённости расположением выхода на посадку;  \n",
    "Food and drink — уровень удовлетворённости едой и напитками;  \n",
    "Online boarding — уровень удовлетворённости онлайн-регистрацией;  \n",
    "Seat comfort — уровень удовлетворённости комфортом сидений;  \n",
    "Inflight entertainment — уровень удовлетворённости развлечениями на борту;  \n",
    "On-board service — уровень удовлетворённости сервисом на борту;  \n",
    "Leg room service — уровень удовлетворённости местом для ног;  \n",
    "Baggage handling — уровень удовлетворённости обработкой багажа;  \n",
    "Check-in service — уровень удовлетворённости услугами регистрации;  \n",
    "Inflight service — уровень удовлетворённости обслуживанием во время полёта;  \n",
    "Cleanliness — уровень удовлетворённости чистотой;  \n",
    "Departure Delay in Minutes — задержка при отправлении (в минутах);  \n",
    "Arrival Delay in Minutes — задержка при прибытии (в минутах);  \n",
    "Satisfaction — удовлетворённость авиакомпанией — целевая переменная (satisfaction/neutral/dissatisfaction).  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как выполнить задания, вам необходимо установить несколько библиотек (если они у вас не установлены):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost\n",
    "# !pip install catboost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внимание! Если при открытии данных первый столбец (порядковый номер строки) считался как отдельный признак, удалите его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>...</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70172</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>13</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco Plus</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5047</td>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>110028</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>26</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24026</td>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>119299</td>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>61</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id  Gender      Customer Type  Age   Type of Travel  \\\n",
       "0           0   70172    Male     Loyal Customer   13  Personal Travel   \n",
       "1           1    5047    Male  disloyal Customer   25  Business travel   \n",
       "2           2  110028  Female     Loyal Customer   26  Business travel   \n",
       "3           3   24026  Female     Loyal Customer   25  Business travel   \n",
       "4           4  119299    Male     Loyal Customer   61  Business travel   \n",
       "\n",
       "      Class  Flight Distance  Inflight wifi service  \\\n",
       "0  Eco Plus              460                      3   \n",
       "1  Business              235                      3   \n",
       "2  Business             1142                      2   \n",
       "3  Business              562                      2   \n",
       "4  Business              214                      3   \n",
       "\n",
       "   Departure/Arrival time convenient  ...  Inflight entertainment  \\\n",
       "0                                  4  ...                       5   \n",
       "1                                  2  ...                       1   \n",
       "2                                  2  ...                       5   \n",
       "3                                  5  ...                       2   \n",
       "4                                  3  ...                       3   \n",
       "\n",
       "   On-board service  Leg room service  Baggage handling  Checkin service  \\\n",
       "0                 4                 3                 4                4   \n",
       "1                 1                 5                 3                1   \n",
       "2                 4                 3                 4                4   \n",
       "3                 2                 5                 3                1   \n",
       "4                 3                 4                 4                3   \n",
       "\n",
       "   Inflight service  Cleanliness  Departure Delay in Minutes  \\\n",
       "0                 5            5                          25   \n",
       "1                 4            1                           1   \n",
       "2                 4            5                           0   \n",
       "3                 4            2                          11   \n",
       "4                 3            3                           0   \n",
       "\n",
       "   Arrival Delay in Minutes             satisfaction  \n",
       "0                      18.0  neutral or dissatisfied  \n",
       "1                       6.0  neutral or dissatisfied  \n",
       "2                       0.0                satisfied  \n",
       "3                       9.0  neutral or dissatisfied  \n",
       "4                       0.0                satisfied  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/AirPass.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis = 1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.1**\n",
    "\n",
    "Для начала сделаем небольшую предобработку данных. Сколько всего в данных пропущенных значений?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.2**\n",
    "\n",
    "Теперь давайте избавимся от найденных пропусков. Заполните их все медианными значениями. После этого вычислите среднее арифметическое для признака, отражающего задержку при прибытии в минутах. Ответ округлите до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.133392362180475"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Arrival Delay in Minutes'] = df['Arrival Delay in Minutes'].fillna(df['Arrival Delay in Minutes'].median())\n",
    "df['Arrival Delay in Minutes'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.3**\n",
    "\n",
    "Проведём небольшой разведывательный анализ. Посмотрим, в каких категориях пассажиров превалировали удовлетворённые полетом клиенты.  \n",
    "Совет: для ответов на вопросы попробуйте использовать как вычисления, так и визуализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender  satisfaction           \n",
       "Female  neutral or dissatisfied    29.058554\n",
       "        satisfied                  21.687327\n",
       "Male    neutral or dissatisfied    27.608177\n",
       "        satisfied                  21.645942\n",
       "Name: satisfaction, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Gender')['satisfaction'].value_counts()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type of Travel   satisfaction           \n",
       "Business travel  satisfied                  40.177472\n",
       "                 neutral or dissatisfied    28.785225\n",
       "Personal Travel  neutral or dissatisfied    27.881506\n",
       "                 satisfied                   3.155798\n",
       "Name: satisfaction, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Type of Travel')['satisfaction'].value_counts()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class     satisfaction           \n",
       "Business  satisfied                  33.184478\n",
       "          neutral or dissatisfied    14.614452\n",
       "Eco       neutral or dissatisfied    36.614567\n",
       "          satisfied                   8.374076\n",
       "Eco Plus  neutral or dissatisfied     5.437712\n",
       "          satisfied                   1.774715\n",
       "Name: satisfaction, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Class')['satisfaction'].value_counts()*100/df.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перекодируем часть бинарных признаков, чтобы использовать их при обучении:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['satisfaction'] = df['satisfaction'].map({'neutral or dissatisfied':0 , 'satisfied':1})\n",
    "df['Customer Type'] = df['Customer Type'].map({'Loyal Customer':1, 'disloyal Customer':0})\n",
    "df['Type of Travel'] = df['Type of Travel'].map({'Personal Travel':0, 'Business travel':1})\n",
    "df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.4**\n",
    "\n",
    "Для остальных категориальных признаков создайте dummy-переменные. Сделайте это с помощью функции get_dummies() из библиотеки Pandas, параметры не меняйте. Сколько теперь признаков в данных (включая целевую переменную)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103904, 26)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df)\n",
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.5**\n",
    "\n",
    "Мы практически добрались до обучения модели. Разбейте данные на обучающую и тестовую выборки в соотношении 80/20, параметр random_state = 26. Сколько наблюдений попало в тестовую выборку?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20781,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('satisfaction', axis = 1)\n",
    "y = df['satisfaction']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=26)\n",
    "y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.6**\n",
    "\n",
    "Теперь нам необходимо реализовать масштабирование данных. Для этого обучите на обучающей выборке метод StandardScaler() и с помощью него преобразуйте и обучающую, и тестовую выборки. Не забудьте, что целевую переменную обрабатывать не нужно.\n",
    "\n",
    "Примечание. Отметим, что если бы дальше мы работали только с деревьями, масштабирование бы не требовалось. Однако мы реализуем его, чтобы можно было обучать и другие модели и сравнивать полученные результаты.\n",
    "\n",
    "В качестве ответа введите самое первое значение из матрицы преобразованных признаков тестовой выборки. Округлите значение до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9408251379303"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.7**\n",
    "\n",
    "Перейдём к обучению моделей. В качестве первой модели возьмём самую простую — логистическую регрессию. Мы делаем это для того, чтобы потом сравнивать с ней полученные результаты: так вы сможете выяснить, насколько ансамбли смогут улучшить точность прогноза.\n",
    "\n",
    "Обучите логистическую регрессию с параметрами по умолчанию на наших данных. В качестве ответа введите значение метрики f1_score. Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8546883773161146"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "preds_test = model_lr.predict(X_test)\n",
    "f1_score(preds_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.8**\n",
    "\n",
    "Теперь перейдём к бустингу. Начнём с обучения первой модели — AdaBoost. В качестве базовой модели для неё возьмите решающее дерево с параметром random_state = 26.\n",
    "\n",
    "Обучите AdaBoost, зафиксировав random_state со значением 26 и задав темп обучения 0.01. В качестве ответа введите значение метрики f1_score. Ответ округлите до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9404794558121674"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_ada = AdaBoostClassifier(DecisionTreeClassifier(random_state=26),random_state=26,learning_rate=0.01)\n",
    "model_ada.fit(X_train, y_train)\n",
    "preds_test = model_ada.predict(X_test)\n",
    "f1_score(preds_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.9**\n",
    "\n",
    "Перейдем к следующему алгоритму — градиентному бустингу.\n",
    "\n",
    "Будем настраивать количество деревьев и темп обучения, делая перебор по следующей сетке:\n",
    "\n",
    "    params = {\"n_estimators\":2**np.arange(8), \"learning_rate\":0.1**np.arange(3)}\n",
    "\n",
    "Используйте для поиска оптимальных параметров GridSearchCV, а для ускорения работы алгоритма задайте параметр кросс-валидации, равный 3.\n",
    "\n",
    "Какое наибольшее значение метрики f1_score получилось? Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    "Примечание. Необходимо указать лучший результат в методе GridSearchCV на тренировочных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV 1/3] END .learning_rate=1.0, n_estimators=1;, score=0.873 total time=   0.1s\n",
      "[CV 2/3] END .learning_rate=1.0, n_estimators=1;, score=0.870 total time=   0.1s\n",
      "[CV 3/3] END .learning_rate=1.0, n_estimators=1;, score=0.871 total time=   0.1s\n",
      "[CV 1/3] END .learning_rate=1.0, n_estimators=2;, score=0.880 total time=   0.2s\n",
      "[CV 2/3] END .learning_rate=1.0, n_estimators=2;, score=0.878 total time=   0.2s\n",
      "[CV 3/3] END .learning_rate=1.0, n_estimators=2;, score=0.875 total time=   0.2s\n",
      "[CV 1/3] END .learning_rate=1.0, n_estimators=4;, score=0.901 total time=   0.5s\n",
      "[CV 2/3] END .learning_rate=1.0, n_estimators=4;, score=0.896 total time=   0.4s\n",
      "[CV 3/3] END .learning_rate=1.0, n_estimators=4;, score=0.897 total time=   0.5s\n",
      "[CV 1/3] END .learning_rate=1.0, n_estimators=8;, score=0.920 total time=   1.2s\n",
      "[CV 2/3] END .learning_rate=1.0, n_estimators=8;, score=0.920 total time=   1.1s\n",
      "[CV 3/3] END .learning_rate=1.0, n_estimators=8;, score=0.919 total time=   1.0s\n",
      "[CV 1/3] END learning_rate=1.0, n_estimators=16;, score=0.935 total time=   2.3s\n",
      "[CV 2/3] END learning_rate=1.0, n_estimators=16;, score=0.938 total time=   2.3s\n",
      "[CV 3/3] END learning_rate=1.0, n_estimators=16;, score=0.933 total time=   2.3s\n",
      "[CV 1/3] END learning_rate=1.0, n_estimators=32;, score=0.943 total time=   4.8s\n",
      "[CV 2/3] END learning_rate=1.0, n_estimators=32;, score=0.945 total time=   4.7s\n",
      "[CV 3/3] END learning_rate=1.0, n_estimators=32;, score=0.944 total time=   4.6s\n",
      "[CV 1/3] END learning_rate=1.0, n_estimators=64;, score=0.947 total time=   9.3s\n",
      "[CV 2/3] END learning_rate=1.0, n_estimators=64;, score=0.947 total time=   9.4s\n",
      "[CV 3/3] END learning_rate=1.0, n_estimators=64;, score=0.948 total time=   9.0s\n",
      "[CV 1/3] END learning_rate=1.0, n_estimators=128;, score=0.949 total time=  18.2s\n",
      "[CV 2/3] END learning_rate=1.0, n_estimators=128;, score=0.949 total time=  18.7s\n",
      "[CV 3/3] END learning_rate=1.0, n_estimators=128;, score=0.949 total time=  18.4s\n",
      "[CV 1/3] END .learning_rate=0.1, n_estimators=1;, score=0.000 total time=   0.1s\n",
      "[CV 2/3] END .learning_rate=0.1, n_estimators=1;, score=0.000 total time=   0.1s\n",
      "[CV 3/3] END .learning_rate=0.1, n_estimators=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/3] END .learning_rate=0.1, n_estimators=2;, score=0.765 total time=   0.2s\n",
      "[CV 2/3] END .learning_rate=0.1, n_estimators=2;, score=0.802 total time=   0.2s\n",
      "[CV 3/3] END .learning_rate=0.1, n_estimators=2;, score=0.794 total time=   0.2s\n",
      "[CV 1/3] END .learning_rate=0.1, n_estimators=4;, score=0.880 total time=   0.5s\n",
      "[CV 2/3] END .learning_rate=0.1, n_estimators=4;, score=0.880 total time=   0.5s\n",
      "[CV 3/3] END .learning_rate=0.1, n_estimators=4;, score=0.878 total time=   0.5s\n",
      "[CV 1/3] END .learning_rate=0.1, n_estimators=8;, score=0.881 total time=   1.1s\n",
      "[CV 2/3] END .learning_rate=0.1, n_estimators=8;, score=0.878 total time=   1.1s\n",
      "[CV 3/3] END .learning_rate=0.1, n_estimators=8;, score=0.881 total time=   1.0s\n",
      "[CV 1/3] END learning_rate=0.1, n_estimators=16;, score=0.886 total time=   2.2s\n",
      "[CV 2/3] END learning_rate=0.1, n_estimators=16;, score=0.887 total time=   2.2s\n",
      "[CV 3/3] END learning_rate=0.1, n_estimators=16;, score=0.889 total time=   2.2s\n",
      "[CV 1/3] END learning_rate=0.1, n_estimators=32;, score=0.914 total time=   4.4s\n",
      "[CV 2/3] END learning_rate=0.1, n_estimators=32;, score=0.919 total time=   4.4s\n",
      "[CV 3/3] END learning_rate=0.1, n_estimators=32;, score=0.910 total time=   4.4s\n",
      "[CV 1/3] END learning_rate=0.1, n_estimators=64;, score=0.928 total time=   9.0s\n",
      "[CV 2/3] END learning_rate=0.1, n_estimators=64;, score=0.929 total time=   8.5s\n",
      "[CV 3/3] END learning_rate=0.1, n_estimators=64;, score=0.929 total time=   8.5s\n",
      "[CV 1/3] END learning_rate=0.1, n_estimators=128;, score=0.939 total time=  17.4s\n",
      "[CV 2/3] END learning_rate=0.1, n_estimators=128;, score=0.938 total time=  18.3s\n",
      "[CV 3/3] END learning_rate=0.1, n_estimators=128;, score=0.938 total time=  19.9s\n",
      "[CV 1/3] END learning_rate=0.010000000000000002, n_estimators=1;, score=0.000 total time=   0.1s\n",
      "[CV 2/3] END learning_rate=0.010000000000000002, n_estimators=1;, score=0.000 total time=   0.1s\n",
      "[CV 3/3] END learning_rate=0.010000000000000002, n_estimators=1;, score=0.000 total time=   0.1s\n",
      "[CV 1/3] END learning_rate=0.010000000000000002, n_estimators=2;, score=0.000 total time=   0.2s\n",
      "[CV 2/3] END learning_rate=0.010000000000000002, n_estimators=2;, score=0.000 total time=   0.2s\n",
      "[CV 3/3] END learning_rate=0.010000000000000002, n_estimators=2;, score=0.000 total time=   0.2s\n",
      "[CV 1/3] END learning_rate=0.010000000000000002, n_estimators=4;, score=0.000 total time=   0.5s\n",
      "[CV 2/3] END learning_rate=0.010000000000000002, n_estimators=4;, score=0.000 total time=   0.5s\n",
      "[CV 3/3] END learning_rate=0.010000000000000002, n_estimators=4;, score=0.000 total time=   0.5s\n",
      "[CV 1/3] END learning_rate=0.010000000000000002, n_estimators=8;, score=0.000 total time=   1.0s\n",
      "[CV 2/3] END learning_rate=0.010000000000000002, n_estimators=8;, score=0.000 total time=   1.1s\n",
      "[CV 3/3] END learning_rate=0.010000000000000002, n_estimators=8;, score=0.000 total time=   1.0s\n",
      "[CV 1/3] END learning_rate=0.010000000000000002, n_estimators=16;, score=0.765 total time=   2.1s\n",
      "[CV 2/3] END learning_rate=0.010000000000000002, n_estimators=16;, score=0.802 total time=   2.0s\n",
      "[CV 3/3] END learning_rate=0.010000000000000002, n_estimators=16;, score=0.757 total time=   2.1s\n",
      "[CV 1/3] END learning_rate=0.010000000000000002, n_estimators=32;, score=0.878 total time=   4.5s\n",
      "[CV 2/3] END learning_rate=0.010000000000000002, n_estimators=32;, score=0.860 total time=   4.6s\n",
      "[CV 3/3] END learning_rate=0.010000000000000002, n_estimators=32;, score=0.858 total time=   4.3s\n",
      "[CV 1/3] END learning_rate=0.010000000000000002, n_estimators=64;, score=0.881 total time=   9.3s\n",
      "[CV 2/3] END learning_rate=0.010000000000000002, n_estimators=64;, score=0.877 total time=   8.9s\n",
      "[CV 3/3] END learning_rate=0.010000000000000002, n_estimators=64;, score=0.877 total time=   8.8s\n",
      "[CV 1/3] END learning_rate=0.010000000000000002, n_estimators=128;, score=0.886 total time=  17.8s\n",
      "[CV 2/3] END learning_rate=0.010000000000000002, n_estimators=128;, score=0.886 total time=  18.1s\n",
      "[CV 3/3] END learning_rate=0.010000000000000002, n_estimators=128;, score=0.885 total time=  17.7s\n",
      "Лучшие гиперпараметры: {'learning_rate': 1.0, 'n_estimators': 128}\n",
      "Лучшее значение метрики: 0.9490829205699454\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "model_for_gs = GradientBoostingClassifier()\n",
    "params = {\"n_estimators\":2**np.arange(8), \"learning_rate\":0.1**np.arange(3)}\n",
    "gs = GridSearchCV(model_for_gs,\n",
    "    params,\n",
    "    cv=3,\n",
    "    scoring=make_scorer(f1_score),\n",
    "    verbose=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Лучшие гиперпараметры:\", gs.best_params_)\n",
    "print(\"Лучшее значение метрики:\", gs.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.10**\n",
    "\n",
    "Обучите алгоритм XGBoost. Так как он достаточно мощный «из коробки», определите его с параметрами по умолчанию, только задайте random_state = 26. Какое значение метрики f1_score получилось? Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    "Подсказка. Для того чтобы обучить алгоритм XGBoost для решения задачи классификации, вам понадобится XGBClassifier из библиотеки xgboost, установленной ранее. Вся дальнейшая последовательность действий (обучение модели, предсказание, оценка качества) идентична другим алгоритмам, например логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579785161685312"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model_xgb = XGBClassifier(random_state=26)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "preds_test = model_xgb.predict(X_test)\n",
    "f1_score(preds_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.11**\n",
    "\n",
    "Обучите алгоритм CatBoost. Как и XGBoost, будем обучать его с настройками по умолчанию и заданным random_state = 26. Какое значение метрики f1_score получилось? Ответ округлите до трёх знаков после точки-разделителя.\n",
    "\n",
    "Подсказка. Для того чтобы обучить алгоритм CatBoost, вам понадобится CatBoostClassifier() из библиотеки catboost, установленной ранее. Вся дальнейшая последовательность действий (обучение модели, предсказание, оценка качества) идентична другим алгоритмам, например логистической регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.068023\n",
      "0:\tlearn: 0.6018138\ttotal: 19.1ms\tremaining: 19.1s\n",
      "1:\tlearn: 0.5020760\ttotal: 36.9ms\tremaining: 18.4s\n",
      "2:\tlearn: 0.4472472\ttotal: 60.5ms\tremaining: 20.1s\n",
      "3:\tlearn: 0.4028682\ttotal: 78.9ms\tremaining: 19.7s\n",
      "4:\tlearn: 0.3674730\ttotal: 97.9ms\tremaining: 19.5s\n",
      "5:\tlearn: 0.3397846\ttotal: 116ms\tremaining: 19.2s\n",
      "6:\tlearn: 0.3121210\ttotal: 134ms\tremaining: 19.1s\n",
      "7:\tlearn: 0.2917499\ttotal: 152ms\tremaining: 18.9s\n",
      "8:\tlearn: 0.2749040\ttotal: 169ms\tremaining: 18.7s\n",
      "9:\tlearn: 0.2575190\ttotal: 184ms\tremaining: 18.2s\n",
      "10:\tlearn: 0.2473691\ttotal: 198ms\tremaining: 17.8s\n",
      "11:\tlearn: 0.2377531\ttotal: 213ms\tremaining: 17.5s\n",
      "12:\tlearn: 0.2279311\ttotal: 226ms\tremaining: 17.2s\n",
      "13:\tlearn: 0.2212512\ttotal: 240ms\tremaining: 16.9s\n",
      "14:\tlearn: 0.2100358\ttotal: 254ms\tremaining: 16.7s\n",
      "15:\tlearn: 0.2025732\ttotal: 269ms\tremaining: 16.5s\n",
      "16:\tlearn: 0.1942301\ttotal: 283ms\tremaining: 16.4s\n",
      "17:\tlearn: 0.1877938\ttotal: 298ms\tremaining: 16.3s\n",
      "18:\tlearn: 0.1832380\ttotal: 313ms\tremaining: 16.1s\n",
      "19:\tlearn: 0.1797365\ttotal: 326ms\tremaining: 16s\n",
      "20:\tlearn: 0.1766270\ttotal: 339ms\tremaining: 15.8s\n",
      "21:\tlearn: 0.1724834\ttotal: 353ms\tremaining: 15.7s\n",
      "22:\tlearn: 0.1681076\ttotal: 367ms\tremaining: 15.6s\n",
      "23:\tlearn: 0.1659676\ttotal: 382ms\tremaining: 15.6s\n",
      "24:\tlearn: 0.1636305\ttotal: 398ms\tremaining: 15.5s\n",
      "25:\tlearn: 0.1615297\ttotal: 413ms\tremaining: 15.5s\n",
      "26:\tlearn: 0.1591233\ttotal: 428ms\tremaining: 15.4s\n",
      "27:\tlearn: 0.1572188\ttotal: 443ms\tremaining: 15.4s\n",
      "28:\tlearn: 0.1557161\ttotal: 456ms\tremaining: 15.3s\n",
      "29:\tlearn: 0.1541993\ttotal: 470ms\tremaining: 15.2s\n",
      "30:\tlearn: 0.1527117\ttotal: 485ms\tremaining: 15.2s\n",
      "31:\tlearn: 0.1511750\ttotal: 499ms\tremaining: 15.1s\n",
      "32:\tlearn: 0.1495155\ttotal: 512ms\tremaining: 15s\n",
      "33:\tlearn: 0.1482199\ttotal: 528ms\tremaining: 15s\n",
      "34:\tlearn: 0.1447922\ttotal: 541ms\tremaining: 14.9s\n",
      "35:\tlearn: 0.1437619\ttotal: 555ms\tremaining: 14.9s\n",
      "36:\tlearn: 0.1428307\ttotal: 568ms\tremaining: 14.8s\n",
      "37:\tlearn: 0.1418335\ttotal: 581ms\tremaining: 14.7s\n",
      "38:\tlearn: 0.1405886\ttotal: 596ms\tremaining: 14.7s\n",
      "39:\tlearn: 0.1393059\ttotal: 610ms\tremaining: 14.6s\n",
      "40:\tlearn: 0.1385384\ttotal: 624ms\tremaining: 14.6s\n",
      "41:\tlearn: 0.1375509\ttotal: 639ms\tremaining: 14.6s\n",
      "42:\tlearn: 0.1359835\ttotal: 653ms\tremaining: 14.5s\n",
      "43:\tlearn: 0.1347067\ttotal: 666ms\tremaining: 14.5s\n",
      "44:\tlearn: 0.1327072\ttotal: 680ms\tremaining: 14.4s\n",
      "45:\tlearn: 0.1316580\ttotal: 694ms\tremaining: 14.4s\n",
      "46:\tlearn: 0.1304422\ttotal: 708ms\tremaining: 14.4s\n",
      "47:\tlearn: 0.1299835\ttotal: 722ms\tremaining: 14.3s\n",
      "48:\tlearn: 0.1295421\ttotal: 735ms\tremaining: 14.3s\n",
      "49:\tlearn: 0.1290791\ttotal: 748ms\tremaining: 14.2s\n",
      "50:\tlearn: 0.1285284\ttotal: 761ms\tremaining: 14.2s\n",
      "51:\tlearn: 0.1280241\ttotal: 775ms\tremaining: 14.1s\n",
      "52:\tlearn: 0.1272417\ttotal: 789ms\tremaining: 14.1s\n",
      "53:\tlearn: 0.1265525\ttotal: 804ms\tremaining: 14.1s\n",
      "54:\tlearn: 0.1258800\ttotal: 817ms\tremaining: 14s\n",
      "55:\tlearn: 0.1248607\ttotal: 830ms\tremaining: 14s\n",
      "56:\tlearn: 0.1242196\ttotal: 844ms\tremaining: 14s\n",
      "57:\tlearn: 0.1240464\ttotal: 858ms\tremaining: 13.9s\n",
      "58:\tlearn: 0.1227505\ttotal: 874ms\tremaining: 13.9s\n",
      "59:\tlearn: 0.1219311\ttotal: 888ms\tremaining: 13.9s\n",
      "60:\tlearn: 0.1214669\ttotal: 902ms\tremaining: 13.9s\n",
      "61:\tlearn: 0.1209629\ttotal: 917ms\tremaining: 13.9s\n",
      "62:\tlearn: 0.1204270\ttotal: 930ms\tremaining: 13.8s\n",
      "63:\tlearn: 0.1197952\ttotal: 943ms\tremaining: 13.8s\n",
      "64:\tlearn: 0.1188690\ttotal: 958ms\tremaining: 13.8s\n",
      "65:\tlearn: 0.1179641\ttotal: 971ms\tremaining: 13.7s\n",
      "66:\tlearn: 0.1175382\ttotal: 985ms\tremaining: 13.7s\n",
      "67:\tlearn: 0.1170936\ttotal: 998ms\tremaining: 13.7s\n",
      "68:\tlearn: 0.1167482\ttotal: 1.01s\tremaining: 13.6s\n",
      "69:\tlearn: 0.1164256\ttotal: 1.02s\tremaining: 13.6s\n",
      "70:\tlearn: 0.1161023\ttotal: 1.04s\tremaining: 13.6s\n",
      "71:\tlearn: 0.1154266\ttotal: 1.05s\tremaining: 13.6s\n",
      "72:\tlearn: 0.1143862\ttotal: 1.07s\tremaining: 13.5s\n",
      "73:\tlearn: 0.1141025\ttotal: 1.08s\tremaining: 13.5s\n",
      "74:\tlearn: 0.1138526\ttotal: 1.09s\tremaining: 13.5s\n",
      "75:\tlearn: 0.1134943\ttotal: 1.11s\tremaining: 13.5s\n",
      "76:\tlearn: 0.1132630\ttotal: 1.12s\tremaining: 13.5s\n",
      "77:\tlearn: 0.1129338\ttotal: 1.14s\tremaining: 13.4s\n",
      "78:\tlearn: 0.1123692\ttotal: 1.15s\tremaining: 13.4s\n",
      "79:\tlearn: 0.1120446\ttotal: 1.16s\tremaining: 13.4s\n",
      "80:\tlearn: 0.1117098\ttotal: 1.18s\tremaining: 13.3s\n",
      "81:\tlearn: 0.1108359\ttotal: 1.19s\tremaining: 13.3s\n",
      "82:\tlearn: 0.1102780\ttotal: 1.2s\tremaining: 13.3s\n",
      "83:\tlearn: 0.1099573\ttotal: 1.22s\tremaining: 13.3s\n",
      "84:\tlearn: 0.1098578\ttotal: 1.23s\tremaining: 13.3s\n",
      "85:\tlearn: 0.1092687\ttotal: 1.25s\tremaining: 13.2s\n",
      "86:\tlearn: 0.1090129\ttotal: 1.26s\tremaining: 13.2s\n",
      "87:\tlearn: 0.1087986\ttotal: 1.27s\tremaining: 13.2s\n",
      "88:\tlearn: 0.1081521\ttotal: 1.29s\tremaining: 13.2s\n",
      "89:\tlearn: 0.1079693\ttotal: 1.3s\tremaining: 13.2s\n",
      "90:\tlearn: 0.1077515\ttotal: 1.32s\tremaining: 13.2s\n",
      "91:\tlearn: 0.1075284\ttotal: 1.33s\tremaining: 13.1s\n",
      "92:\tlearn: 0.1071406\ttotal: 1.34s\tremaining: 13.1s\n",
      "93:\tlearn: 0.1070248\ttotal: 1.36s\tremaining: 13.1s\n",
      "94:\tlearn: 0.1068193\ttotal: 1.37s\tremaining: 13.1s\n",
      "95:\tlearn: 0.1064462\ttotal: 1.39s\tremaining: 13.1s\n",
      "96:\tlearn: 0.1059303\ttotal: 1.4s\tremaining: 13s\n",
      "97:\tlearn: 0.1056717\ttotal: 1.42s\tremaining: 13s\n",
      "98:\tlearn: 0.1054191\ttotal: 1.43s\tremaining: 13s\n",
      "99:\tlearn: 0.1051353\ttotal: 1.44s\tremaining: 13s\n",
      "100:\tlearn: 0.1047669\ttotal: 1.45s\tremaining: 12.9s\n",
      "101:\tlearn: 0.1044769\ttotal: 1.47s\tremaining: 12.9s\n",
      "102:\tlearn: 0.1041727\ttotal: 1.48s\tremaining: 12.9s\n",
      "103:\tlearn: 0.1039213\ttotal: 1.5s\tremaining: 12.9s\n",
      "104:\tlearn: 0.1034244\ttotal: 1.51s\tremaining: 12.9s\n",
      "105:\tlearn: 0.1032078\ttotal: 1.52s\tremaining: 12.9s\n",
      "106:\tlearn: 0.1030341\ttotal: 1.54s\tremaining: 12.8s\n",
      "107:\tlearn: 0.1025611\ttotal: 1.55s\tremaining: 12.8s\n",
      "108:\tlearn: 0.1022940\ttotal: 1.57s\tremaining: 12.8s\n",
      "109:\tlearn: 0.1021191\ttotal: 1.58s\tremaining: 12.8s\n",
      "110:\tlearn: 0.1017959\ttotal: 1.59s\tremaining: 12.8s\n",
      "111:\tlearn: 0.1015856\ttotal: 1.61s\tremaining: 12.8s\n",
      "112:\tlearn: 0.1011752\ttotal: 1.62s\tremaining: 12.7s\n",
      "113:\tlearn: 0.1008759\ttotal: 1.64s\tremaining: 12.7s\n",
      "114:\tlearn: 0.1006960\ttotal: 1.65s\tremaining: 12.7s\n",
      "115:\tlearn: 0.1005650\ttotal: 1.66s\tremaining: 12.7s\n",
      "116:\tlearn: 0.1003043\ttotal: 1.68s\tremaining: 12.7s\n",
      "117:\tlearn: 0.1000931\ttotal: 1.69s\tremaining: 12.6s\n",
      "118:\tlearn: 0.0999173\ttotal: 1.71s\tremaining: 12.6s\n",
      "119:\tlearn: 0.0995890\ttotal: 1.73s\tremaining: 12.7s\n",
      "120:\tlearn: 0.0992166\ttotal: 1.74s\tremaining: 12.7s\n",
      "121:\tlearn: 0.0991357\ttotal: 1.76s\tremaining: 12.6s\n",
      "122:\tlearn: 0.0990491\ttotal: 1.77s\tremaining: 12.6s\n",
      "123:\tlearn: 0.0988977\ttotal: 1.78s\tremaining: 12.6s\n",
      "124:\tlearn: 0.0987814\ttotal: 1.8s\tremaining: 12.6s\n",
      "125:\tlearn: 0.0982177\ttotal: 1.81s\tremaining: 12.6s\n",
      "126:\tlearn: 0.0979959\ttotal: 1.82s\tremaining: 12.5s\n",
      "127:\tlearn: 0.0975458\ttotal: 1.84s\tremaining: 12.5s\n",
      "128:\tlearn: 0.0973966\ttotal: 1.85s\tremaining: 12.5s\n",
      "129:\tlearn: 0.0971498\ttotal: 1.87s\tremaining: 12.5s\n",
      "130:\tlearn: 0.0969600\ttotal: 1.88s\tremaining: 12.5s\n",
      "131:\tlearn: 0.0968171\ttotal: 1.89s\tremaining: 12.5s\n",
      "132:\tlearn: 0.0966655\ttotal: 1.91s\tremaining: 12.4s\n",
      "133:\tlearn: 0.0965935\ttotal: 1.92s\tremaining: 12.4s\n",
      "134:\tlearn: 0.0965290\ttotal: 1.94s\tremaining: 12.4s\n",
      "135:\tlearn: 0.0963293\ttotal: 1.95s\tremaining: 12.4s\n",
      "136:\tlearn: 0.0962325\ttotal: 1.96s\tremaining: 12.4s\n",
      "137:\tlearn: 0.0960271\ttotal: 1.98s\tremaining: 12.3s\n",
      "138:\tlearn: 0.0957717\ttotal: 1.99s\tremaining: 12.3s\n",
      "139:\tlearn: 0.0956518\ttotal: 2s\tremaining: 12.3s\n",
      "140:\tlearn: 0.0954566\ttotal: 2.02s\tremaining: 12.3s\n",
      "141:\tlearn: 0.0952811\ttotal: 2.03s\tremaining: 12.3s\n",
      "142:\tlearn: 0.0951755\ttotal: 2.04s\tremaining: 12.3s\n",
      "143:\tlearn: 0.0950737\ttotal: 2.06s\tremaining: 12.2s\n",
      "144:\tlearn: 0.0948309\ttotal: 2.07s\tremaining: 12.2s\n",
      "145:\tlearn: 0.0947880\ttotal: 2.09s\tremaining: 12.2s\n",
      "146:\tlearn: 0.0942155\ttotal: 2.1s\tremaining: 12.2s\n",
      "147:\tlearn: 0.0940962\ttotal: 2.12s\tremaining: 12.2s\n",
      "148:\tlearn: 0.0939183\ttotal: 2.13s\tremaining: 12.2s\n",
      "149:\tlearn: 0.0937727\ttotal: 2.15s\tremaining: 12.2s\n",
      "150:\tlearn: 0.0935927\ttotal: 2.16s\tremaining: 12.2s\n",
      "151:\tlearn: 0.0935436\ttotal: 2.17s\tremaining: 12.1s\n",
      "152:\tlearn: 0.0931701\ttotal: 2.19s\tremaining: 12.1s\n",
      "153:\tlearn: 0.0929398\ttotal: 2.2s\tremaining: 12.1s\n",
      "154:\tlearn: 0.0928262\ttotal: 2.21s\tremaining: 12.1s\n",
      "155:\tlearn: 0.0926361\ttotal: 2.23s\tremaining: 12.1s\n",
      "156:\tlearn: 0.0923514\ttotal: 2.24s\tremaining: 12s\n",
      "157:\tlearn: 0.0922529\ttotal: 2.25s\tremaining: 12s\n",
      "158:\tlearn: 0.0921441\ttotal: 2.27s\tremaining: 12s\n",
      "159:\tlearn: 0.0920109\ttotal: 2.28s\tremaining: 12s\n",
      "160:\tlearn: 0.0918072\ttotal: 2.3s\tremaining: 12s\n",
      "161:\tlearn: 0.0917630\ttotal: 2.31s\tremaining: 12s\n",
      "162:\tlearn: 0.0916563\ttotal: 2.32s\tremaining: 11.9s\n",
      "163:\tlearn: 0.0915353\ttotal: 2.34s\tremaining: 11.9s\n",
      "164:\tlearn: 0.0913332\ttotal: 2.35s\tremaining: 11.9s\n",
      "165:\tlearn: 0.0911235\ttotal: 2.37s\tremaining: 11.9s\n",
      "166:\tlearn: 0.0909360\ttotal: 2.38s\tremaining: 11.9s\n",
      "167:\tlearn: 0.0907373\ttotal: 2.39s\tremaining: 11.9s\n",
      "168:\tlearn: 0.0905480\ttotal: 2.41s\tremaining: 11.8s\n",
      "169:\tlearn: 0.0903470\ttotal: 2.42s\tremaining: 11.8s\n",
      "170:\tlearn: 0.0903090\ttotal: 2.43s\tremaining: 11.8s\n",
      "171:\tlearn: 0.0901973\ttotal: 2.45s\tremaining: 11.8s\n",
      "172:\tlearn: 0.0900302\ttotal: 2.46s\tremaining: 11.8s\n",
      "173:\tlearn: 0.0898935\ttotal: 2.48s\tremaining: 11.8s\n",
      "174:\tlearn: 0.0897223\ttotal: 2.49s\tremaining: 11.7s\n",
      "175:\tlearn: 0.0896837\ttotal: 2.5s\tremaining: 11.7s\n",
      "176:\tlearn: 0.0892261\ttotal: 2.52s\tremaining: 11.7s\n",
      "177:\tlearn: 0.0890884\ttotal: 2.53s\tremaining: 11.7s\n",
      "178:\tlearn: 0.0889683\ttotal: 2.54s\tremaining: 11.7s\n",
      "179:\tlearn: 0.0888734\ttotal: 2.56s\tremaining: 11.6s\n",
      "180:\tlearn: 0.0887797\ttotal: 2.57s\tremaining: 11.6s\n",
      "181:\tlearn: 0.0886890\ttotal: 2.58s\tremaining: 11.6s\n",
      "182:\tlearn: 0.0886169\ttotal: 2.6s\tremaining: 11.6s\n",
      "183:\tlearn: 0.0885335\ttotal: 2.61s\tremaining: 11.6s\n",
      "184:\tlearn: 0.0884627\ttotal: 2.63s\tremaining: 11.6s\n",
      "185:\tlearn: 0.0883685\ttotal: 2.64s\tremaining: 11.6s\n",
      "186:\tlearn: 0.0882691\ttotal: 2.65s\tremaining: 11.5s\n",
      "187:\tlearn: 0.0880897\ttotal: 2.67s\tremaining: 11.5s\n",
      "188:\tlearn: 0.0880304\ttotal: 2.68s\tremaining: 11.5s\n",
      "189:\tlearn: 0.0879233\ttotal: 2.69s\tremaining: 11.5s\n",
      "190:\tlearn: 0.0876441\ttotal: 2.71s\tremaining: 11.5s\n",
      "191:\tlearn: 0.0875253\ttotal: 2.72s\tremaining: 11.5s\n",
      "192:\tlearn: 0.0874791\ttotal: 2.73s\tremaining: 11.4s\n",
      "193:\tlearn: 0.0872907\ttotal: 2.75s\tremaining: 11.4s\n",
      "194:\tlearn: 0.0872521\ttotal: 2.76s\tremaining: 11.4s\n",
      "195:\tlearn: 0.0870328\ttotal: 2.78s\tremaining: 11.4s\n",
      "196:\tlearn: 0.0868901\ttotal: 2.79s\tremaining: 11.4s\n",
      "197:\tlearn: 0.0868130\ttotal: 2.81s\tremaining: 11.4s\n",
      "198:\tlearn: 0.0867343\ttotal: 2.82s\tremaining: 11.3s\n",
      "199:\tlearn: 0.0866017\ttotal: 2.83s\tremaining: 11.3s\n",
      "200:\tlearn: 0.0865260\ttotal: 2.85s\tremaining: 11.3s\n",
      "201:\tlearn: 0.0864278\ttotal: 2.86s\tremaining: 11.3s\n",
      "202:\tlearn: 0.0863128\ttotal: 2.88s\tremaining: 11.3s\n",
      "203:\tlearn: 0.0862006\ttotal: 2.89s\tremaining: 11.3s\n",
      "204:\tlearn: 0.0861286\ttotal: 2.9s\tremaining: 11.3s\n",
      "205:\tlearn: 0.0860501\ttotal: 2.92s\tremaining: 11.2s\n",
      "206:\tlearn: 0.0858724\ttotal: 2.93s\tremaining: 11.2s\n",
      "207:\tlearn: 0.0857589\ttotal: 2.94s\tremaining: 11.2s\n",
      "208:\tlearn: 0.0856918\ttotal: 2.96s\tremaining: 11.2s\n",
      "209:\tlearn: 0.0855529\ttotal: 2.97s\tremaining: 11.2s\n",
      "210:\tlearn: 0.0854904\ttotal: 2.98s\tremaining: 11.2s\n",
      "211:\tlearn: 0.0854201\ttotal: 3s\tremaining: 11.1s\n",
      "212:\tlearn: 0.0853754\ttotal: 3.01s\tremaining: 11.1s\n",
      "213:\tlearn: 0.0853244\ttotal: 3.03s\tremaining: 11.1s\n",
      "214:\tlearn: 0.0852699\ttotal: 3.04s\tremaining: 11.1s\n",
      "215:\tlearn: 0.0852532\ttotal: 3.05s\tremaining: 11.1s\n",
      "216:\tlearn: 0.0852273\ttotal: 3.07s\tremaining: 11.1s\n",
      "217:\tlearn: 0.0851339\ttotal: 3.08s\tremaining: 11.1s\n",
      "218:\tlearn: 0.0850794\ttotal: 3.1s\tremaining: 11s\n",
      "219:\tlearn: 0.0850413\ttotal: 3.11s\tremaining: 11s\n",
      "220:\tlearn: 0.0849353\ttotal: 3.12s\tremaining: 11s\n",
      "221:\tlearn: 0.0848262\ttotal: 3.14s\tremaining: 11s\n",
      "222:\tlearn: 0.0846502\ttotal: 3.15s\tremaining: 11s\n",
      "223:\tlearn: 0.0846198\ttotal: 3.16s\tremaining: 11s\n",
      "224:\tlearn: 0.0843217\ttotal: 3.18s\tremaining: 10.9s\n",
      "225:\tlearn: 0.0841929\ttotal: 3.19s\tremaining: 10.9s\n",
      "226:\tlearn: 0.0841319\ttotal: 3.2s\tremaining: 10.9s\n",
      "227:\tlearn: 0.0840858\ttotal: 3.22s\tremaining: 10.9s\n",
      "228:\tlearn: 0.0839088\ttotal: 3.23s\tremaining: 10.9s\n",
      "229:\tlearn: 0.0838526\ttotal: 3.25s\tremaining: 10.9s\n",
      "230:\tlearn: 0.0837752\ttotal: 3.26s\tremaining: 10.9s\n",
      "231:\tlearn: 0.0836686\ttotal: 3.27s\tremaining: 10.8s\n",
      "232:\tlearn: 0.0836083\ttotal: 3.29s\tremaining: 10.8s\n",
      "233:\tlearn: 0.0835118\ttotal: 3.3s\tremaining: 10.8s\n",
      "234:\tlearn: 0.0834419\ttotal: 3.31s\tremaining: 10.8s\n",
      "235:\tlearn: 0.0833729\ttotal: 3.33s\tremaining: 10.8s\n",
      "236:\tlearn: 0.0832126\ttotal: 3.34s\tremaining: 10.8s\n",
      "237:\tlearn: 0.0831311\ttotal: 3.36s\tremaining: 10.7s\n",
      "238:\tlearn: 0.0830955\ttotal: 3.37s\tremaining: 10.7s\n",
      "239:\tlearn: 0.0830331\ttotal: 3.38s\tremaining: 10.7s\n",
      "240:\tlearn: 0.0829695\ttotal: 3.4s\tremaining: 10.7s\n",
      "241:\tlearn: 0.0829022\ttotal: 3.41s\tremaining: 10.7s\n",
      "242:\tlearn: 0.0828268\ttotal: 3.42s\tremaining: 10.7s\n",
      "243:\tlearn: 0.0827829\ttotal: 3.44s\tremaining: 10.7s\n",
      "244:\tlearn: 0.0827387\ttotal: 3.45s\tremaining: 10.6s\n",
      "245:\tlearn: 0.0826598\ttotal: 3.46s\tremaining: 10.6s\n",
      "246:\tlearn: 0.0825863\ttotal: 3.48s\tremaining: 10.6s\n",
      "247:\tlearn: 0.0825107\ttotal: 3.49s\tremaining: 10.6s\n",
      "248:\tlearn: 0.0824742\ttotal: 3.5s\tremaining: 10.6s\n",
      "249:\tlearn: 0.0824307\ttotal: 3.52s\tremaining: 10.6s\n",
      "250:\tlearn: 0.0824053\ttotal: 3.53s\tremaining: 10.5s\n",
      "251:\tlearn: 0.0823486\ttotal: 3.54s\tremaining: 10.5s\n",
      "252:\tlearn: 0.0822370\ttotal: 3.56s\tremaining: 10.5s\n",
      "253:\tlearn: 0.0821948\ttotal: 3.57s\tremaining: 10.5s\n",
      "254:\tlearn: 0.0821170\ttotal: 3.58s\tremaining: 10.5s\n",
      "255:\tlearn: 0.0820327\ttotal: 3.6s\tremaining: 10.5s\n",
      "256:\tlearn: 0.0819759\ttotal: 3.61s\tremaining: 10.4s\n",
      "257:\tlearn: 0.0818549\ttotal: 3.63s\tremaining: 10.4s\n",
      "258:\tlearn: 0.0817910\ttotal: 3.64s\tremaining: 10.4s\n",
      "259:\tlearn: 0.0817126\ttotal: 3.65s\tremaining: 10.4s\n",
      "260:\tlearn: 0.0816450\ttotal: 3.67s\tremaining: 10.4s\n",
      "261:\tlearn: 0.0815432\ttotal: 3.68s\tremaining: 10.4s\n",
      "262:\tlearn: 0.0814953\ttotal: 3.69s\tremaining: 10.4s\n",
      "263:\tlearn: 0.0814396\ttotal: 3.71s\tremaining: 10.3s\n",
      "264:\tlearn: 0.0814124\ttotal: 3.72s\tremaining: 10.3s\n",
      "265:\tlearn: 0.0814046\ttotal: 3.73s\tremaining: 10.3s\n",
      "266:\tlearn: 0.0812999\ttotal: 3.75s\tremaining: 10.3s\n",
      "267:\tlearn: 0.0812329\ttotal: 3.76s\tremaining: 10.3s\n",
      "268:\tlearn: 0.0812007\ttotal: 3.78s\tremaining: 10.3s\n",
      "269:\tlearn: 0.0810944\ttotal: 3.79s\tremaining: 10.2s\n",
      "270:\tlearn: 0.0810519\ttotal: 3.8s\tremaining: 10.2s\n",
      "271:\tlearn: 0.0809828\ttotal: 3.82s\tremaining: 10.2s\n",
      "272:\tlearn: 0.0809609\ttotal: 3.83s\tremaining: 10.2s\n",
      "273:\tlearn: 0.0808536\ttotal: 3.84s\tremaining: 10.2s\n",
      "274:\tlearn: 0.0807958\ttotal: 3.86s\tremaining: 10.2s\n",
      "275:\tlearn: 0.0807571\ttotal: 3.87s\tremaining: 10.2s\n",
      "276:\tlearn: 0.0806412\ttotal: 3.88s\tremaining: 10.1s\n",
      "277:\tlearn: 0.0805663\ttotal: 3.9s\tremaining: 10.1s\n",
      "278:\tlearn: 0.0804395\ttotal: 3.91s\tremaining: 10.1s\n",
      "279:\tlearn: 0.0803810\ttotal: 3.93s\tremaining: 10.1s\n",
      "280:\tlearn: 0.0802957\ttotal: 3.94s\tremaining: 10.1s\n",
      "281:\tlearn: 0.0802670\ttotal: 3.95s\tremaining: 10.1s\n",
      "282:\tlearn: 0.0802462\ttotal: 3.97s\tremaining: 10.1s\n",
      "283:\tlearn: 0.0801863\ttotal: 3.98s\tremaining: 10s\n",
      "284:\tlearn: 0.0801505\ttotal: 3.99s\tremaining: 10s\n",
      "285:\tlearn: 0.0801227\ttotal: 4.01s\tremaining: 10s\n",
      "286:\tlearn: 0.0801065\ttotal: 4.02s\tremaining: 9.99s\n",
      "287:\tlearn: 0.0800773\ttotal: 4.04s\tremaining: 9.98s\n",
      "288:\tlearn: 0.0799061\ttotal: 4.05s\tremaining: 9.96s\n",
      "289:\tlearn: 0.0797597\ttotal: 4.06s\tremaining: 9.95s\n",
      "290:\tlearn: 0.0797415\ttotal: 4.08s\tremaining: 9.94s\n",
      "291:\tlearn: 0.0797117\ttotal: 4.09s\tremaining: 9.92s\n",
      "292:\tlearn: 0.0796779\ttotal: 4.1s\tremaining: 9.9s\n",
      "293:\tlearn: 0.0796389\ttotal: 4.12s\tremaining: 9.89s\n",
      "294:\tlearn: 0.0795364\ttotal: 4.13s\tremaining: 9.88s\n",
      "295:\tlearn: 0.0794908\ttotal: 4.15s\tremaining: 9.86s\n",
      "296:\tlearn: 0.0794599\ttotal: 4.16s\tremaining: 9.85s\n",
      "297:\tlearn: 0.0793930\ttotal: 4.17s\tremaining: 9.83s\n",
      "298:\tlearn: 0.0793129\ttotal: 4.19s\tremaining: 9.82s\n",
      "299:\tlearn: 0.0792353\ttotal: 4.2s\tremaining: 9.8s\n",
      "300:\tlearn: 0.0790519\ttotal: 4.22s\tremaining: 9.79s\n",
      "301:\tlearn: 0.0789589\ttotal: 4.23s\tremaining: 9.78s\n",
      "302:\tlearn: 0.0788837\ttotal: 4.24s\tremaining: 9.76s\n",
      "303:\tlearn: 0.0788377\ttotal: 4.26s\tremaining: 9.74s\n",
      "304:\tlearn: 0.0787731\ttotal: 4.27s\tremaining: 9.73s\n",
      "305:\tlearn: 0.0787223\ttotal: 4.28s\tremaining: 9.72s\n",
      "306:\tlearn: 0.0786856\ttotal: 4.3s\tremaining: 9.71s\n",
      "307:\tlearn: 0.0786316\ttotal: 4.31s\tremaining: 9.69s\n",
      "308:\tlearn: 0.0785582\ttotal: 4.33s\tremaining: 9.67s\n",
      "309:\tlearn: 0.0785205\ttotal: 4.34s\tremaining: 9.66s\n",
      "310:\tlearn: 0.0784844\ttotal: 4.35s\tremaining: 9.64s\n",
      "311:\tlearn: 0.0784498\ttotal: 4.37s\tremaining: 9.63s\n",
      "312:\tlearn: 0.0784330\ttotal: 4.38s\tremaining: 9.61s\n",
      "313:\tlearn: 0.0783942\ttotal: 4.39s\tremaining: 9.6s\n",
      "314:\tlearn: 0.0783722\ttotal: 4.41s\tremaining: 9.58s\n",
      "315:\tlearn: 0.0782870\ttotal: 4.42s\tremaining: 9.57s\n",
      "316:\tlearn: 0.0782373\ttotal: 4.43s\tremaining: 9.55s\n",
      "317:\tlearn: 0.0782103\ttotal: 4.45s\tremaining: 9.54s\n",
      "318:\tlearn: 0.0781664\ttotal: 4.46s\tremaining: 9.53s\n",
      "319:\tlearn: 0.0781422\ttotal: 4.47s\tremaining: 9.51s\n",
      "320:\tlearn: 0.0781031\ttotal: 4.49s\tremaining: 9.49s\n",
      "321:\tlearn: 0.0780622\ttotal: 4.5s\tremaining: 9.48s\n",
      "322:\tlearn: 0.0779984\ttotal: 4.51s\tremaining: 9.46s\n",
      "323:\tlearn: 0.0779710\ttotal: 4.53s\tremaining: 9.45s\n",
      "324:\tlearn: 0.0778795\ttotal: 4.54s\tremaining: 9.44s\n",
      "325:\tlearn: 0.0777916\ttotal: 4.56s\tremaining: 9.42s\n",
      "326:\tlearn: 0.0777347\ttotal: 4.57s\tremaining: 9.41s\n",
      "327:\tlearn: 0.0776857\ttotal: 4.58s\tremaining: 9.39s\n",
      "328:\tlearn: 0.0776199\ttotal: 4.6s\tremaining: 9.38s\n",
      "329:\tlearn: 0.0775605\ttotal: 4.61s\tremaining: 9.36s\n",
      "330:\tlearn: 0.0774902\ttotal: 4.63s\tremaining: 9.35s\n",
      "331:\tlearn: 0.0774523\ttotal: 4.64s\tremaining: 9.33s\n",
      "332:\tlearn: 0.0774076\ttotal: 4.65s\tremaining: 9.32s\n",
      "333:\tlearn: 0.0773756\ttotal: 4.66s\tremaining: 9.3s\n",
      "334:\tlearn: 0.0773003\ttotal: 4.68s\tremaining: 9.29s\n",
      "335:\tlearn: 0.0772730\ttotal: 4.69s\tremaining: 9.27s\n",
      "336:\tlearn: 0.0771827\ttotal: 4.7s\tremaining: 9.25s\n",
      "337:\tlearn: 0.0770572\ttotal: 4.72s\tremaining: 9.24s\n",
      "338:\tlearn: 0.0769375\ttotal: 4.73s\tremaining: 9.22s\n",
      "339:\tlearn: 0.0768571\ttotal: 4.74s\tremaining: 9.21s\n",
      "340:\tlearn: 0.0767574\ttotal: 4.76s\tremaining: 9.19s\n",
      "341:\tlearn: 0.0766923\ttotal: 4.77s\tremaining: 9.18s\n",
      "342:\tlearn: 0.0765943\ttotal: 4.78s\tremaining: 9.16s\n",
      "343:\tlearn: 0.0765618\ttotal: 4.8s\tremaining: 9.15s\n",
      "344:\tlearn: 0.0765475\ttotal: 4.81s\tremaining: 9.13s\n",
      "345:\tlearn: 0.0765120\ttotal: 4.83s\tremaining: 9.12s\n",
      "346:\tlearn: 0.0764885\ttotal: 4.84s\tremaining: 9.11s\n",
      "347:\tlearn: 0.0764503\ttotal: 4.85s\tremaining: 9.09s\n",
      "348:\tlearn: 0.0764072\ttotal: 4.86s\tremaining: 9.07s\n",
      "349:\tlearn: 0.0763573\ttotal: 4.88s\tremaining: 9.06s\n",
      "350:\tlearn: 0.0763169\ttotal: 4.89s\tremaining: 9.05s\n",
      "351:\tlearn: 0.0762891\ttotal: 4.91s\tremaining: 9.03s\n",
      "352:\tlearn: 0.0761802\ttotal: 4.92s\tremaining: 9.02s\n",
      "353:\tlearn: 0.0761181\ttotal: 4.93s\tremaining: 9s\n",
      "354:\tlearn: 0.0761165\ttotal: 4.95s\tremaining: 8.99s\n",
      "355:\tlearn: 0.0760403\ttotal: 4.96s\tremaining: 8.97s\n",
      "356:\tlearn: 0.0760138\ttotal: 4.97s\tremaining: 8.96s\n",
      "357:\tlearn: 0.0759867\ttotal: 4.99s\tremaining: 8.95s\n",
      "358:\tlearn: 0.0759568\ttotal: 5s\tremaining: 8.93s\n",
      "359:\tlearn: 0.0758942\ttotal: 5.01s\tremaining: 8.91s\n",
      "360:\tlearn: 0.0758552\ttotal: 5.03s\tremaining: 8.9s\n",
      "361:\tlearn: 0.0758038\ttotal: 5.04s\tremaining: 8.89s\n",
      "362:\tlearn: 0.0757447\ttotal: 5.06s\tremaining: 8.87s\n",
      "363:\tlearn: 0.0757074\ttotal: 5.07s\tremaining: 8.86s\n",
      "364:\tlearn: 0.0756662\ttotal: 5.08s\tremaining: 8.85s\n",
      "365:\tlearn: 0.0756249\ttotal: 5.1s\tremaining: 8.83s\n",
      "366:\tlearn: 0.0755770\ttotal: 5.11s\tremaining: 8.81s\n",
      "367:\tlearn: 0.0755216\ttotal: 5.13s\tremaining: 8.8s\n",
      "368:\tlearn: 0.0754489\ttotal: 5.14s\tremaining: 8.79s\n",
      "369:\tlearn: 0.0754110\ttotal: 5.15s\tremaining: 8.77s\n",
      "370:\tlearn: 0.0753725\ttotal: 5.17s\tremaining: 8.76s\n",
      "371:\tlearn: 0.0753151\ttotal: 5.18s\tremaining: 8.74s\n",
      "372:\tlearn: 0.0752673\ttotal: 5.19s\tremaining: 8.73s\n",
      "373:\tlearn: 0.0751865\ttotal: 5.21s\tremaining: 8.71s\n",
      "374:\tlearn: 0.0751495\ttotal: 5.22s\tremaining: 8.7s\n",
      "375:\tlearn: 0.0751095\ttotal: 5.23s\tremaining: 8.68s\n",
      "376:\tlearn: 0.0750544\ttotal: 5.25s\tremaining: 8.67s\n",
      "377:\tlearn: 0.0750268\ttotal: 5.26s\tremaining: 8.65s\n",
      "378:\tlearn: 0.0749983\ttotal: 5.27s\tremaining: 8.64s\n",
      "379:\tlearn: 0.0748585\ttotal: 5.29s\tremaining: 8.63s\n",
      "380:\tlearn: 0.0747984\ttotal: 5.3s\tremaining: 8.61s\n",
      "381:\tlearn: 0.0747729\ttotal: 5.31s\tremaining: 8.59s\n",
      "382:\tlearn: 0.0747155\ttotal: 5.33s\tremaining: 8.58s\n",
      "383:\tlearn: 0.0746583\ttotal: 5.34s\tremaining: 8.56s\n",
      "384:\tlearn: 0.0746418\ttotal: 5.35s\tremaining: 8.55s\n",
      "385:\tlearn: 0.0745771\ttotal: 5.37s\tremaining: 8.54s\n",
      "386:\tlearn: 0.0745393\ttotal: 5.38s\tremaining: 8.52s\n",
      "387:\tlearn: 0.0744725\ttotal: 5.39s\tremaining: 8.51s\n",
      "388:\tlearn: 0.0744241\ttotal: 5.41s\tremaining: 8.49s\n",
      "389:\tlearn: 0.0743785\ttotal: 5.42s\tremaining: 8.48s\n",
      "390:\tlearn: 0.0743594\ttotal: 5.43s\tremaining: 8.46s\n",
      "391:\tlearn: 0.0743375\ttotal: 5.45s\tremaining: 8.45s\n",
      "392:\tlearn: 0.0742833\ttotal: 5.46s\tremaining: 8.43s\n",
      "393:\tlearn: 0.0742201\ttotal: 5.47s\tremaining: 8.42s\n",
      "394:\tlearn: 0.0741887\ttotal: 5.49s\tremaining: 8.4s\n",
      "395:\tlearn: 0.0740943\ttotal: 5.5s\tremaining: 8.39s\n",
      "396:\tlearn: 0.0740311\ttotal: 5.51s\tremaining: 8.38s\n",
      "397:\tlearn: 0.0740049\ttotal: 5.53s\tremaining: 8.36s\n",
      "398:\tlearn: 0.0739851\ttotal: 5.54s\tremaining: 8.35s\n",
      "399:\tlearn: 0.0739499\ttotal: 5.55s\tremaining: 8.33s\n",
      "400:\tlearn: 0.0739353\ttotal: 5.57s\tremaining: 8.32s\n",
      "401:\tlearn: 0.0739239\ttotal: 5.58s\tremaining: 8.3s\n",
      "402:\tlearn: 0.0738819\ttotal: 5.6s\tremaining: 8.29s\n",
      "403:\tlearn: 0.0738459\ttotal: 5.61s\tremaining: 8.28s\n",
      "404:\tlearn: 0.0738217\ttotal: 5.62s\tremaining: 8.26s\n",
      "405:\tlearn: 0.0737768\ttotal: 5.64s\tremaining: 8.25s\n",
      "406:\tlearn: 0.0737288\ttotal: 5.65s\tremaining: 8.23s\n",
      "407:\tlearn: 0.0736881\ttotal: 5.66s\tremaining: 8.22s\n",
      "408:\tlearn: 0.0736719\ttotal: 5.68s\tremaining: 8.2s\n",
      "409:\tlearn: 0.0736632\ttotal: 5.69s\tremaining: 8.19s\n",
      "410:\tlearn: 0.0736167\ttotal: 5.7s\tremaining: 8.17s\n",
      "411:\tlearn: 0.0735891\ttotal: 5.72s\tremaining: 8.16s\n",
      "412:\tlearn: 0.0735317\ttotal: 5.73s\tremaining: 8.15s\n",
      "413:\tlearn: 0.0734942\ttotal: 5.74s\tremaining: 8.13s\n",
      "414:\tlearn: 0.0734682\ttotal: 5.76s\tremaining: 8.12s\n",
      "415:\tlearn: 0.0734052\ttotal: 5.77s\tremaining: 8.1s\n",
      "416:\tlearn: 0.0733597\ttotal: 5.79s\tremaining: 8.09s\n",
      "417:\tlearn: 0.0733218\ttotal: 5.8s\tremaining: 8.08s\n",
      "418:\tlearn: 0.0732689\ttotal: 5.81s\tremaining: 8.06s\n",
      "419:\tlearn: 0.0732203\ttotal: 5.83s\tremaining: 8.05s\n",
      "420:\tlearn: 0.0731837\ttotal: 5.84s\tremaining: 8.03s\n",
      "421:\tlearn: 0.0731525\ttotal: 5.85s\tremaining: 8.02s\n",
      "422:\tlearn: 0.0731028\ttotal: 5.87s\tremaining: 8.01s\n",
      "423:\tlearn: 0.0730826\ttotal: 5.88s\tremaining: 7.99s\n",
      "424:\tlearn: 0.0730608\ttotal: 5.89s\tremaining: 7.97s\n",
      "425:\tlearn: 0.0730280\ttotal: 5.91s\tremaining: 7.96s\n",
      "426:\tlearn: 0.0729931\ttotal: 5.92s\tremaining: 7.95s\n",
      "427:\tlearn: 0.0729726\ttotal: 5.94s\tremaining: 7.93s\n",
      "428:\tlearn: 0.0729611\ttotal: 5.95s\tremaining: 7.92s\n",
      "429:\tlearn: 0.0728820\ttotal: 5.96s\tremaining: 7.9s\n",
      "430:\tlearn: 0.0728399\ttotal: 5.98s\tremaining: 7.89s\n",
      "431:\tlearn: 0.0728113\ttotal: 5.99s\tremaining: 7.88s\n",
      "432:\tlearn: 0.0727623\ttotal: 6s\tremaining: 7.86s\n",
      "433:\tlearn: 0.0727233\ttotal: 6.02s\tremaining: 7.85s\n",
      "434:\tlearn: 0.0727100\ttotal: 6.03s\tremaining: 7.84s\n",
      "435:\tlearn: 0.0726733\ttotal: 6.05s\tremaining: 7.82s\n",
      "436:\tlearn: 0.0726485\ttotal: 6.06s\tremaining: 7.81s\n",
      "437:\tlearn: 0.0726113\ttotal: 6.07s\tremaining: 7.79s\n",
      "438:\tlearn: 0.0725772\ttotal: 6.09s\tremaining: 7.78s\n",
      "439:\tlearn: 0.0725198\ttotal: 6.1s\tremaining: 7.76s\n",
      "440:\tlearn: 0.0725004\ttotal: 6.11s\tremaining: 7.75s\n",
      "441:\tlearn: 0.0724964\ttotal: 6.13s\tremaining: 7.73s\n",
      "442:\tlearn: 0.0724644\ttotal: 6.14s\tremaining: 7.72s\n",
      "443:\tlearn: 0.0724529\ttotal: 6.15s\tremaining: 7.7s\n",
      "444:\tlearn: 0.0723946\ttotal: 6.17s\tremaining: 7.69s\n",
      "445:\tlearn: 0.0723497\ttotal: 6.18s\tremaining: 7.68s\n",
      "446:\tlearn: 0.0722299\ttotal: 6.19s\tremaining: 7.66s\n",
      "447:\tlearn: 0.0721981\ttotal: 6.21s\tremaining: 7.65s\n",
      "448:\tlearn: 0.0721772\ttotal: 6.22s\tremaining: 7.63s\n",
      "449:\tlearn: 0.0721628\ttotal: 6.23s\tremaining: 7.62s\n",
      "450:\tlearn: 0.0721573\ttotal: 6.25s\tremaining: 7.61s\n",
      "451:\tlearn: 0.0721016\ttotal: 6.26s\tremaining: 7.59s\n",
      "452:\tlearn: 0.0720811\ttotal: 6.27s\tremaining: 7.58s\n",
      "453:\tlearn: 0.0720354\ttotal: 6.29s\tremaining: 7.56s\n",
      "454:\tlearn: 0.0719746\ttotal: 6.3s\tremaining: 7.55s\n",
      "455:\tlearn: 0.0719450\ttotal: 6.32s\tremaining: 7.53s\n",
      "456:\tlearn: 0.0719231\ttotal: 6.33s\tremaining: 7.52s\n",
      "457:\tlearn: 0.0718710\ttotal: 6.34s\tremaining: 7.5s\n",
      "458:\tlearn: 0.0718213\ttotal: 6.36s\tremaining: 7.49s\n",
      "459:\tlearn: 0.0717543\ttotal: 6.37s\tremaining: 7.48s\n",
      "460:\tlearn: 0.0717162\ttotal: 6.38s\tremaining: 7.46s\n",
      "461:\tlearn: 0.0716971\ttotal: 6.4s\tremaining: 7.45s\n",
      "462:\tlearn: 0.0716606\ttotal: 6.41s\tremaining: 7.43s\n",
      "463:\tlearn: 0.0716411\ttotal: 6.42s\tremaining: 7.42s\n",
      "464:\tlearn: 0.0715952\ttotal: 6.44s\tremaining: 7.41s\n",
      "465:\tlearn: 0.0715662\ttotal: 6.45s\tremaining: 7.39s\n",
      "466:\tlearn: 0.0715286\ttotal: 6.46s\tremaining: 7.38s\n",
      "467:\tlearn: 0.0715109\ttotal: 6.48s\tremaining: 7.36s\n",
      "468:\tlearn: 0.0715061\ttotal: 6.49s\tremaining: 7.35s\n",
      "469:\tlearn: 0.0714697\ttotal: 6.5s\tremaining: 7.33s\n",
      "470:\tlearn: 0.0714220\ttotal: 6.52s\tremaining: 7.32s\n",
      "471:\tlearn: 0.0713207\ttotal: 6.53s\tremaining: 7.3s\n",
      "472:\tlearn: 0.0712757\ttotal: 6.54s\tremaining: 7.29s\n",
      "473:\tlearn: 0.0712536\ttotal: 6.56s\tremaining: 7.28s\n",
      "474:\tlearn: 0.0711976\ttotal: 6.57s\tremaining: 7.26s\n",
      "475:\tlearn: 0.0711870\ttotal: 6.58s\tremaining: 7.25s\n",
      "476:\tlearn: 0.0711339\ttotal: 6.6s\tremaining: 7.23s\n",
      "477:\tlearn: 0.0710801\ttotal: 6.61s\tremaining: 7.22s\n",
      "478:\tlearn: 0.0710465\ttotal: 6.63s\tremaining: 7.21s\n",
      "479:\tlearn: 0.0710267\ttotal: 6.64s\tremaining: 7.19s\n",
      "480:\tlearn: 0.0709881\ttotal: 6.65s\tremaining: 7.18s\n",
      "481:\tlearn: 0.0709396\ttotal: 6.66s\tremaining: 7.16s\n",
      "482:\tlearn: 0.0708718\ttotal: 6.68s\tremaining: 7.15s\n",
      "483:\tlearn: 0.0708506\ttotal: 6.69s\tremaining: 7.13s\n",
      "484:\tlearn: 0.0708415\ttotal: 6.7s\tremaining: 7.12s\n",
      "485:\tlearn: 0.0708104\ttotal: 6.71s\tremaining: 7.1s\n",
      "486:\tlearn: 0.0707711\ttotal: 6.73s\tremaining: 7.09s\n",
      "487:\tlearn: 0.0707456\ttotal: 6.74s\tremaining: 7.07s\n",
      "488:\tlearn: 0.0707232\ttotal: 6.75s\tremaining: 7.06s\n",
      "489:\tlearn: 0.0706968\ttotal: 6.77s\tremaining: 7.04s\n",
      "490:\tlearn: 0.0706902\ttotal: 6.78s\tremaining: 7.03s\n",
      "491:\tlearn: 0.0706517\ttotal: 6.79s\tremaining: 7.02s\n",
      "492:\tlearn: 0.0706131\ttotal: 6.81s\tremaining: 7s\n",
      "493:\tlearn: 0.0705858\ttotal: 6.82s\tremaining: 6.99s\n",
      "494:\tlearn: 0.0705483\ttotal: 6.83s\tremaining: 6.97s\n",
      "495:\tlearn: 0.0705056\ttotal: 6.85s\tremaining: 6.96s\n",
      "496:\tlearn: 0.0704676\ttotal: 6.86s\tremaining: 6.95s\n",
      "497:\tlearn: 0.0704237\ttotal: 6.88s\tremaining: 6.93s\n",
      "498:\tlearn: 0.0703947\ttotal: 6.89s\tremaining: 6.92s\n",
      "499:\tlearn: 0.0703333\ttotal: 6.9s\tremaining: 6.9s\n",
      "500:\tlearn: 0.0702475\ttotal: 6.92s\tremaining: 6.89s\n",
      "501:\tlearn: 0.0701849\ttotal: 6.93s\tremaining: 6.87s\n",
      "502:\tlearn: 0.0701295\ttotal: 6.94s\tremaining: 6.86s\n",
      "503:\tlearn: 0.0700823\ttotal: 6.96s\tremaining: 6.85s\n",
      "504:\tlearn: 0.0700616\ttotal: 6.97s\tremaining: 6.83s\n",
      "505:\tlearn: 0.0700198\ttotal: 6.98s\tremaining: 6.82s\n",
      "506:\tlearn: 0.0699820\ttotal: 7s\tremaining: 6.8s\n",
      "507:\tlearn: 0.0699389\ttotal: 7.01s\tremaining: 6.79s\n",
      "508:\tlearn: 0.0699210\ttotal: 7.02s\tremaining: 6.77s\n",
      "509:\tlearn: 0.0699106\ttotal: 7.03s\tremaining: 6.76s\n",
      "510:\tlearn: 0.0698480\ttotal: 7.05s\tremaining: 6.74s\n",
      "511:\tlearn: 0.0698016\ttotal: 7.06s\tremaining: 6.73s\n",
      "512:\tlearn: 0.0697766\ttotal: 7.08s\tremaining: 6.72s\n",
      "513:\tlearn: 0.0697554\ttotal: 7.09s\tremaining: 6.71s\n",
      "514:\tlearn: 0.0697223\ttotal: 7.11s\tremaining: 6.69s\n",
      "515:\tlearn: 0.0696889\ttotal: 7.12s\tremaining: 6.68s\n",
      "516:\tlearn: 0.0696706\ttotal: 7.13s\tremaining: 6.66s\n",
      "517:\tlearn: 0.0696523\ttotal: 7.14s\tremaining: 6.65s\n",
      "518:\tlearn: 0.0696193\ttotal: 7.16s\tremaining: 6.63s\n",
      "519:\tlearn: 0.0695698\ttotal: 7.17s\tremaining: 6.62s\n",
      "520:\tlearn: 0.0695437\ttotal: 7.18s\tremaining: 6.61s\n",
      "521:\tlearn: 0.0695312\ttotal: 7.2s\tremaining: 6.59s\n",
      "522:\tlearn: 0.0695147\ttotal: 7.21s\tremaining: 6.58s\n",
      "523:\tlearn: 0.0694648\ttotal: 7.22s\tremaining: 6.56s\n",
      "524:\tlearn: 0.0694501\ttotal: 7.24s\tremaining: 6.55s\n",
      "525:\tlearn: 0.0694163\ttotal: 7.25s\tremaining: 6.54s\n",
      "526:\tlearn: 0.0694091\ttotal: 7.27s\tremaining: 6.52s\n",
      "527:\tlearn: 0.0693740\ttotal: 7.28s\tremaining: 6.51s\n",
      "528:\tlearn: 0.0693311\ttotal: 7.29s\tremaining: 6.49s\n",
      "529:\tlearn: 0.0693050\ttotal: 7.31s\tremaining: 6.48s\n",
      "530:\tlearn: 0.0692957\ttotal: 7.32s\tremaining: 6.47s\n",
      "531:\tlearn: 0.0692438\ttotal: 7.33s\tremaining: 6.45s\n",
      "532:\tlearn: 0.0692321\ttotal: 7.35s\tremaining: 6.44s\n",
      "533:\tlearn: 0.0691967\ttotal: 7.36s\tremaining: 6.42s\n",
      "534:\tlearn: 0.0691803\ttotal: 7.37s\tremaining: 6.41s\n",
      "535:\tlearn: 0.0691662\ttotal: 7.39s\tremaining: 6.4s\n",
      "536:\tlearn: 0.0691462\ttotal: 7.4s\tremaining: 6.38s\n",
      "537:\tlearn: 0.0690309\ttotal: 7.41s\tremaining: 6.37s\n",
      "538:\tlearn: 0.0689985\ttotal: 7.43s\tremaining: 6.35s\n",
      "539:\tlearn: 0.0689456\ttotal: 7.44s\tremaining: 6.34s\n",
      "540:\tlearn: 0.0689211\ttotal: 7.46s\tremaining: 6.33s\n",
      "541:\tlearn: 0.0688577\ttotal: 7.47s\tremaining: 6.31s\n",
      "542:\tlearn: 0.0688397\ttotal: 7.48s\tremaining: 6.3s\n",
      "543:\tlearn: 0.0688019\ttotal: 7.5s\tremaining: 6.28s\n",
      "544:\tlearn: 0.0687784\ttotal: 7.51s\tremaining: 6.27s\n",
      "545:\tlearn: 0.0687486\ttotal: 7.52s\tremaining: 6.26s\n",
      "546:\tlearn: 0.0687124\ttotal: 7.54s\tremaining: 6.24s\n",
      "547:\tlearn: 0.0686377\ttotal: 7.55s\tremaining: 6.23s\n",
      "548:\tlearn: 0.0686337\ttotal: 7.56s\tremaining: 6.21s\n",
      "549:\tlearn: 0.0686112\ttotal: 7.58s\tremaining: 6.2s\n",
      "550:\tlearn: 0.0686008\ttotal: 7.59s\tremaining: 6.18s\n",
      "551:\tlearn: 0.0685774\ttotal: 7.6s\tremaining: 6.17s\n",
      "552:\tlearn: 0.0685661\ttotal: 7.62s\tremaining: 6.16s\n",
      "553:\tlearn: 0.0685078\ttotal: 7.63s\tremaining: 6.14s\n",
      "554:\tlearn: 0.0684648\ttotal: 7.64s\tremaining: 6.13s\n",
      "555:\tlearn: 0.0684149\ttotal: 7.66s\tremaining: 6.12s\n",
      "556:\tlearn: 0.0683919\ttotal: 7.67s\tremaining: 6.1s\n",
      "557:\tlearn: 0.0683778\ttotal: 7.68s\tremaining: 6.09s\n",
      "558:\tlearn: 0.0683737\ttotal: 7.7s\tremaining: 6.07s\n",
      "559:\tlearn: 0.0683633\ttotal: 7.71s\tremaining: 6.06s\n",
      "560:\tlearn: 0.0682993\ttotal: 7.72s\tremaining: 6.04s\n",
      "561:\tlearn: 0.0682627\ttotal: 7.74s\tremaining: 6.03s\n",
      "562:\tlearn: 0.0682395\ttotal: 7.75s\tremaining: 6.02s\n",
      "563:\tlearn: 0.0682131\ttotal: 7.76s\tremaining: 6s\n",
      "564:\tlearn: 0.0681603\ttotal: 7.78s\tremaining: 5.99s\n",
      "565:\tlearn: 0.0681328\ttotal: 7.79s\tremaining: 5.97s\n",
      "566:\tlearn: 0.0680909\ttotal: 7.8s\tremaining: 5.96s\n",
      "567:\tlearn: 0.0680592\ttotal: 7.82s\tremaining: 5.95s\n",
      "568:\tlearn: 0.0680373\ttotal: 7.83s\tremaining: 5.93s\n",
      "569:\tlearn: 0.0679955\ttotal: 7.84s\tremaining: 5.92s\n",
      "570:\tlearn: 0.0679636\ttotal: 7.86s\tremaining: 5.9s\n",
      "571:\tlearn: 0.0679179\ttotal: 7.87s\tremaining: 5.89s\n",
      "572:\tlearn: 0.0678443\ttotal: 7.89s\tremaining: 5.88s\n",
      "573:\tlearn: 0.0678142\ttotal: 7.9s\tremaining: 5.86s\n",
      "574:\tlearn: 0.0677971\ttotal: 7.92s\tremaining: 5.85s\n",
      "575:\tlearn: 0.0677698\ttotal: 7.93s\tremaining: 5.84s\n",
      "576:\tlearn: 0.0677318\ttotal: 7.94s\tremaining: 5.82s\n",
      "577:\tlearn: 0.0676898\ttotal: 7.96s\tremaining: 5.81s\n",
      "578:\tlearn: 0.0676732\ttotal: 7.97s\tremaining: 5.79s\n",
      "579:\tlearn: 0.0676566\ttotal: 7.99s\tremaining: 5.78s\n",
      "580:\tlearn: 0.0676393\ttotal: 8s\tremaining: 5.77s\n",
      "581:\tlearn: 0.0675866\ttotal: 8.01s\tremaining: 5.75s\n",
      "582:\tlearn: 0.0675595\ttotal: 8.03s\tremaining: 5.74s\n",
      "583:\tlearn: 0.0675080\ttotal: 8.04s\tremaining: 5.73s\n",
      "584:\tlearn: 0.0674515\ttotal: 8.05s\tremaining: 5.71s\n",
      "585:\tlearn: 0.0674236\ttotal: 8.07s\tremaining: 5.7s\n",
      "586:\tlearn: 0.0673965\ttotal: 8.08s\tremaining: 5.68s\n",
      "587:\tlearn: 0.0673694\ttotal: 8.09s\tremaining: 5.67s\n",
      "588:\tlearn: 0.0673672\ttotal: 8.11s\tremaining: 5.66s\n",
      "589:\tlearn: 0.0673469\ttotal: 8.12s\tremaining: 5.64s\n",
      "590:\tlearn: 0.0673239\ttotal: 8.13s\tremaining: 5.63s\n",
      "591:\tlearn: 0.0673014\ttotal: 8.15s\tremaining: 5.61s\n",
      "592:\tlearn: 0.0672879\ttotal: 8.16s\tremaining: 5.6s\n",
      "593:\tlearn: 0.0672204\ttotal: 8.17s\tremaining: 5.59s\n",
      "594:\tlearn: 0.0671741\ttotal: 8.19s\tremaining: 5.57s\n",
      "595:\tlearn: 0.0671442\ttotal: 8.2s\tremaining: 5.56s\n",
      "596:\tlearn: 0.0671240\ttotal: 8.21s\tremaining: 5.54s\n",
      "597:\tlearn: 0.0670915\ttotal: 8.23s\tremaining: 5.53s\n",
      "598:\tlearn: 0.0670639\ttotal: 8.24s\tremaining: 5.52s\n",
      "599:\tlearn: 0.0670384\ttotal: 8.25s\tremaining: 5.5s\n",
      "600:\tlearn: 0.0670070\ttotal: 8.27s\tremaining: 5.49s\n",
      "601:\tlearn: 0.0669759\ttotal: 8.28s\tremaining: 5.47s\n",
      "602:\tlearn: 0.0669386\ttotal: 8.3s\tremaining: 5.46s\n",
      "603:\tlearn: 0.0669144\ttotal: 8.31s\tremaining: 5.45s\n",
      "604:\tlearn: 0.0668886\ttotal: 8.32s\tremaining: 5.43s\n",
      "605:\tlearn: 0.0668650\ttotal: 8.34s\tremaining: 5.42s\n",
      "606:\tlearn: 0.0668334\ttotal: 8.35s\tremaining: 5.41s\n",
      "607:\tlearn: 0.0668009\ttotal: 8.37s\tremaining: 5.39s\n",
      "608:\tlearn: 0.0667702\ttotal: 8.38s\tremaining: 5.38s\n",
      "609:\tlearn: 0.0667511\ttotal: 8.39s\tremaining: 5.37s\n",
      "610:\tlearn: 0.0667247\ttotal: 8.4s\tremaining: 5.35s\n",
      "611:\tlearn: 0.0667158\ttotal: 8.42s\tremaining: 5.34s\n",
      "612:\tlearn: 0.0666983\ttotal: 8.43s\tremaining: 5.32s\n",
      "613:\tlearn: 0.0666607\ttotal: 8.45s\tremaining: 5.31s\n",
      "614:\tlearn: 0.0666587\ttotal: 8.46s\tremaining: 5.3s\n",
      "615:\tlearn: 0.0666279\ttotal: 8.47s\tremaining: 5.28s\n",
      "616:\tlearn: 0.0666158\ttotal: 8.48s\tremaining: 5.27s\n",
      "617:\tlearn: 0.0665598\ttotal: 8.5s\tremaining: 5.25s\n",
      "618:\tlearn: 0.0665276\ttotal: 8.51s\tremaining: 5.24s\n",
      "619:\tlearn: 0.0664958\ttotal: 8.53s\tremaining: 5.23s\n",
      "620:\tlearn: 0.0664677\ttotal: 8.54s\tremaining: 5.21s\n",
      "621:\tlearn: 0.0664411\ttotal: 8.55s\tremaining: 5.2s\n",
      "622:\tlearn: 0.0663832\ttotal: 8.57s\tremaining: 5.18s\n",
      "623:\tlearn: 0.0663750\ttotal: 8.58s\tremaining: 5.17s\n",
      "624:\tlearn: 0.0663356\ttotal: 8.6s\tremaining: 5.16s\n",
      "625:\tlearn: 0.0663102\ttotal: 8.61s\tremaining: 5.14s\n",
      "626:\tlearn: 0.0662834\ttotal: 8.62s\tremaining: 5.13s\n",
      "627:\tlearn: 0.0662451\ttotal: 8.63s\tremaining: 5.11s\n",
      "628:\tlearn: 0.0661708\ttotal: 8.65s\tremaining: 5.1s\n",
      "629:\tlearn: 0.0661430\ttotal: 8.66s\tremaining: 5.09s\n",
      "630:\tlearn: 0.0661312\ttotal: 8.67s\tremaining: 5.07s\n",
      "631:\tlearn: 0.0661111\ttotal: 8.69s\tremaining: 5.06s\n",
      "632:\tlearn: 0.0660717\ttotal: 8.7s\tremaining: 5.04s\n",
      "633:\tlearn: 0.0660424\ttotal: 8.71s\tremaining: 5.03s\n",
      "634:\tlearn: 0.0660037\ttotal: 8.73s\tremaining: 5.01s\n",
      "635:\tlearn: 0.0659938\ttotal: 8.74s\tremaining: 5s\n",
      "636:\tlearn: 0.0659503\ttotal: 8.75s\tremaining: 4.99s\n",
      "637:\tlearn: 0.0659176\ttotal: 8.77s\tremaining: 4.97s\n",
      "638:\tlearn: 0.0658908\ttotal: 8.78s\tremaining: 4.96s\n",
      "639:\tlearn: 0.0658604\ttotal: 8.79s\tremaining: 4.95s\n",
      "640:\tlearn: 0.0658117\ttotal: 8.81s\tremaining: 4.93s\n",
      "641:\tlearn: 0.0657704\ttotal: 8.82s\tremaining: 4.92s\n",
      "642:\tlearn: 0.0657379\ttotal: 8.84s\tremaining: 4.91s\n",
      "643:\tlearn: 0.0657170\ttotal: 8.85s\tremaining: 4.89s\n",
      "644:\tlearn: 0.0656871\ttotal: 8.86s\tremaining: 4.88s\n",
      "645:\tlearn: 0.0656293\ttotal: 8.88s\tremaining: 4.86s\n",
      "646:\tlearn: 0.0655974\ttotal: 8.89s\tremaining: 4.85s\n",
      "647:\tlearn: 0.0655101\ttotal: 8.91s\tremaining: 4.84s\n",
      "648:\tlearn: 0.0654753\ttotal: 8.92s\tremaining: 4.82s\n",
      "649:\tlearn: 0.0654500\ttotal: 8.93s\tremaining: 4.81s\n",
      "650:\tlearn: 0.0654269\ttotal: 8.95s\tremaining: 4.8s\n",
      "651:\tlearn: 0.0654073\ttotal: 8.96s\tremaining: 4.78s\n",
      "652:\tlearn: 0.0653973\ttotal: 8.97s\tremaining: 4.77s\n",
      "653:\tlearn: 0.0653885\ttotal: 8.98s\tremaining: 4.75s\n",
      "654:\tlearn: 0.0653473\ttotal: 9s\tremaining: 4.74s\n",
      "655:\tlearn: 0.0653206\ttotal: 9.01s\tremaining: 4.73s\n",
      "656:\tlearn: 0.0652818\ttotal: 9.03s\tremaining: 4.71s\n",
      "657:\tlearn: 0.0652100\ttotal: 9.04s\tremaining: 4.7s\n",
      "658:\tlearn: 0.0651807\ttotal: 9.05s\tremaining: 4.68s\n",
      "659:\tlearn: 0.0651253\ttotal: 9.07s\tremaining: 4.67s\n",
      "660:\tlearn: 0.0651061\ttotal: 9.08s\tremaining: 4.66s\n",
      "661:\tlearn: 0.0650781\ttotal: 9.09s\tremaining: 4.64s\n",
      "662:\tlearn: 0.0650473\ttotal: 9.11s\tremaining: 4.63s\n",
      "663:\tlearn: 0.0650173\ttotal: 9.12s\tremaining: 4.62s\n",
      "664:\tlearn: 0.0649991\ttotal: 9.13s\tremaining: 4.6s\n",
      "665:\tlearn: 0.0649676\ttotal: 9.15s\tremaining: 4.59s\n",
      "666:\tlearn: 0.0649480\ttotal: 9.16s\tremaining: 4.57s\n",
      "667:\tlearn: 0.0649225\ttotal: 9.17s\tremaining: 4.56s\n",
      "668:\tlearn: 0.0648961\ttotal: 9.19s\tremaining: 4.54s\n",
      "669:\tlearn: 0.0648557\ttotal: 9.2s\tremaining: 4.53s\n",
      "670:\tlearn: 0.0648483\ttotal: 9.21s\tremaining: 4.52s\n",
      "671:\tlearn: 0.0648439\ttotal: 9.22s\tremaining: 4.5s\n",
      "672:\tlearn: 0.0648295\ttotal: 9.24s\tremaining: 4.49s\n",
      "673:\tlearn: 0.0648086\ttotal: 9.25s\tremaining: 4.47s\n",
      "674:\tlearn: 0.0647662\ttotal: 9.27s\tremaining: 4.46s\n",
      "675:\tlearn: 0.0647278\ttotal: 9.28s\tremaining: 4.45s\n",
      "676:\tlearn: 0.0646995\ttotal: 9.29s\tremaining: 4.43s\n",
      "677:\tlearn: 0.0646866\ttotal: 9.31s\tremaining: 4.42s\n",
      "678:\tlearn: 0.0646430\ttotal: 9.32s\tremaining: 4.41s\n",
      "679:\tlearn: 0.0646258\ttotal: 9.33s\tremaining: 4.39s\n",
      "680:\tlearn: 0.0645957\ttotal: 9.35s\tremaining: 4.38s\n",
      "681:\tlearn: 0.0645760\ttotal: 9.36s\tremaining: 4.36s\n",
      "682:\tlearn: 0.0645454\ttotal: 9.37s\tremaining: 4.35s\n",
      "683:\tlearn: 0.0644937\ttotal: 9.39s\tremaining: 4.34s\n",
      "684:\tlearn: 0.0644481\ttotal: 9.41s\tremaining: 4.33s\n",
      "685:\tlearn: 0.0644137\ttotal: 9.42s\tremaining: 4.31s\n",
      "686:\tlearn: 0.0643975\ttotal: 9.44s\tremaining: 4.3s\n",
      "687:\tlearn: 0.0643801\ttotal: 9.46s\tremaining: 4.29s\n",
      "688:\tlearn: 0.0643784\ttotal: 9.47s\tremaining: 4.28s\n",
      "689:\tlearn: 0.0643706\ttotal: 9.49s\tremaining: 4.26s\n",
      "690:\tlearn: 0.0643318\ttotal: 9.51s\tremaining: 4.25s\n",
      "691:\tlearn: 0.0643053\ttotal: 9.52s\tremaining: 4.24s\n",
      "692:\tlearn: 0.0642799\ttotal: 9.54s\tremaining: 4.22s\n",
      "693:\tlearn: 0.0642568\ttotal: 9.55s\tremaining: 4.21s\n",
      "694:\tlearn: 0.0642414\ttotal: 9.57s\tremaining: 4.2s\n",
      "695:\tlearn: 0.0642127\ttotal: 9.58s\tremaining: 4.18s\n",
      "696:\tlearn: 0.0641973\ttotal: 9.59s\tremaining: 4.17s\n",
      "697:\tlearn: 0.0641588\ttotal: 9.61s\tremaining: 4.16s\n",
      "698:\tlearn: 0.0641335\ttotal: 9.62s\tremaining: 4.14s\n",
      "699:\tlearn: 0.0641004\ttotal: 9.63s\tremaining: 4.13s\n",
      "700:\tlearn: 0.0640719\ttotal: 9.65s\tremaining: 4.12s\n",
      "701:\tlearn: 0.0640570\ttotal: 9.66s\tremaining: 4.1s\n",
      "702:\tlearn: 0.0640040\ttotal: 9.67s\tremaining: 4.09s\n",
      "703:\tlearn: 0.0639795\ttotal: 9.69s\tremaining: 4.07s\n",
      "704:\tlearn: 0.0639530\ttotal: 9.7s\tremaining: 4.06s\n",
      "705:\tlearn: 0.0639293\ttotal: 9.72s\tremaining: 4.05s\n",
      "706:\tlearn: 0.0639063\ttotal: 9.73s\tremaining: 4.03s\n",
      "707:\tlearn: 0.0638678\ttotal: 9.74s\tremaining: 4.02s\n",
      "708:\tlearn: 0.0638420\ttotal: 9.76s\tremaining: 4s\n",
      "709:\tlearn: 0.0638002\ttotal: 9.77s\tremaining: 3.99s\n",
      "710:\tlearn: 0.0637710\ttotal: 9.78s\tremaining: 3.98s\n",
      "711:\tlearn: 0.0637498\ttotal: 9.79s\tremaining: 3.96s\n",
      "712:\tlearn: 0.0637211\ttotal: 9.81s\tremaining: 3.95s\n",
      "713:\tlearn: 0.0637010\ttotal: 9.82s\tremaining: 3.93s\n",
      "714:\tlearn: 0.0635801\ttotal: 9.84s\tremaining: 3.92s\n",
      "715:\tlearn: 0.0635395\ttotal: 9.85s\tremaining: 3.91s\n",
      "716:\tlearn: 0.0635302\ttotal: 9.86s\tremaining: 3.89s\n",
      "717:\tlearn: 0.0635048\ttotal: 9.87s\tremaining: 3.88s\n",
      "718:\tlearn: 0.0634793\ttotal: 9.89s\tremaining: 3.86s\n",
      "719:\tlearn: 0.0634539\ttotal: 9.9s\tremaining: 3.85s\n",
      "720:\tlearn: 0.0634522\ttotal: 9.91s\tremaining: 3.84s\n",
      "721:\tlearn: 0.0633870\ttotal: 9.93s\tremaining: 3.82s\n",
      "722:\tlearn: 0.0633708\ttotal: 9.94s\tremaining: 3.81s\n",
      "723:\tlearn: 0.0633405\ttotal: 9.95s\tremaining: 3.79s\n",
      "724:\tlearn: 0.0633209\ttotal: 9.97s\tremaining: 3.78s\n",
      "725:\tlearn: 0.0633062\ttotal: 9.98s\tremaining: 3.77s\n",
      "726:\tlearn: 0.0632752\ttotal: 9.99s\tremaining: 3.75s\n",
      "727:\tlearn: 0.0632544\ttotal: 10s\tremaining: 3.74s\n",
      "728:\tlearn: 0.0632073\ttotal: 10s\tremaining: 3.73s\n",
      "729:\tlearn: 0.0631471\ttotal: 10s\tremaining: 3.71s\n",
      "730:\tlearn: 0.0631254\ttotal: 10.1s\tremaining: 3.7s\n",
      "731:\tlearn: 0.0630994\ttotal: 10.1s\tremaining: 3.69s\n",
      "732:\tlearn: 0.0630614\ttotal: 10.1s\tremaining: 3.67s\n",
      "733:\tlearn: 0.0630434\ttotal: 10.1s\tremaining: 3.66s\n",
      "734:\tlearn: 0.0630154\ttotal: 10.1s\tremaining: 3.64s\n",
      "735:\tlearn: 0.0629849\ttotal: 10.1s\tremaining: 3.63s\n",
      "736:\tlearn: 0.0629731\ttotal: 10.1s\tremaining: 3.62s\n",
      "737:\tlearn: 0.0629711\ttotal: 10.2s\tremaining: 3.6s\n",
      "738:\tlearn: 0.0629300\ttotal: 10.2s\tremaining: 3.59s\n",
      "739:\tlearn: 0.0628973\ttotal: 10.2s\tremaining: 3.58s\n",
      "740:\tlearn: 0.0628660\ttotal: 10.2s\tremaining: 3.56s\n",
      "741:\tlearn: 0.0628365\ttotal: 10.2s\tremaining: 3.55s\n",
      "742:\tlearn: 0.0627780\ttotal: 10.2s\tremaining: 3.54s\n",
      "743:\tlearn: 0.0627433\ttotal: 10.3s\tremaining: 3.53s\n",
      "744:\tlearn: 0.0627119\ttotal: 10.3s\tremaining: 3.52s\n",
      "745:\tlearn: 0.0626763\ttotal: 10.3s\tremaining: 3.5s\n",
      "746:\tlearn: 0.0625653\ttotal: 10.3s\tremaining: 3.49s\n",
      "747:\tlearn: 0.0625411\ttotal: 10.3s\tremaining: 3.48s\n",
      "748:\tlearn: 0.0625297\ttotal: 10.3s\tremaining: 3.46s\n",
      "749:\tlearn: 0.0625093\ttotal: 10.3s\tremaining: 3.45s\n",
      "750:\tlearn: 0.0624881\ttotal: 10.4s\tremaining: 3.43s\n",
      "751:\tlearn: 0.0624446\ttotal: 10.4s\tremaining: 3.42s\n",
      "752:\tlearn: 0.0624290\ttotal: 10.4s\tremaining: 3.4s\n",
      "753:\tlearn: 0.0623915\ttotal: 10.4s\tremaining: 3.39s\n",
      "754:\tlearn: 0.0623699\ttotal: 10.4s\tremaining: 3.38s\n",
      "755:\tlearn: 0.0623556\ttotal: 10.4s\tremaining: 3.36s\n",
      "756:\tlearn: 0.0623315\ttotal: 10.4s\tremaining: 3.35s\n",
      "757:\tlearn: 0.0623012\ttotal: 10.5s\tremaining: 3.34s\n",
      "758:\tlearn: 0.0622884\ttotal: 10.5s\tremaining: 3.32s\n",
      "759:\tlearn: 0.0622551\ttotal: 10.5s\tremaining: 3.31s\n",
      "760:\tlearn: 0.0622214\ttotal: 10.5s\tremaining: 3.3s\n",
      "761:\tlearn: 0.0621996\ttotal: 10.5s\tremaining: 3.28s\n",
      "762:\tlearn: 0.0621525\ttotal: 10.5s\tremaining: 3.27s\n",
      "763:\tlearn: 0.0621357\ttotal: 10.5s\tremaining: 3.25s\n",
      "764:\tlearn: 0.0621124\ttotal: 10.5s\tremaining: 3.24s\n",
      "765:\tlearn: 0.0620546\ttotal: 10.6s\tremaining: 3.23s\n",
      "766:\tlearn: 0.0620345\ttotal: 10.6s\tremaining: 3.21s\n",
      "767:\tlearn: 0.0620110\ttotal: 10.6s\tremaining: 3.2s\n",
      "768:\tlearn: 0.0620045\ttotal: 10.6s\tremaining: 3.19s\n",
      "769:\tlearn: 0.0619769\ttotal: 10.6s\tremaining: 3.17s\n",
      "770:\tlearn: 0.0619652\ttotal: 10.6s\tremaining: 3.16s\n",
      "771:\tlearn: 0.0619501\ttotal: 10.6s\tremaining: 3.14s\n",
      "772:\tlearn: 0.0619398\ttotal: 10.7s\tremaining: 3.13s\n",
      "773:\tlearn: 0.0619140\ttotal: 10.7s\tremaining: 3.12s\n",
      "774:\tlearn: 0.0618805\ttotal: 10.7s\tremaining: 3.1s\n",
      "775:\tlearn: 0.0618512\ttotal: 10.7s\tremaining: 3.09s\n",
      "776:\tlearn: 0.0618324\ttotal: 10.7s\tremaining: 3.07s\n",
      "777:\tlearn: 0.0617983\ttotal: 10.7s\tremaining: 3.06s\n",
      "778:\tlearn: 0.0617728\ttotal: 10.7s\tremaining: 3.05s\n",
      "779:\tlearn: 0.0617714\ttotal: 10.8s\tremaining: 3.03s\n",
      "780:\tlearn: 0.0617451\ttotal: 10.8s\tremaining: 3.02s\n",
      "781:\tlearn: 0.0617156\ttotal: 10.8s\tremaining: 3s\n",
      "782:\tlearn: 0.0617026\ttotal: 10.8s\tremaining: 2.99s\n",
      "783:\tlearn: 0.0616523\ttotal: 10.8s\tremaining: 2.98s\n",
      "784:\tlearn: 0.0616301\ttotal: 10.8s\tremaining: 2.96s\n",
      "785:\tlearn: 0.0616280\ttotal: 10.8s\tremaining: 2.95s\n",
      "786:\tlearn: 0.0616170\ttotal: 10.8s\tremaining: 2.94s\n",
      "787:\tlearn: 0.0616068\ttotal: 10.9s\tremaining: 2.92s\n",
      "788:\tlearn: 0.0615826\ttotal: 10.9s\tremaining: 2.91s\n",
      "789:\tlearn: 0.0615633\ttotal: 10.9s\tremaining: 2.89s\n",
      "790:\tlearn: 0.0615391\ttotal: 10.9s\tremaining: 2.88s\n",
      "791:\tlearn: 0.0615159\ttotal: 10.9s\tremaining: 2.87s\n",
      "792:\tlearn: 0.0614888\ttotal: 10.9s\tremaining: 2.85s\n",
      "793:\tlearn: 0.0614427\ttotal: 10.9s\tremaining: 2.84s\n",
      "794:\tlearn: 0.0614171\ttotal: 11s\tremaining: 2.83s\n",
      "795:\tlearn: 0.0613844\ttotal: 11s\tremaining: 2.81s\n",
      "796:\tlearn: 0.0613549\ttotal: 11s\tremaining: 2.8s\n",
      "797:\tlearn: 0.0613146\ttotal: 11s\tremaining: 2.78s\n",
      "798:\tlearn: 0.0613069\ttotal: 11s\tremaining: 2.77s\n",
      "799:\tlearn: 0.0612923\ttotal: 11s\tremaining: 2.76s\n",
      "800:\tlearn: 0.0612585\ttotal: 11s\tremaining: 2.74s\n",
      "801:\tlearn: 0.0612345\ttotal: 11.1s\tremaining: 2.73s\n",
      "802:\tlearn: 0.0611998\ttotal: 11.1s\tremaining: 2.71s\n",
      "803:\tlearn: 0.0611543\ttotal: 11.1s\tremaining: 2.7s\n",
      "804:\tlearn: 0.0610864\ttotal: 11.1s\tremaining: 2.69s\n",
      "805:\tlearn: 0.0610777\ttotal: 11.1s\tremaining: 2.67s\n",
      "806:\tlearn: 0.0610332\ttotal: 11.1s\tremaining: 2.66s\n",
      "807:\tlearn: 0.0610055\ttotal: 11.1s\tremaining: 2.65s\n",
      "808:\tlearn: 0.0609821\ttotal: 11.1s\tremaining: 2.63s\n",
      "809:\tlearn: 0.0609652\ttotal: 11.2s\tremaining: 2.62s\n",
      "810:\tlearn: 0.0609243\ttotal: 11.2s\tremaining: 2.6s\n",
      "811:\tlearn: 0.0609036\ttotal: 11.2s\tremaining: 2.59s\n",
      "812:\tlearn: 0.0608897\ttotal: 11.2s\tremaining: 2.58s\n",
      "813:\tlearn: 0.0608562\ttotal: 11.2s\tremaining: 2.56s\n",
      "814:\tlearn: 0.0608308\ttotal: 11.2s\tremaining: 2.55s\n",
      "815:\tlearn: 0.0608080\ttotal: 11.2s\tremaining: 2.53s\n",
      "816:\tlearn: 0.0607869\ttotal: 11.3s\tremaining: 2.52s\n",
      "817:\tlearn: 0.0607569\ttotal: 11.3s\tremaining: 2.51s\n",
      "818:\tlearn: 0.0607164\ttotal: 11.3s\tremaining: 2.49s\n",
      "819:\tlearn: 0.0606945\ttotal: 11.3s\tremaining: 2.48s\n",
      "820:\tlearn: 0.0606890\ttotal: 11.3s\tremaining: 2.46s\n",
      "821:\tlearn: 0.0606686\ttotal: 11.3s\tremaining: 2.45s\n",
      "822:\tlearn: 0.0606247\ttotal: 11.3s\tremaining: 2.44s\n",
      "823:\tlearn: 0.0606141\ttotal: 11.3s\tremaining: 2.42s\n",
      "824:\tlearn: 0.0606054\ttotal: 11.4s\tremaining: 2.41s\n",
      "825:\tlearn: 0.0605884\ttotal: 11.4s\tremaining: 2.4s\n",
      "826:\tlearn: 0.0605427\ttotal: 11.4s\tremaining: 2.38s\n",
      "827:\tlearn: 0.0605348\ttotal: 11.4s\tremaining: 2.37s\n",
      "828:\tlearn: 0.0605140\ttotal: 11.4s\tremaining: 2.36s\n",
      "829:\tlearn: 0.0605093\ttotal: 11.4s\tremaining: 2.34s\n",
      "830:\tlearn: 0.0604998\ttotal: 11.5s\tremaining: 2.33s\n",
      "831:\tlearn: 0.0604786\ttotal: 11.5s\tremaining: 2.32s\n",
      "832:\tlearn: 0.0604485\ttotal: 11.5s\tremaining: 2.3s\n",
      "833:\tlearn: 0.0604029\ttotal: 11.5s\tremaining: 2.29s\n",
      "834:\tlearn: 0.0603876\ttotal: 11.5s\tremaining: 2.27s\n",
      "835:\tlearn: 0.0603681\ttotal: 11.5s\tremaining: 2.26s\n",
      "836:\tlearn: 0.0603419\ttotal: 11.5s\tremaining: 2.25s\n",
      "837:\tlearn: 0.0603141\ttotal: 11.6s\tremaining: 2.23s\n",
      "838:\tlearn: 0.0602915\ttotal: 11.6s\tremaining: 2.22s\n",
      "839:\tlearn: 0.0602652\ttotal: 11.6s\tremaining: 2.21s\n",
      "840:\tlearn: 0.0602324\ttotal: 11.6s\tremaining: 2.19s\n",
      "841:\tlearn: 0.0602102\ttotal: 11.6s\tremaining: 2.18s\n",
      "842:\tlearn: 0.0601853\ttotal: 11.6s\tremaining: 2.16s\n",
      "843:\tlearn: 0.0601597\ttotal: 11.6s\tremaining: 2.15s\n",
      "844:\tlearn: 0.0601293\ttotal: 11.6s\tremaining: 2.14s\n",
      "845:\tlearn: 0.0601108\ttotal: 11.7s\tremaining: 2.12s\n",
      "846:\tlearn: 0.0600781\ttotal: 11.7s\tremaining: 2.11s\n",
      "847:\tlearn: 0.0600730\ttotal: 11.7s\tremaining: 2.1s\n",
      "848:\tlearn: 0.0600561\ttotal: 11.7s\tremaining: 2.08s\n",
      "849:\tlearn: 0.0600302\ttotal: 11.7s\tremaining: 2.07s\n",
      "850:\tlearn: 0.0599873\ttotal: 11.7s\tremaining: 2.05s\n",
      "851:\tlearn: 0.0599475\ttotal: 11.7s\tremaining: 2.04s\n",
      "852:\tlearn: 0.0599170\ttotal: 11.8s\tremaining: 2.03s\n",
      "853:\tlearn: 0.0599043\ttotal: 11.8s\tremaining: 2.01s\n",
      "854:\tlearn: 0.0598812\ttotal: 11.8s\tremaining: 2s\n",
      "855:\tlearn: 0.0598471\ttotal: 11.8s\tremaining: 1.99s\n",
      "856:\tlearn: 0.0598274\ttotal: 11.8s\tremaining: 1.97s\n",
      "857:\tlearn: 0.0598129\ttotal: 11.8s\tremaining: 1.96s\n",
      "858:\tlearn: 0.0597873\ttotal: 11.8s\tremaining: 1.94s\n",
      "859:\tlearn: 0.0597758\ttotal: 11.9s\tremaining: 1.93s\n",
      "860:\tlearn: 0.0597556\ttotal: 11.9s\tremaining: 1.92s\n",
      "861:\tlearn: 0.0597317\ttotal: 11.9s\tremaining: 1.9s\n",
      "862:\tlearn: 0.0596857\ttotal: 11.9s\tremaining: 1.89s\n",
      "863:\tlearn: 0.0596803\ttotal: 11.9s\tremaining: 1.87s\n",
      "864:\tlearn: 0.0596622\ttotal: 11.9s\tremaining: 1.86s\n",
      "865:\tlearn: 0.0596225\ttotal: 11.9s\tremaining: 1.85s\n",
      "866:\tlearn: 0.0596107\ttotal: 12s\tremaining: 1.83s\n",
      "867:\tlearn: 0.0595919\ttotal: 12s\tremaining: 1.82s\n",
      "868:\tlearn: 0.0595629\ttotal: 12s\tremaining: 1.8s\n",
      "869:\tlearn: 0.0595433\ttotal: 12s\tremaining: 1.79s\n",
      "870:\tlearn: 0.0595240\ttotal: 12s\tremaining: 1.78s\n",
      "871:\tlearn: 0.0595033\ttotal: 12s\tremaining: 1.76s\n",
      "872:\tlearn: 0.0594966\ttotal: 12s\tremaining: 1.75s\n",
      "873:\tlearn: 0.0594632\ttotal: 12s\tremaining: 1.74s\n",
      "874:\tlearn: 0.0594597\ttotal: 12.1s\tremaining: 1.72s\n",
      "875:\tlearn: 0.0594504\ttotal: 12.1s\tremaining: 1.71s\n",
      "876:\tlearn: 0.0594127\ttotal: 12.1s\tremaining: 1.7s\n",
      "877:\tlearn: 0.0593910\ttotal: 12.1s\tremaining: 1.68s\n",
      "878:\tlearn: 0.0593235\ttotal: 12.1s\tremaining: 1.67s\n",
      "879:\tlearn: 0.0593122\ttotal: 12.1s\tremaining: 1.65s\n",
      "880:\tlearn: 0.0592963\ttotal: 12.1s\tremaining: 1.64s\n",
      "881:\tlearn: 0.0592727\ttotal: 12.2s\tremaining: 1.63s\n",
      "882:\tlearn: 0.0592426\ttotal: 12.2s\tremaining: 1.61s\n",
      "883:\tlearn: 0.0592334\ttotal: 12.2s\tremaining: 1.6s\n",
      "884:\tlearn: 0.0592229\ttotal: 12.2s\tremaining: 1.58s\n",
      "885:\tlearn: 0.0592208\ttotal: 12.2s\tremaining: 1.57s\n",
      "886:\tlearn: 0.0592019\ttotal: 12.2s\tremaining: 1.56s\n",
      "887:\tlearn: 0.0591907\ttotal: 12.2s\tremaining: 1.54s\n",
      "888:\tlearn: 0.0591616\ttotal: 12.3s\tremaining: 1.53s\n",
      "889:\tlearn: 0.0591543\ttotal: 12.3s\tremaining: 1.52s\n",
      "890:\tlearn: 0.0591311\ttotal: 12.3s\tremaining: 1.5s\n",
      "891:\tlearn: 0.0591201\ttotal: 12.3s\tremaining: 1.49s\n",
      "892:\tlearn: 0.0591076\ttotal: 12.3s\tremaining: 1.47s\n",
      "893:\tlearn: 0.0590817\ttotal: 12.3s\tremaining: 1.46s\n",
      "894:\tlearn: 0.0590751\ttotal: 12.3s\tremaining: 1.45s\n",
      "895:\tlearn: 0.0590426\ttotal: 12.3s\tremaining: 1.43s\n",
      "896:\tlearn: 0.0590101\ttotal: 12.4s\tremaining: 1.42s\n",
      "897:\tlearn: 0.0589704\ttotal: 12.4s\tremaining: 1.41s\n",
      "898:\tlearn: 0.0589635\ttotal: 12.4s\tremaining: 1.39s\n",
      "899:\tlearn: 0.0589426\ttotal: 12.4s\tremaining: 1.38s\n",
      "900:\tlearn: 0.0589131\ttotal: 12.4s\tremaining: 1.36s\n",
      "901:\tlearn: 0.0588890\ttotal: 12.4s\tremaining: 1.35s\n",
      "902:\tlearn: 0.0588676\ttotal: 12.4s\tremaining: 1.34s\n",
      "903:\tlearn: 0.0588543\ttotal: 12.5s\tremaining: 1.32s\n",
      "904:\tlearn: 0.0588355\ttotal: 12.5s\tremaining: 1.31s\n",
      "905:\tlearn: 0.0588186\ttotal: 12.5s\tremaining: 1.29s\n",
      "906:\tlearn: 0.0587904\ttotal: 12.5s\tremaining: 1.28s\n",
      "907:\tlearn: 0.0587113\ttotal: 12.5s\tremaining: 1.27s\n",
      "908:\tlearn: 0.0586839\ttotal: 12.5s\tremaining: 1.25s\n",
      "909:\tlearn: 0.0586654\ttotal: 12.5s\tremaining: 1.24s\n",
      "910:\tlearn: 0.0586464\ttotal: 12.6s\tremaining: 1.23s\n",
      "911:\tlearn: 0.0586343\ttotal: 12.6s\tremaining: 1.21s\n",
      "912:\tlearn: 0.0586173\ttotal: 12.6s\tremaining: 1.2s\n",
      "913:\tlearn: 0.0586010\ttotal: 12.6s\tremaining: 1.19s\n",
      "914:\tlearn: 0.0585935\ttotal: 12.6s\tremaining: 1.17s\n",
      "915:\tlearn: 0.0585795\ttotal: 12.6s\tremaining: 1.16s\n",
      "916:\tlearn: 0.0585579\ttotal: 12.7s\tremaining: 1.14s\n",
      "917:\tlearn: 0.0585444\ttotal: 12.7s\tremaining: 1.13s\n",
      "918:\tlearn: 0.0585263\ttotal: 12.7s\tremaining: 1.12s\n",
      "919:\tlearn: 0.0585024\ttotal: 12.7s\tremaining: 1.1s\n",
      "920:\tlearn: 0.0584807\ttotal: 12.7s\tremaining: 1.09s\n",
      "921:\tlearn: 0.0584523\ttotal: 12.7s\tremaining: 1.08s\n",
      "922:\tlearn: 0.0584385\ttotal: 12.7s\tremaining: 1.06s\n",
      "923:\tlearn: 0.0584027\ttotal: 12.8s\tremaining: 1.05s\n",
      "924:\tlearn: 0.0583733\ttotal: 12.8s\tremaining: 1.03s\n",
      "925:\tlearn: 0.0583644\ttotal: 12.8s\tremaining: 1.02s\n",
      "926:\tlearn: 0.0583627\ttotal: 12.8s\tremaining: 1.01s\n",
      "927:\tlearn: 0.0583529\ttotal: 12.8s\tremaining: 994ms\n",
      "928:\tlearn: 0.0583244\ttotal: 12.8s\tremaining: 980ms\n",
      "929:\tlearn: 0.0582997\ttotal: 12.8s\tremaining: 966ms\n",
      "930:\tlearn: 0.0582735\ttotal: 12.9s\tremaining: 953ms\n",
      "931:\tlearn: 0.0582299\ttotal: 12.9s\tremaining: 939ms\n",
      "932:\tlearn: 0.0582028\ttotal: 12.9s\tremaining: 925ms\n",
      "933:\tlearn: 0.0581856\ttotal: 12.9s\tremaining: 911ms\n",
      "934:\tlearn: 0.0581552\ttotal: 12.9s\tremaining: 897ms\n",
      "935:\tlearn: 0.0581250\ttotal: 12.9s\tremaining: 883ms\n",
      "936:\tlearn: 0.0580977\ttotal: 12.9s\tremaining: 870ms\n",
      "937:\tlearn: 0.0580764\ttotal: 13s\tremaining: 857ms\n",
      "938:\tlearn: 0.0580567\ttotal: 13s\tremaining: 843ms\n",
      "939:\tlearn: 0.0580405\ttotal: 13s\tremaining: 830ms\n",
      "940:\tlearn: 0.0580129\ttotal: 13s\tremaining: 816ms\n",
      "941:\tlearn: 0.0579920\ttotal: 13s\tremaining: 803ms\n",
      "942:\tlearn: 0.0579418\ttotal: 13.1s\tremaining: 789ms\n",
      "943:\tlearn: 0.0579190\ttotal: 13.1s\tremaining: 775ms\n",
      "944:\tlearn: 0.0579007\ttotal: 13.1s\tremaining: 761ms\n",
      "945:\tlearn: 0.0578873\ttotal: 13.1s\tremaining: 747ms\n",
      "946:\tlearn: 0.0578517\ttotal: 13.1s\tremaining: 733ms\n",
      "947:\tlearn: 0.0578346\ttotal: 13.1s\tremaining: 720ms\n",
      "948:\tlearn: 0.0578209\ttotal: 13.1s\tremaining: 706ms\n",
      "949:\tlearn: 0.0577918\ttotal: 13.1s\tremaining: 692ms\n",
      "950:\tlearn: 0.0577829\ttotal: 13.2s\tremaining: 678ms\n",
      "951:\tlearn: 0.0577552\ttotal: 13.2s\tremaining: 664ms\n",
      "952:\tlearn: 0.0577325\ttotal: 13.2s\tremaining: 650ms\n",
      "953:\tlearn: 0.0577152\ttotal: 13.2s\tremaining: 636ms\n",
      "954:\tlearn: 0.0577049\ttotal: 13.2s\tremaining: 623ms\n",
      "955:\tlearn: 0.0576779\ttotal: 13.2s\tremaining: 609ms\n",
      "956:\tlearn: 0.0576649\ttotal: 13.2s\tremaining: 595ms\n",
      "957:\tlearn: 0.0576573\ttotal: 13.3s\tremaining: 581ms\n",
      "958:\tlearn: 0.0576458\ttotal: 13.3s\tremaining: 567ms\n",
      "959:\tlearn: 0.0576405\ttotal: 13.3s\tremaining: 553ms\n",
      "960:\tlearn: 0.0576058\ttotal: 13.3s\tremaining: 540ms\n",
      "961:\tlearn: 0.0575859\ttotal: 13.3s\tremaining: 526ms\n",
      "962:\tlearn: 0.0575784\ttotal: 13.3s\tremaining: 512ms\n",
      "963:\tlearn: 0.0575693\ttotal: 13.3s\tremaining: 498ms\n",
      "964:\tlearn: 0.0575442\ttotal: 13.3s\tremaining: 484ms\n",
      "965:\tlearn: 0.0575431\ttotal: 13.4s\tremaining: 470ms\n",
      "966:\tlearn: 0.0575246\ttotal: 13.4s\tremaining: 456ms\n",
      "967:\tlearn: 0.0575033\ttotal: 13.4s\tremaining: 443ms\n",
      "968:\tlearn: 0.0574772\ttotal: 13.4s\tremaining: 429ms\n",
      "969:\tlearn: 0.0574603\ttotal: 13.4s\tremaining: 415ms\n",
      "970:\tlearn: 0.0574507\ttotal: 13.4s\tremaining: 401ms\n",
      "971:\tlearn: 0.0574262\ttotal: 13.4s\tremaining: 387ms\n",
      "972:\tlearn: 0.0573975\ttotal: 13.5s\tremaining: 373ms\n",
      "973:\tlearn: 0.0573823\ttotal: 13.5s\tremaining: 359ms\n",
      "974:\tlearn: 0.0573629\ttotal: 13.5s\tremaining: 346ms\n",
      "975:\tlearn: 0.0573324\ttotal: 13.5s\tremaining: 332ms\n",
      "976:\tlearn: 0.0573146\ttotal: 13.5s\tremaining: 318ms\n",
      "977:\tlearn: 0.0572715\ttotal: 13.5s\tremaining: 304ms\n",
      "978:\tlearn: 0.0572438\ttotal: 13.5s\tremaining: 290ms\n",
      "979:\tlearn: 0.0572256\ttotal: 13.5s\tremaining: 277ms\n",
      "980:\tlearn: 0.0572004\ttotal: 13.6s\tremaining: 263ms\n",
      "981:\tlearn: 0.0571737\ttotal: 13.6s\tremaining: 249ms\n",
      "982:\tlearn: 0.0571543\ttotal: 13.6s\tremaining: 235ms\n",
      "983:\tlearn: 0.0571266\ttotal: 13.6s\tremaining: 221ms\n",
      "984:\tlearn: 0.0570974\ttotal: 13.6s\tremaining: 207ms\n",
      "985:\tlearn: 0.0570614\ttotal: 13.6s\tremaining: 193ms\n",
      "986:\tlearn: 0.0570400\ttotal: 13.6s\tremaining: 180ms\n",
      "987:\tlearn: 0.0570243\ttotal: 13.7s\tremaining: 166ms\n",
      "988:\tlearn: 0.0570027\ttotal: 13.7s\tremaining: 152ms\n",
      "989:\tlearn: 0.0569727\ttotal: 13.7s\tremaining: 138ms\n",
      "990:\tlearn: 0.0569586\ttotal: 13.7s\tremaining: 124ms\n",
      "991:\tlearn: 0.0569379\ttotal: 13.7s\tremaining: 111ms\n",
      "992:\tlearn: 0.0569186\ttotal: 13.7s\tremaining: 96.7ms\n",
      "993:\tlearn: 0.0569055\ttotal: 13.7s\tremaining: 82.9ms\n",
      "994:\tlearn: 0.0568905\ttotal: 13.7s\tremaining: 69.1ms\n",
      "995:\tlearn: 0.0568693\ttotal: 13.8s\tremaining: 55.3ms\n",
      "996:\tlearn: 0.0568491\ttotal: 13.8s\tremaining: 41.4ms\n",
      "997:\tlearn: 0.0568058\ttotal: 13.8s\tremaining: 27.6ms\n",
      "998:\tlearn: 0.0567894\ttotal: 13.8s\tremaining: 13.8ms\n",
      "999:\tlearn: 0.0567600\ttotal: 13.8s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9595555555555556"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(random_state=26)\n",
    "model.fit(X_train, y_train)\n",
    "preds_class = model.predict(X_test)\n",
    "f1_score(preds_class, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.12**\n",
    "\n",
    "Выведите матрицу ошибок для алгоритма, который получил наилучшие показатели качества модели на обучающей выборке (будем считать, что оцениваем по f1_score). Матрица ошибок выводится в следующем формате:\n",
    "\n",
    "<img src=\"data\\MATHML_md9_6_2.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "Значения в матрице ошибок переведите в проценты от общего числа наблюдений в обучающей выборке и округлите до целых.\n",
    "\n",
    "Подсказка. Для того чтобы построить матрицу ошибок в CatBoost, необходимо использовать следующий шаблон:   \n",
    "\n",
    "    get_confusion_matrix(модель, Pool(признаки обучающей выборки, целевая переменная обучающей выборки))\n",
    "\n",
    "Более подробно построение матрицы ошибок можно изучить в документации https://catboost.ai/en/docs/concepts/python-reference_utils_get_confusion_matrix.\n",
    "\n",
    "Заполните соответствующие значения (в процентах от общего числа наблюдений в обучающей выборке, округленных до целого):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46665.   541.]\n",
      " [ 1256. 34661.]]\n"
     ]
    }
   ],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "from catboost.utils import get_confusion_matrix\n",
    "\n",
    "cm = get_confusion_matrix(model, Pool(X_train, y_train))\n",
    "print(cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6.13**\n",
    "\n",
    "Оцените важность признаков для модели из предыдущего задания. Отметьте признак, который оказывает наибольшее влияние на значение целевой переменной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>feature_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.329103</td>\n",
       "      <td>Inflight wifi service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.161031</td>\n",
       "      <td>Type of Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.429019</td>\n",
       "      <td>Online boarding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.293092</td>\n",
       "      <td>Customer Type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.514859</td>\n",
       "      <td>Class_Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.938168</td>\n",
       "      <td>Checkin service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.797618</td>\n",
       "      <td>Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.698958</td>\n",
       "      <td>Baggage handling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.256603</td>\n",
       "      <td>Gate location</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.935592</td>\n",
       "      <td>Inflight service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.923553</td>\n",
       "      <td>Seat comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.805014</td>\n",
       "      <td>Inflight entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.011917</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.688502</td>\n",
       "      <td>Flight Distance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.549199</td>\n",
       "      <td>Departure/Arrival time convenient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.525832</td>\n",
       "      <td>Cleanliness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.496001</td>\n",
       "      <td>Ease of Online booking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.381004</td>\n",
       "      <td>On-board service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.244024</td>\n",
       "      <td>Leg room service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.870628</td>\n",
       "      <td>Arrival Delay in Minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.463406</td>\n",
       "      <td>Departure Delay in Minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.324055</td>\n",
       "      <td>Food and drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.155390</td>\n",
       "      <td>Class_Eco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.149305</td>\n",
       "      <td>Class_Eco Plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058131</td>\n",
       "      <td>Gender</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature_importance                      feature_names\n",
       "6            25.329103              Inflight wifi service\n",
       "4            18.161031                     Type of Travel\n",
       "11            7.429019                    Online boarding\n",
       "2             7.293092                      Customer Type\n",
       "22            5.514859                     Class_Business\n",
       "17            3.938168                    Checkin service\n",
       "3             3.797618                                Age\n",
       "16            3.698958                   Baggage handling\n",
       "9             3.256603                      Gate location\n",
       "18            2.935592                   Inflight service\n",
       "12            2.923553                       Seat comfort\n",
       "13            2.805014             Inflight entertainment\n",
       "0             2.011917                                 id\n",
       "5             1.688502                    Flight Distance\n",
       "7             1.549199  Departure/Arrival time convenient\n",
       "19            1.525832                        Cleanliness\n",
       "8             1.496001             Ease of Online booking\n",
       "14            1.381004                   On-board service\n",
       "15            1.244024                   Leg room service\n",
       "21            0.870628           Arrival Delay in Minutes\n",
       "20            0.463406         Departure Delay in Minutes\n",
       "10            0.324055                     Food and drink\n",
       "23            0.155390                          Class_Eco\n",
       "24            0.149305                     Class_Eco Plus\n",
       "1             0.058131                             Gender"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "{\n",
    "\"feature_importance\": model.get_feature_importance(),\n",
    "\"feature_names\": df.drop(columns=\"satisfaction\").columns,\n",
    "}\n",
    ").sort_values(by=[\"feature_importance\"], ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Поздравляем, вы справились с достаточно сложной задачей и добились высокого качества выделения. Советуем не останавливаться на достигнутом и попробовать организовать наиболее посещаемый ансамбль. Тем не менее, будьте готовы: перебор гиперпараметров на большие объёмы данных занимает достаточно много времени.\n",
    "\n",
    "Уже в следующем юните вы изучите ещё один вид ансамблей и пополните свой арсенал алгоритмов →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Стекинг"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В предыдущих юнитах мы разобрались с ансамблями, в которых объединение нескольких моделей одного типа помогает повысить качество предсказания при решении задачи регрессии или классификации. А что, если мы объединим модели двух или трёх типов (например, логистическую регрессию, метод опорных векторов и KNN)? Может быть, это сделает результат ещё лучше? Да, это действительно может помочь. В некоторых случаях очень полезно использовать различные виды моделей, чтобы повысить точность прогнозирования.\n",
    "\n",
    "? Тогда возникает следующий вопрос: как именно мы можем объединить несколько моделей разных типов?\n",
    "\n",
    "Здесь нам на помощь приходит **стекинг** — третий вид ансамблирования моделей. Принцип реализации стекинга мы уже обсудили в одном из предыдущих модулей, а в этом юните мы формализуем всё изученное в чёткий алгоритм и ещё раз закрепим этот материал. Математических выкладок здесь уже практически не будет, так как стекинг является абсолютной эвристикой, под которой нет никакого теоретического фундамента — его эффективность можно наблюдать только на практике."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Стекинг** —  это агрегация ответов моделей машинного обучения. Подход использует понятие **базовых моделей**, каждая из которых обучается независимо от остальных, и **метамодели**, которая использует предсказания базовых моделей как признаки."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_7_1.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что мы обучили K базовых моделей $a_1 (x), ..., a_K (x)$ на некоторой выборке и теперь хотим использовать их результаты для обучения метамодели $f(x)$.\n",
    "\n",
    "Самый простой вариант — обучить метамодель на той же выборке. Тогда функция потерь будет выражаться следующим образом:\n",
    "\n",
    "$\\sum_{i=1}^{N} L\\left(y_{i}, f\\left(a_{1}\\left(x_{i}\\right), \\ldots, a_{K}\\left(x_{i}\\right)\\right)\\right) \\rightarrow \\min _{f}$\n",
    "\n",
    "→ В таком случае метамодель $f$ будет отдавать предпочтение тем базовым алгоритмам, которые сильнее других подстроились под целевую переменную при обучении, так как по их прогнозам проще всего предсказывать правильные ответы. Если среди базовых алгоритмов будет тот, который просто запомнил все ответы на обучающей выборке, то метаалгоритму будет проще всего использовать только прогнозы данного переобученного базового алгоритма, ведь такой подход будет давать максимальный результат. Но, разумеется, высокое качество в таком случае будет только на обучающей выборке — на тестовой оно будет значительно хуже.\n",
    "\n",
    "Поэтому важно отметить, что базовые алгоритмы и метамодель должны обучаться на разных выборках. \n",
    "\n",
    "Разобьём выборку на $L$ частей: $X_1, X_2, ..., X_L$. Пусть $a^{-l}_j (x)$ — это базовый $j$-й алгоритм, который обучен на всех подвыборках, кроме первой.\n",
    "\n",
    "Для обучения метамодели мы будем минимизировать следующий функционал:\n",
    "\n",
    "$\\sum_{l=1}^{L} \\sum_{\\left(x_{i}, y_{j}) \\in X_{l}\\right.} L\\left(y_{i}, f\\left(a_{1}^{-l}\\left(x_{i}\\right), \\ldots, a_{K}^{-l}\\left(x_{i}\\right)\\right)\\right) \\rightarrow \\min _{f}$\n",
    "\n",
    "Как мы уже выяснили, чтобы избежать переобучения, необходимо обучать базовые модели и метамодель на разных выборках. Это можно делать с помощью **блендинга** или **стекинга**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### БЛЕНДИНГ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объясним его суть на примере ↓\n",
    "\n",
    "Предположим, у нас есть обучающая выборка $X$, которую мы делим пополам: первая часть используется для обучения базовых моделей, а на второй базовые модели делают предсказания — метапризнаки, на которых и обучается в дальнейшем метамодель.\n",
    "\n",
    "Формализовать этот алгоритм можно следующим образом:\n",
    "\n",
    "- Пусть у нас есть обучающая выборка $(X,y)$ и тестовая выборка $(X_{test}, y_{test})$.\n",
    "Мы хотим использовать $K$ базовых моделей: $a_1 (x), a_2 (x), ..., a_K (x)$.\n",
    "- Делим обучающую выборку на две части: $(X_{train}, y_{train})$ и $(X_{meta}, y_{meta})$.\n",
    "- Введём для удобства обозначения: $(X_{train}, y_{train}) = A, \\ (X_{meta}, y_{meta}) = B, \\ (X_{test}, y_{test}) = C$.\n",
    "- Для каждой модели $a_i (x)$:\n",
    "    - Обучаем модель $a_i (x)$ на подвыборке $A$.\n",
    "    - Для каждого объекта из подвыборки B делаем предсказание с помощью $a_i (x)$ — получаем столбец новых признаков для метамодели.\n",
    "    - Для каждого объекта из подвыборки C делаем предсказание с помощью $a_i (x)$ — получаем ещё один столбец признаков для метамодели.\n",
    "- Итак, получили матрицу метапризнаков $B_{meta}$ из предсказаний $a_i (x)$ для подвыборки $B$ и матрицу метапризнаков $C_{meta}$ из предсказаний $a_i (x)$ для подвыборки $C$.\n",
    "- Обучаем метамодель на подвыборке $B_{meta}$.\n",
    "- С помощью обученной метамодели делаем предсказания для всех объектов из $C_{meta}$ — это и будут наши ответы.\n",
    "Важно отметить, что для блендинга можно и нужно использовать базовые алгоритмы разной природы: например, вы можете объединять KNN, метод опорных векторов, решающие деревья и на результатах этих базовых алгоритмов обучать метамодель.\n",
    "\n",
    "Метамодель тоже может быть разной природы, но часто в качестве неё берут просто линейную модель:\n",
    "\n",
    "$f(x) = \\sum^K_{i = 1} w_i a_i (x)$\n",
    "\n",
    "Схематично описанный выше алгоритм можно изобразить следующим образом:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_7_2.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СТЕКИНГ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, у блендинга есть проблема: ни базовые модели, ни метамодель не обучаются на полных данных.\n",
    "\n",
    "Эту проблему решает **стекинг**.\n",
    "\n",
    "Чтобы в итоге все модели могли «познакомиться» с полным набором данных, можно использовать подход, аналогичный кросс-валидации: мы можем разделять выборку на $L$ частей, обучать модель на части $L-1$ и делать предсказание на оставшейся. Определённого правила для выбора количества частей нет, но, разумеется, чем больше их будет, тем выше будет качество (времени на обучение также будет потрачено больше)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм стекинга следующий:\n",
    "\n",
    "- Пусть у нас есть обучающая выборка $(X,y)$ и тестовая выборка $(X_{test}, y_{test})$.\n",
    "- Мы хотим использовать $K$ базовых моделей: $a_1 (x), a_2 (x), ..., a_K (x)$.\n",
    "- Делим обучающую выборку $L$ частей: $A_1, A_2, ..., A_L$.\n",
    "- Для каждой части $A_i$ из $L$ частей обучающей выборки:\n",
    "    - Обучаем все $K$ базовых моделей на всех частях выборки, кроме $A_i$.\n",
    "    - Делаем предсказание для каждого объекта из подвыборки $A_i$.\n",
    "    - В итоге получаем новые признаки для метамодели.\n",
    "- Обучаем базовые модели на всей обучающей выборке $(X,y)$, делаем предсказание на тестовой выборке $(X_{test}, y_{test})$ и получаем метапризнаки для тестовой выборки — матрицу $C_{meta}$.\n",
    "- Обучаем метаалгоритм на новых признаках метамодели из обучающей выборки.\n",
    "- Делаем предсказание с помощью метаалгоритма для $C_{meta}$ — это и будут наши ответы.\n",
    "  \n",
    "Схематично можно изобразить это так:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_7_3.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несомненный **плюс стекинга** в том, что использование различных видов алгоритмов может помочь идентифицировать сложные зависимости. Например, ниже можно видеть иллюстрацию задачи классификации, где структура данных довольно сложная, но при использовании нескольких алгоритмов получается её выявить."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_7_4.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также метод стекинга можно реализовать с более чем двумя уровнями — это называется **многоуровневым стекингом**. В таком случае мы определяем базовые модели, затем обучаем ряд метамоделей на результатах базовых моделей и в итоге обучаем конечную метамодель. Рассматривать и реализовывать такой подход мы не будем, так как улучшение качества будет незначительным, а вычислительные затраты — невероятно высокими."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_7_5.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, вы заметили, что принцип многоуровневого стекинга очень похож на принцип работы искусственных нейронных сетей, о которых мы говорили ранее в модуле про оптимизацию, и это действительно так.\n",
    "\n",
    "Давайте вспомним **плюсы и минусы стекинга**, которые мы уже рассматривали в предыдущих модулях:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\happy-icon.png\" alt=\"drawing\" width=\"50\"/> \n",
    "\n",
    "- хорошо параллелится (модели обучаются параллельно);\n",
    "- хорошо подходит для использования различных по природе базовых моделей. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\sad-icon.png\" alt=\"drawing\" width=\"50\"/> \n",
    "\n",
    "- качество сильно зависит от качества базовых моделей;\n",
    "- плохо интерпретируемые результаты."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда теоретические основы изучены, наступает время практики: потренируемся в решении задач с использованием стекинга ↓\n",
    "\n",
    "Мы будем работать с данными, которые содержат информацию о звуках, издаваемых лягушками, и характеристики этих звуков https://lms.skillfactory.ru/assets/courseware/v1/a21a8975fee2a747c0a0f335a4a9e0f4/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/Frogs_MFCCs.zip.\n",
    "\n",
    "Необходимо классифицировать семейства лягушек в зависимости от особенностей их кваканья и прочих звуковых эффектов.\n",
    "\n",
    "Будем решать задачу бинарной классификации по выявлению лягушек, которые относятся к семейству 'Dendrobatidae' (признак 'Family'). Семейство 'Dendrobatidae' будет классом 1, все остальные семейства — классом 0.\n",
    "\n",
    "<img src=\"data\\MATHML_md9_7_6.jpg\" alt=\"drawing\" width=\"300\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве признаков, которые мы будем использовать для предсказания, необходимо взять все, кроме:\n",
    "\n",
    "'Family' — семейство лягушек;  \n",
    "'Genus' — род лягушек;  \n",
    "'Species' — вид лягушек;  \n",
    "'RecordID' — ID записи.  \n",
    "\n",
    "Все остальные признаки относятся к акустическим особенностям кваканья — они-то нам и понадобятся, чтобы определить, к какому семейству относится лягушка."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделите выборку на обучающую и тестовую в соотношении 80/20, параметр random_state = 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0       1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1       1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2       1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3       1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4       1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "\n",
       "   MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  \\\n",
       "0 -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568  0.057684   \n",
       "1 -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303  0.020140   \n",
       "2 -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722 -0.025083   \n",
       "3 -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498 -0.054766   \n",
       "4 -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550 -0.031346   \n",
       "\n",
       "   MFCCs_21  MFCCs_22           Family      Genus         Species  RecordID  \n",
       "0  0.118680  0.014038  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "1  0.082263  0.029056  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "2  0.099108  0.077162  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "3 -0.018691  0.023954  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "4  0.108610  0.079244  Leptodactylidae  Adenomera  AdenomeraAndre         1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/Frogs_MFCCs.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Family'] = df['Family'].apply(lambda x: 1 if x == 'Dendrobatidae' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6653\n",
       "1     542\n",
       "Name: Family, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Family'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1439,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(['Family', 'Genus', 'Species', 'RecordID'], axis = 1)\n",
    "y = df['Family']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=31)\n",
    "y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7.5**\n",
    "\n",
    "Для начала обучите на наших данных случайный лес с десятью решающими деревьями. Воспользуйтесь параметрами по умолчанию. В качестве значения random_state возьмите число 42.\n",
    "\n",
    "Оцените значение F_1-меры и введите его в качестве ответа, предварительно округлив до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9726775956284154"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model_rfc = ensemble.RandomForestClassifier(10, random_state=42)\n",
    "model_rfc.fit(X_train, y_train)\n",
    "pred = model_rfc.predict(X_test)\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7.6**\n",
    "\n",
    "Теперь попробуем улучшить качество нашего предсказания за счёт использования стекинга.\n",
    "\n",
    "В качестве базовых моделей выберите следующие:\n",
    "\n",
    "случайный лес с десятью деревьями, random_state = 31;\n",
    "KNN, количество соседей = 11;\n",
    "наивный байесовский классификатор с параметрами по умолчанию, в качестве метода возьмите GaussianNB().\n",
    "В качестве метамодели выберите логистическую регрессию.\n",
    "\n",
    "Обучите модели и сделайте предсказание целевой метки для тестового набора данных.\n",
    "\n",
    "Рассчитайте F_1-меру для тестового набора данных и введите её в качестве ответа, предварительно округлив до двух знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989247311827957"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes  import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "estimators = [('rf', ensemble.RandomForestClassifier(n_estimators=10, random_state=31)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors= 11)),\n",
    "    ('nb', GaussianNB() )\n",
    "]\n",
    "metamodel = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")\n",
    "metamodel.fit(X_train, y_train)\n",
    "pred = metamodel.predict(X_test)\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, мы увидели, как сильно улучшает качество применение стекинга. Несмотря на недостатки этого метода (долгое обучение, необходимость подбора параметров, редкое использование на практике — зачастую лишь для того, чтобы добыть дополнительные баллы на Kaggle), в определённых ситуациях он может быть очень полезен. Если у вас достаточно вычислительных ресурсов, вы готовы потратить время на подбор моделей и параметров, а точность модели крайне важна, стекинг сослужит вам хорошую службу.\n",
    "\n",
    "Теперь, когда в вашем арсенале есть все ансамблевые методы, нам осталось лишь подвести итоги этого модуля"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Итоги"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ В этом модуле мы рассмотрели ансамблевые методы машинного обучения. Мы не только повторили основные концепции, но и разобрались с математическими основами алгоритмов.\n",
    "\n",
    "Давайте ещё раз посмотрим на те ансамбли, которые мы изучили:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_8_1.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткое описание бэггинга**   \n",
    "Параллельное обучение одинаковых алгоритмов. Результирующий прогноз формируется как среднее арифметическое моделей (случай регрессии) или по большему количеству голосов (случай классификации)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_8_2.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткое описание бустинга**  \n",
    "Последовательное обучение одинаковых алгоритмов, каждый из которых исправляет ошибки предыдущих до достижения необходимого качества."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\MATHML_md9_8_3.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Краткое описание стекинга**  \n",
    "Параллельное и независимое обучение моделей (не обязательно одной природы), использование их как факторов для обучения метамодели, которая и формирует итоговый результат."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь для каждого ансамбля вы можете:\n",
    "\n",
    "- объяснить его суть и рассказать про стоящую за ним математическую составляющую;\n",
    "- применить его для решения задачи классификации и регрессии;\n",
    "- настроить гиперпараметры ансамбля так, чтобы получить наилучшее качество модели.  \n",
    "\n",
    "Если вы хотите ознакомиться с **дополнительными материалами**, чтобы ещё больше углубить свои знания, рекомендуем обратить внимание на следующие статьи:\n",
    "\n",
    "- О тонкостях настройки гиперпараметров в ансамблях https://habr.com/ru/post/672486/  \n",
    "- О развитии ансамблевых методов машинного обучения https://www.researchgate.net/publication/278019662_Istoria_razvitia_ansamblevyh_metodov_klassifikacii_v_masinnom_obucenii  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Поздравляем, вы справились со всеми заданиями, и теперь можно считать, что вы прекрасно разбираетесь в ансамблях моделей, а главное — понимаете их математические основы и сможете ответить даже на самые сложные вопросы на собеседовании при приёме на работу.\n",
    "\n",
    "Вы ещё встретитесь с ансамблями при выполнении проекта, а в следующих модулях вас ждёт увлекательное изучение математических тонкостей алгоритмов кластеризации →"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
