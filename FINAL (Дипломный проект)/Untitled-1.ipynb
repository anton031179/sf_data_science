{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заранее импортируем модули, которые понадобятся нам для решения задачи:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прочитаем файл с исходными данными:\n",
    "data = pd.read_csv(\"data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число найденных дубликатов: 50\n"
     ]
    }
   ],
   "source": [
    "# Проанализируем датасет на наличие дублирующихся записей\n",
    "# data = df_train\n",
    "dupl_columns = list(data.columns)\n",
    "# dupl_columns.remove('id')\n",
    "\n",
    "mask = data.duplicated(subset=dupl_columns)\n",
    "data_duplicates = data[mask]\n",
    "print(f'Число найденных дубликатов: {data_duplicates.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результирующее число записей: 377135\n"
     ]
    }
   ],
   "source": [
    "# удалим дубликаты\n",
    "data = data.drop_duplicates(subset=dupl_columns)\n",
    "print(f'Результирующее число записей: {data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "private pool    98.891378\n",
       "mls-id          93.386453\n",
       "PrivatePool     89.311520\n",
       "fireplace       72.659127\n",
       "stories         39.952007\n",
       "baths           28.188315\n",
       "beds            24.196640\n",
       "MlsId           17.730786\n",
       "sqft            10.752118\n",
       "status          10.584274\n",
       "propertyType     9.209699\n",
       "target           0.657589\n",
       "city             0.009015\n",
       "street           0.000530\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверим датасет на наличие пропусков в данных\n",
    "cols_null_percent = data.isnull().mean() * 100\n",
    "cols_with_null = cols_null_percent[cols_null_percent > 0].sort_values(\n",
    "    ascending=False)\n",
    "display(cols_with_null)\n",
    "# data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим строки, в которых отсутствуют значения целевого признака\n",
    "\n",
    "data.dropna(subset=['target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция разбиения значений признака: \n",
    "\n",
    "def set_sign(col, key):\n",
    "    delimiters = \" |/|, |: |\\n\"\n",
    "    # data_list = col.split(' ')\n",
    "    data_list = re.split(delimiters, col)\n",
    "    if key in data_list:\n",
    "        return key\n",
    "    else: return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция объединения близких по смыслу значений признака по ключевым словам:\n",
    "\n",
    "def comb_val(col, lst):\n",
    "    for item in lst:\n",
    "        data[col] = data[col].astype('str').apply(set_sign, key=item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция переназначения значений признака по словарю:\n",
    "\n",
    "def remap_val(dict, col):\n",
    "        data[col] = data[col].replace(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция вывода количества уникальных значений признака:\n",
    "\n",
    "def uniq_val_count(col):\n",
    "    # pd.set_option(\"display.max_rows\", None)\n",
    "    # col = 'status'\n",
    "    print(data[col].value_counts(dropna=False))\n",
    "    print(f'Число найденных уникальных значений = {len(pd.unique(data[col]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция построения гистогаммы распределения признака col:\n",
    "\n",
    "def  sign_hist(col):\n",
    "    df = px.data.tips()\n",
    "    fig = px.histogram(data, x=col)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция однократного кодирования признака col:\n",
    "\n",
    "def  onehot_cod(col):\n",
    "    encoder = ce.OneHotEncoder(cols=[col]) # указываем столбец для кодирования\n",
    "    type_bin = encoder.fit_transform(data[col])\n",
    "    data = pd.concat([data, type_bin], axis=1)\n",
    "    data.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция бинорного кодирования признака col:\n",
    "\n",
    "def  binary_cod(col):\n",
    "    bin_encoder = ce.BinaryEncoder(cols=[col]) # указываем столбец для кодирования\n",
    "    type_bin = bin_encoder.fit_transform(data[col])\n",
    "    data = pd.concat([data, type_bin], axis=1)\n",
    "    data.drop([col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# объединим близкие по смыслу значений признаки по ключевым словам:\n",
    "\n",
    "col = 'status'\n",
    "lst = ['Active', 'Pending', 'Coming', 'Contract', 'Contingent', 'New', 'Backup', 'Pre-foreclosure', 'Sold', 'backups', 'Backups']\n",
    "comb_val(col, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переназначим значения признака по словарю с учетом сокращений, регистра символов и присвоения пустым ячейкам значения Unknown:\n",
    "\n",
    "col = 'status'\n",
    "dict = {'Coming':'Coming soon', 'Apartment for rent':'For rent', 'P':'Pending', 'Ps':'Pending', 'pending':'Pending', \n",
    "        'Uc Continue To Show':'Contract', 'Under contract':'Contract', 'C Continue Show':'Contingent', \n",
    "        'Re Activated':'Reactivated', 'Pf':'Pending', 'Pi':'Pending', 'Ct':'Contract', 'Back On Market':'Back on Market',\n",
    "        'For Sale':'For sale', 'for sale':'For sale', 'for rent':'For rent', 'C':'Contract', ' / auction':'Auction', 'nan':'Unknown', \n",
    "        'Condo for rent':'For rent', 'backups':'Backup', 'Backups':'Backup'}\n",
    "remap_val(dict, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For sale                            199520\n",
      "Active                              106554\n",
      "Unknown                              39256\n",
      "Pending                               6889\n",
      "New                                   6148\n",
      "foreclosure                           5677\n",
      "Pre-foreclosure                       3281\n",
      "Contract                              3121\n",
      "Auction                               1292\n",
      "Contingent                             996\n",
      "Price Change                           563\n",
      "For rent                               412\n",
      "Foreclosure                            343\n",
      "Foreclosed                             294\n",
      "Back on Market                         112\n",
      "Coming soon                            110\n",
      "Listing Extended                        28\n",
      "Due Diligence Period                    27\n",
      "CT Insp - Inspection Contingency        10\n",
      "Contingency 48 Hr (+/ )                  5\n",
      "Closed                                   5\n",
      "Accepted Offer                           4\n",
      "Backup                                   4\n",
      "Reactivated                              3\n",
      "Lease/Purchase                           1\n",
      "Name: status, dtype: int64\n",
      "Число найденных уникальных значений = 25\n"
     ]
    }
   ],
   "source": [
    "# выведем полученный перечень уникальных значений признака после преобразований:\n",
    "\n",
    "col = 'status'\n",
    "uniq_val_count(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Построим гистогамму распределения признака col:\n",
    "\n",
    "# col = 'status'\n",
    "# sign_hist(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # используем двоичное кодирование для кодировки признака status\n",
    "\n",
    "# on_cod(col)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. private pool, PrivatePool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN    370504\n",
      "Yes      4151\n",
      "Name: private pool, dtype: int64\n",
      "Число найденных уникальных значений = 2\n"
     ]
    }
   ],
   "source": [
    "col = 'private pool'\n",
    "uniq_val_count(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим есть ли пересечения непустых значений в столбцах private pool, PrivatePool\n",
    "\n",
    "mask1 = data['private pool'].notna()\n",
    "mask2 = data['PrivatePool'].notna()\n",
    "data[mask1 & mask2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# т.к. пересечений непустых значений нет объединим данные о наличии бассейна в один столбец\n",
    "\n",
    "data['PrivatePool'] = data['PrivatePool'].fillna(data['private pool'])\n",
    "data = data.drop(['private pool'], axis=1)\n",
    "data['PrivatePool'] = data['PrivatePool'].replace({'yes': 'Yes'})\n",
    "data['PrivatePool'] = data['PrivatePool'].fillna(value='No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     330384\n",
      "Yes     44271\n",
      "Name: PrivatePool, dtype: int64\n",
      "Число найденных уникальных значений = 2\n"
     ]
    }
   ],
   "source": [
    "# выведем полученный перечень уникальных значений признака после преобразований:\n",
    "\n",
    "col = 'PrivatePool'\n",
    "uniq_val_count(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Построим гистогамму распределения признака col:\n",
    "\n",
    "# col = 'PrivatePool'\n",
    "# sign_hist(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # используем однократное кодирование для кодировки признака PrivatePool\n",
    "\n",
    "# onehot_cod(col)\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. propertyType**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single-family home                                             91370\n",
      "Single Family                                                  61886\n",
      "NaN                                                            34554\n",
      "Single Family Home                                             31725\n",
      "condo                                                          25874\n",
      "                                                               ...  \n",
      "1 Story, Contemporary, Other (See Remarks)                         1\n",
      "Custom, Elevated, Other                                            1\n",
      "Contemporary, Farmhouse                                            1\n",
      "2 Stories, Traditional, Mediterranean, Texas Hill Country          1\n",
      "Bilevel, Converted Dwelling, Loft with Bedrooms, Condo/Unit        1\n",
      "Name: propertyType, Length: 1280, dtype: int64\n",
      "Число найденных уникальных значений = 1280\n"
     ]
    }
   ],
   "source": [
    "col = 'propertyType'\n",
    "uniq_val_count(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. street**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число найденных уникальных значений = 334752\n"
     ]
    }
   ],
   "source": [
    "# выведем количество уникальных значений признака street:\n",
    "col = 'street'\n",
    "print(f'Число найденных уникальных значений = {len(pd.unique(data[col]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # выведем полученный перечень уникальных значений признака street:\n",
    "\n",
    "# uniq_val_count(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['street'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['street'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 374655 entries, 0 to 377184\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   status        374655 non-null  object\n",
      " 1   propertyType  340101 non-null  object\n",
      " 2   baths         269308 non-null  object\n",
      " 3   homeFacts     374655 non-null  object\n",
      " 4   fireplace     102519 non-null  object\n",
      " 5   city          374621 non-null  object\n",
      " 6   schools       374655 non-null  object\n",
      " 7   sqft          334560 non-null  object\n",
      " 8   zipcode       374655 non-null  object\n",
      " 9   beds          283726 non-null  object\n",
      " 10  state         374655 non-null  object\n",
      " 11  stories       224902 non-null  object\n",
      " 12  mls-id        24937 non-null   object\n",
      " 13  PrivatePool   374655 non-null  object\n",
      " 14  MlsId         310187 non-null  object\n",
      " 15  target        374655 non-null  object\n",
      "dtypes: object(16)\n",
      "memory usage: 48.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
