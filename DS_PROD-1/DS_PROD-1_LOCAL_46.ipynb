{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Введение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДОБРО ПОЖАЛОВАТЬ В РАЗДЕЛ, ПОСВЯЩЁННЫЙ МОДЕЛЯМ МАШИННОГО ОБУЧЕНИЯ В PRODUCTION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели машинного обучения сами по себе никому не нужны — они создаются для того, чтобы приносить пользу. В этом и последующих модулях мы разберём, как заставить ML-модель работать на бизнес."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ЭТОМ РАЗДЕЛЕ ВЫ:\n",
    "\n",
    "Узнаете:\n",
    "\n",
    "- о различных способах применения ML-моделей;\n",
    "- таких понятиях, как изолированность, оркестрация и контейнеризация;\n",
    "- больше о жизненном цикле ML-моделей и о том, как происходит их разработка в DS-командах на стадии выведения модели в production;\n",
    "- как учесть требование воспроизводимости среды в DS-проекте;\n",
    "- особенности монолитной и микросервисной архитектур, организации взаимодействия между сервисами;\n",
    "\n",
    "Научитесь:\n",
    "\n",
    "- формулировать требования продакшн-среды к ML-моделям;\n",
    "- сохранять ML-модели в зависимости от этих требований;\n",
    "- разрабатывать простейшие веб-сервисы для деплоя моделей на Flask;\n",
    "- создавать контейнеры для своих моделей и работать с Docker и Docker-compose;\n",
    "- оценивать качество моделей после внедрения в production."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы уже умеете создавать модели машинного обучения: они выдают какие-то предсказания, и вы научились оценивать их с помощью метрик качества. Вы можете составлять графики и делать выводы на основе данных. Но что дальше?\n",
    "\n",
    "Важно задать себе следующие вопросы:\n",
    "\n",
    "- Какими будут основные потребители результатов? Это будут другие сервисы? Или модель будет встроена в мобильное приложение?\n",
    "- Как и в каком виде потребители ожидают получать результаты? По времени или по запросу? Если по запросу, то по каким правилам они будут его осуществлять?\n",
    "- Какая для этого существует (или планируется) инфраструктура?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ВСПОМИНАЕМ CRISP-DM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует множество методологий для управления Data Science-проектами. Наиболее распространённой методологией разработки является знакомая нам модель Cross-Industry Standard Process for Data Mining, или CRISP-DM. Давайте ещё раз взглянем на её этапы:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_1_2.png\" alt=\"drawing\" width=\"450\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Если вы забыли, что из себя представляет методология разработки CRISP-DM, рекомендуем заглянуть в модуль ML-1. «Теория машинного обучения».\n",
    "\n",
    "На этапе внедрения мы должны понять, будет ли происходить деградация модели во времени в связи с изменением распределений входных данных и возможно ли автоматизировать оценку качества, обновление моделей и их деплой.\n",
    "\n",
    "Как учесть все эти сложности в процессе разработки моделей? Вот с этим мы и будем разбираться."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ДЕПЛОЙ МОДЕЛИ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача развёртывания приложения на сервере называется деплой (от англ. deployment — внедрение, развёртывание). По сути, это процесс трансформации исходного кода вашего приложения в рабочее состояние на конкретном сервере.\n",
    "\n",
    "Для того чтобы внедрить модель в продакшн (в минимальном варианте), необходимо:\n",
    "\n",
    "- Сохранить обученную модель в файл.\n",
    "- Поднять сервер.\n",
    "- Доставить и запустить на нём свою модель.\n",
    "\n",
    "Звучит довольно просто, не так ли?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_1_3.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, при моделировании зачастую не учитываются вопросы, связанные с деплоем модели и её внедрением в уже существующие системы. Для чего мы обучили модель? Может быть, мы будем использовать её для чат-бота? Может, она должна быть встроена в приложение для iPhone? Как часто потребуется переобучать модель?\n",
    "\n",
    "Опыт подсказывает, что если модель создаётся «в вакууме», то в итоге её просто нельзя будет вывести в продакшн.\n",
    "\n",
    "Дополнительной проблемой является то, что большинство библиотек для машинного обучения сфокусированы именно на **обучении**, а не на **предсказании**.\n",
    "\n",
    "Кроме того, в крупных компаниях дата-сайентисты, дата-инженеры, ML-инженеры, занимающиеся внедрением моделей в продакшн, могут быть не просто разными людьми, но и разными командами. На практике может оказаться так, что готовая обученная модель будет внедрена другой командой на другом языке программирования. При этом обычным разработчикам модели машинного обучения могут представляться непрозрачными загадочными чёрными ящиками.\n",
    "\n",
    "В этом модуле мы будем учиться подготавливать модели к внедрению в продакшн и разворачивать собственный веб-сервис. Как вы увидите дальше, код, который мы написали в Jupyter Notebook, практически никогда не попадает в продакшн без изменений."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЦЕЛИ ЭТОГО МОДУЛЯ:\n",
    "\n",
    "- Понять, что такое инференс модели и как организуется сохранение и загрузка модели.\n",
    "- Узнать, что такое сериализация и десериализация и научиться их различать.\n",
    "- Понять, что делать, если итоговый проект реализован на другом языке программирования, а ваша модель обучена на Python.\n",
    "- Рассмотреть вопросы сетевого взаимодействия и узнать о настройке взаимодействия между серверами по сети.\n",
    "- Закрепить умение писать запросы к серверу (мы затрагивали эту тему в модуле PY-17. «Как получать данные из веб-источников и API», но теперь веб-источник мы будем создавать сами).\n",
    "- Разобрать основные отличия и области применения фреймворков для разработки веб-сервисов (Django, FastAPI и, конечно, Flask).\n",
    "- Научиться использовать фреймворк Flask для реализации простейших сервисов моделей.\n",
    "- Познакомиться с инструментами uWSGI и NGINX, которые помогают повысить пропускную способность и производительность сервера."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Сохранение и загрузка моделей: pickle и joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представьте ситуацию: вы садитесь за руль автомобиля, и… вам нужно заново учиться водить! Сложная ситуация, не правда ли? В реальности мы просто заводим машину, включаем передачу и начинаем движение.\n",
    "\n",
    "Примерно того же продакшн-среда требует от моделей. И это понятно, ведь намного дешевле с точки зрения расходования ресурсов хранить данные в виде готовой модели, чем каждый раз заново обучать модель на сервере из восьми видеокарт.\n",
    "\n",
    "Именно поэтому код, который был написан для обучения модели и оценки её качества, крайне редко используется для **инференса** (от англ inference — вывод). Так называется непрерывная работа алгоритма машинного обучения в конечном приложении. По этой причине при внедрении моделей в продакшн их принято сохранять в готовом виде, то есть уже обученными и готовыми решать реальные задачи."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_2_1.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изучив материалы в этом юните, вы сможете:\n",
    "\n",
    "1. Подробно разобраться с тем, как с помощью библиотеки pickle сохранять обученные модели машинного обучения, загружать их обратно и заново обращаться к ним для предсказаний.\n",
    "2. Узнать о способах передачи моделей для внедрения на языках программирования, отличных от Python.\n",
    "3. Разобраться с темой **сериализации**.\n",
    "   \n",
    "**Совет**. Обязательно попробуйте воспроизвести примеры, которые мы будем разбирать далее."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СЕРИАЛИЗАЦИЯ И ДЕСЕРИАЛИЗАЦИЯ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и почти всё в языке программирования Python, обученная модель является **объектом**. Этот объект не простой, поскольку модель содержит сложную иерархию классов — в каждом классе есть набор полей, ссылающихся на объекты других классов, и так далее.\n",
    "\n",
    "Например, объект класса RandomForestClassifier https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html из библиотеки sklearn содержит множество полей, часть из которых устанавливается во время инициализации модели (максимальная глубина, количество деревьев в ансамбле, критерий информативности и т. д.), а часть определяется во время обучения модели (последовательность предикатов внутри каждого дерева в ансамбле, значимость признаков). Наша задача — «законсервировать» этот объект (модель), сохранив значение всех полей, которые мы задали при инициализации объекта и получили по итогам обучения. То есть мы должны сохранить модель, включая её внешние и внутренние параметры.\n",
    "\n",
    "Чтобы гарантировать сохранение всей структуры данных и получить её при загрузке обратно, используется сериализация.\n",
    "\n",
    "**Сериализация** — это процесс трансформации любой структуры данных, поддерживаемой в языке, в последовательность битов (или байтов). Обратной операцией является **десериализации**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_2_2.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ЗАЧЕМ ЭТО НУЖНО?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То, в каком виде данные записаны на диск, зачастую может сильно отличаться от того, в каком виде они существуют в памяти программы. И там, и там это будут байты информации, но в файле будет представлена просто их последовательность, а в памяти программы это может быть какой-то объект или даже несколько объектов со структурой.\n",
    "\n",
    "Приведём простой пример с форматом CSV. Пусть у нас есть файл с одной строкой, где несколько слов записаны через запятую. На диске это будет записано просто как последовательность байтов.\n",
    "\n",
    "Однако когда мы считываем эту последовательность внутри программы, мы хотим работать с ней как со списком строк, то есть нам нужно не только считать эти данные, но и применить к ним некоторое преобразование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word1', ' word2', ' word3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = 'word1, word2, word3'\n",
    "line.split(\",\")\n",
    "#### ['word1', 'word2', 'word3']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что после этого преобразования появилось много объектов (каждое слово списка) и некоторая структура (то, как слова расположены в этом списке). Процесс, который мы только что выполнили, называется **десериализацией**.\n",
    "\n",
    "Также возможен обратный процесс, когда мы хотим сохранить в виде последовательности байтов какие-то данные из памяти программы. Например, нам нужно снова получить начальную строку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word1,word2,word3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(['word1', 'word2', 'word3'])\n",
    "\n",
    "## word1,word2,word3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот процесс как раз и называется **сериализацией**.\n",
    "\n",
    "Мы разобрали простейший пример, но на практике всё гораздо сложнее. Сериализовывать можно не только в текст (как с CSV, JSON и подобными форматами), но и в **бинарный** формат, который человек не сможет прочитать.\n",
    "\n",
    "Бывают форматы, которые могут описывать более сложные структуры (тот же JSON). Также можно добавить сжатие итогового набора битов.\n",
    "\n",
    "Заметим, что программа должна потратить некоторый ресурс CPU, чтобы преобразовать объект в набор байтов и наоборот."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ИНСТРУМЕНТЫ СЕРИАЛИЗАЦИИ: PICKLE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, с помощью каких средств происходит сериализация объектов в Python.\n",
    "\n",
    "В стандартную библиотеку Python входит модуль pickle https://docs.python.org/3/library/pickle.html, который служит для сериализации почти всех объектов произвольного типа.\n",
    "\n",
    "Мы помним, что объекты находятся в оперативной памяти и направляются в байтовые потоки ввода-вывода. В байтовые потоки может быть направлен любой файлоподобный объект.\n",
    "\n",
    "В ходе десериализации исходный объект воссоздаётся в оперативной памяти с теми же самыми значениями, но с новой идентичностью — новым адресом в памяти."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_2_4.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ШАГ №1**\n",
    "\n",
    "Обучим модель линейной регрессии на встроенном датасете о диабете — Diabetes dataset.\n",
    "\n",
    "В данном датасете представлены десять исходных признаков: возраст, пол, индекс массы тела, среднее артериальное давление и шесть измерений сыворотки крови были получены для каждого из 442 пациентов с сахарным диабетом. Интерес представляет количественный показатель прогресса заболевания, замеренный через год после исходного измерения. Тип задачи — регрессия.\n",
    "\n",
    "**Примечание**. Для простоты и наглядности мы опустим процесс предобработки данных, разведывательный анализ, разделение выборки на обучающую и тестовую, валидацию модели и подбор гиперпараметров, так как для наших целей это неважно. Мы уверены, что вы уже способны произвести эти этапы самостоятельно.\n",
    "\n",
    "В качестве модели, прогнозирующей целевую переменную, возьмём простейшую линейную регрессию, и обучим её на исходных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Загружаем датасет о диабете\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "# Инициализируем модель линейной регрессии\n",
    "regressor = LinearRegression()\n",
    "# Обучаем модель\n",
    "regressor.fit(X,y)\n",
    "\n",
    "## LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате выполнения кода получился объект класса LinearRegression, на который ссылается переменная regressor. При этом атрибуты объекта (веса модели линейной регрессии) были сформированы во время обучения. То есть объект regressor теперь является обученной моделью."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ШАГ №2**\n",
    "\n",
    "Далее, когда мы получили обученную модель, нам необходимо сериализовать её, превратив объект Python в поток байтов. Для этого импортируем модуль pickle и воспользуемся функцией dumps(), в которую нужно передать объект Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'sklearn.linear_model._base.LinearRegression'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Производим сериализацию обученной модели\n",
    "model = pickle.dumps(regressor)\n",
    "\n",
    "print(type(model))\n",
    "print(type(regressor))\n",
    "## bytes\n",
    "## sklearn.linear_model._base.LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, мы создали объект model типа bytes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ШАГ №3**\n",
    "\n",
    "Давайте попробуем восстановить (десериализовать) объект Python. Для этого в модуле pickle есть функция loads(), в которую нужно передать сериализованный объект (поток байтов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Производим десериализацию\n",
    "regressor_from_bytes = pickle.loads(model)\n",
    "regressor_from_bytes\n",
    "## LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате десериализации мы смогли восстановить исходный объект (модель)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ШАГ №4**\n",
    "\n",
    "Сохраним сериализованный объект прямо в файл. Для этого в pickle есть функция dump() (без s на конце). В неё необходимо передать имя файла или ссылку на открытый файл. Файл назовём myfile, его расширение — .pkl (формат данных pickle):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Производим сериализацию и записываем результат в файл формата pkl\n",
    "with open('myfile.pkl', 'wb') as output:\n",
    "    pickle.dump(regressor, output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть бинарный файл с готовой моделью, и мы можем передать его, например, ML-инженерам, которые будут заниматься деплоем модели на сервер."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ШАГ №5**\n",
    "\n",
    "Посмотрим на код, который восстанавливает (десериализует) обученную модель из файла myfile.pkl. Для этого в pickle есть функция load() (без s на конце). В неё необходимо передать имя файла или ссылку на открытый файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Производим десериализацию и извлекаем модель из файла формата pkl\n",
    "with open('myfile.pkl', 'rb') as pkl_file:\n",
    "    regressor_from_file = pickle.load(pkl_file)\n",
    "\n",
    "regressor_from_file\n",
    "## LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ШАГ №6**\n",
    "\n",
    "Убедимся, что методы и результаты предсказаний обученной модели и модели, загруженной из файла, совпадают:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверяем, что все элементы массивов предсказаний совпадают между собой\n",
    "all(regressor.predict(X) == regressor_from_bytes.predict(X))\n",
    "## True\n",
    "all(regressor.predict(X) == regressor_from_file.predict(X))\n",
    "## True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видите, исходная и восстановленная из байтов и файла модели дают одинаковые предсказания. Это значит, что теперь мы можем импортировать наши обученные модели в любое Python-приложение и пользоваться ими, минуя этап обучения и все этапы, предшествующие ему."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ОГРАНИЧЕНИЯ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы упоминали, у pickle есть ограничения. Например, мы не можем сериализовать лямбда-функции. Давайте посмотрим, что нам вернёт следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_lambda = lambda x: x*2\n",
    "# with open('my_lambda.pkl', 'wb') as output:\n",
    "#     pickle.dump(my_lambda, output)\n",
    " \n",
    "# ##\"PicklingError: Can't pickle <function <lambda>\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет. В таких случаях лучше пользоваться пакетом dill https://github.com/uqfoundation/dill."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СОХРАНЕНИЕ ПАЙПЛАЙНА"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы посмотрели простейший пример сериализации готовой модели.\n",
    "\n",
    "У вас мог возникнуть вопрос: что делать, если перед подачей данных в модель их необходимо предобработать, например произвести стандартизацию, исключить неинформативные признаки? Неужели придётся прописывать все эти шаги в коде инференса модели? А что если вопросами инференса занимаются совершенно другие специалисты, которые вообще ничего не знают о машинном обучении и не умеют производить предобработку данных?\n",
    "\n",
    "Конечно, мы должны передать результаты в таком виде, чтобы ими можно было воспользоваться без лишних манипуляций.\n",
    "\n",
    "Мы уже упоминали, что pickle работает с любыми объектами Python. Поэтому для сохранения может быть доступна не просто обученная модель, но и целый **пайплайн**, включающий предобработку данных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Если вы забыли, что такое пайплайны и как их формировать с помощью библиотеки sklearn, рекомендуем заглянуть в модуль ML-8. «Продвинутые методы машинного обучения» https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/da4e838982b64a649afd5c7cd3a993d4.\n",
    "\n",
    "Например, мы хотим сериализовать пайплайн, который включает в себя min-max-нормализацию и отбор пяти наиболее важных факторов на основе корреляции Пирсона. Полученные в результате данные отправляются на вход модели линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Scaling&#x27;, MinMaxScaler()),\n",
       "                (&#x27;FeatureSelection&#x27;,\n",
       "                 SelectKBest(k=5,\n",
       "                             score_func=&lt;function f_regression at 0x0000022B2BF2DCF0&gt;)),\n",
       "                (&#x27;Linear&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Scaling&#x27;, MinMaxScaler()),\n",
       "                (&#x27;FeatureSelection&#x27;,\n",
       "                 SelectKBest(k=5,\n",
       "                             score_func=&lt;function f_regression at 0x0000022B2BF2DCF0&gt;)),\n",
       "                (&#x27;Linear&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=5, score_func=&lt;function f_regression at 0x0000022B2BF2DCF0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Scaling', MinMaxScaler()),\n",
       "                ('FeatureSelection',\n",
       "                 SelectKBest(k=5,\n",
       "                             score_func=<function f_regression at 0x0000022B2BF2DCF0>)),\n",
       "                ('Linear', LinearRegression())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Загружаем датасет о диабете\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "# Создаём пайплайн, который включает нормализацию, отбор признаков и обучение модели\n",
    "pipe = Pipeline([  \n",
    "  ('Scaling', MinMaxScaler()),\n",
    "  ('FeatureSelection', SelectKBest(f_regression, k=5)),\n",
    "  ('Linear', LinearRegression())\n",
    "  ])\n",
    "\n",
    "# Обучаем пайплайн\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пайплайн обучен. Давайте сохраним его в файл с помощью pickle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сериализуем pipeline и записываем результат в файл\n",
    "with open('my_pipeline.pkl', 'wb') as output:\n",
    "    pickle.dump(pipe, output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если сериализация завершилась успешно, то при инференсе модели мы сможем восстановить её из файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Десериализуем pipeline из файла\n",
    "with open('my_pipeline.pkl', 'rb') as pkl_file:\n",
    "    loaded_pipe = pickle.load(pkl_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, что результаты исходного и десериализованного пайплайнов и идентичны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Сравниваем предсказания исходного и восстановленного пайплайнов\n",
    "print(all(pipe.predict(X) == loaded_pipe.predict(X)))\n",
    "\n",
    "## True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Если мы хотим сохранять сериализованные пайплайны в виде потока байтов, нужно использовать функции dumps() и loads(), а не dump() и load().\n",
    "\n",
    "Однако в процессе предобработки могут возникнуть шаги, которые нельзя реализовать стандартными методами sklearn. Например, для решения многих задач в нашем курсе мы часто использовали feature engineering, чтобы повысить качество работы моделей. Как встроить этот шаг в исходный пайплайн?\n",
    "\n",
    "Для этого в sklearn можно организовать так называемые **кастомные трансформеры**. Такой трансформер должен наследоваться от двух классов: TransformerMixin и BaseEstimator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на шаблон кастомного трансформера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class MyTransformer(TransformerMixin, BaseEstimator):\n",
    "    '''Шаблон кастомного трансформера'''\n",
    " \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Здесь прописывается инициализация параметров, не зависящих от данных.\n",
    "        '''\n",
    "        pass\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        '''\n",
    "        Здесь прописывается «обучение» трансформера.\n",
    "        Вычисляются необходимые для работы трансформера параметры (если они нужны).\n",
    "        '''\n",
    "\n",
    "        return self\n",
    " \n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Здесь прописываются действия с данными.\n",
    "        '''\n",
    "        return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У трансформера должно быть **три обязательных метода**:\n",
    "\n",
    "- __init__() — метод, который вызывается при создании объекта данного класса. Он предназначен для инициализации исходных параметров.\n",
    "Например, у трансформера для создания полиномиальных признаков PolynomialFeatures из sklearn в методе __init__() параметр degree задаёт степень полинома.  \n",
    "- fit() — метод, который вызывается для «обучения» трансформера. Он должен возвращать ссылку на сам объект (self).\n",
    "Например, в трансформере StandardScaler в методе fit() прописано вычисление среднего значения и стандартного отклонения в каждом столбце таблицы, переданной в качестве параметра метода fit().  \n",
    "- transform() — метод, который трансформирует приходящие на вход данные. Он должен возвращать преобразованный массив данных.\n",
    "Например, при вызове метода transform() у StandardScaler из sklearn внутри происходит преобразование — вычитание из каждого столбца среднего и деление результата на стандартное отклонение. Причём среднее и стандартное отклонение вычисляются заранее в методе fit().  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Как мы знаем, у некоторых трансформеров из sklearn, например у того же MinMaxScaler, есть ещё и метод fit_transform(), который является комбинацией методов fit() и transform().\n",
    "\n",
    "Наш трансформер пока что ничего не делает. Предположим, мы хотим генерировать в данных новый признак, который является простым произведением первых трёх столбцов таблицы. Давайте пропишем в методе transform() эти действия.\n",
    "\n",
    "Для работы такого трансформера нужны только исходные данные без дополнительных параметров, поэтому методы __init__() и fit() остаются без изменений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyTransformer(TransformerMixin, BaseEstimator):\n",
    "#     '''Шаблон кастомного трансформера'''\n",
    "\n",
    "\n",
    "#     def __init__(self):\n",
    "#         '''Здесь прописывается инициализация параметров, не зависящих от данных.'''\n",
    "#         pass\n",
    "\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         '''\n",
    "#         Здесь прописывается «обучение» трансформера.\n",
    "#         Вычисляются необходимые для работы трансформера параметры (если они нужны).\n",
    "#         '''\n",
    "#         return self\n",
    "\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         '''Здесь прописываются действия с данными.'''\n",
    "#         # Создаём новый столбец как произведение первых трёх\n",
    "#         new_column = X[:, 0] * X[:, 1] * X[:, 2]\n",
    "#         # Для добавления столбца в массив нужно изменить его размер на (n_rows, 1)\n",
    "#         new_column = new_column.reshape(X.shape[0], 1)\n",
    "#         # Добавляем столбец в матрицу измерений\n",
    "#         X = np.append(X, new_column, axis=1)\n",
    "#         return X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как работает наш кастомный трансформер. Создадим объект трансформера, вызовем метод transform и посмотрим на результирующий размер таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before transform: (442, 10)\n",
      "Shape after transform: (442, 10)\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем объект класса MyTransformer (вызывается метод __init__)\n",
    "custom_transformer = MyTransformer()\n",
    "# Чисто формально вызываем метод fit, но у нас он ничего не делает\n",
    "custom_transformer.fit(X)\n",
    "# Трансформируем исходные данные (вызывается метод transform)\n",
    "X_transformed = custom_transformer.transform(X)\n",
    "print('Shape before transform: {}'.format(X.shape))\n",
    "print('Shape after transform: {}'.format(X_transformed.shape))\n",
    "\n",
    "## Shape before transform: (442, 10)\n",
    "## Shape after transform: (442, 11)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что в результате трансформации в исходную матрицу наблюдений добавился новый столбец.\n",
    "\n",
    "Теперь давайте встроим этот трансформер в сам пайплайн — для этого достаточно добавить новый шаг в пайплайн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;FeatureEngineering&#x27;, MyTransformer()),\n",
       "                (&#x27;Scaling&#x27;, MinMaxScaler()),\n",
       "                (&#x27;FeatureSelection&#x27;,\n",
       "                 SelectKBest(k=5,\n",
       "                             score_func=&lt;function f_regression at 0x0000022B2BF2DCF0&gt;)),\n",
       "                (&#x27;Linear&#x27;, LinearRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;FeatureEngineering&#x27;, MyTransformer()),\n",
       "                (&#x27;Scaling&#x27;, MinMaxScaler()),\n",
       "                (&#x27;FeatureSelection&#x27;,\n",
       "                 SelectKBest(k=5,\n",
       "                             score_func=&lt;function f_regression at 0x0000022B2BF2DCF0&gt;)),\n",
       "                (&#x27;Linear&#x27;, LinearRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MyTransformer</label><div class=\"sk-toggleable__content\"><pre>MyTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=5, score_func=&lt;function f_regression at 0x0000022B2BF2DCF0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('FeatureEngineering', MyTransformer()),\n",
       "                ('Scaling', MinMaxScaler()),\n",
       "                ('FeatureSelection',\n",
       "                 SelectKBest(k=5,\n",
       "                             score_func=<function f_regression at 0x0000022B2BF2DCF0>)),\n",
       "                ('Linear', LinearRegression())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создаём пайплайн, который включает Feature Engineering, нормализацию, отбор признаков и обучение модели\n",
    "pipe = Pipeline([  \n",
    "  ('FeatureEngineering', MyTransformer()),\n",
    "  ('Scaling', MinMaxScaler()),\n",
    "  ('FeatureSelection', SelectKBest(f_regression, k=5)),\n",
    "  ('Linear', LinearRegression())\n",
    "  ])\n",
    "\n",
    "# Обучаем пайплайн\n",
    "pipe.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец можно сериализовать полученный pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сериализуем pipeline и записываем результат в файл\n",
    "with open('my_new_pipeline.pkl', 'wb') as output:\n",
    "    pickle.dump(pipe, output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем передать пайплайн и воспользоваться им для инференса, предварительно произведя десериализацию."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.5**\n",
    "\n",
    "Десериализуйте полученный pipeline с добавленным в него кастомной трансформации из файла. Затем предскажите значение целевой переменной для наблюдения, которое описывается следующим вектором:   \n",
    "np.array([[ 0.00538306, -0.04464164,  0.05954058, -0.05616605,  0.02457414, 0.05286081, -0.04340085,  0.05091436, -0.00421986, -0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В поле для ответа введите предсказанное значение целевой переменной, округлённое до целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173.]\n"
     ]
    }
   ],
   "source": [
    "# Десериализуем pipeline из файла\n",
    "with open('my_new_pipeline.pkl', 'rb') as pkl_file:\n",
    "    loaded_pipe = pickle.load(pkl_file)\n",
    "    features =np.array([[ 0.00538306, -0.04464164, 0.05954058, -0.05616605, 0.02457414, 0.05286081,\n",
    "    -0.04340085, 0.05091436, -0.00421986, -0.03007245]])\n",
    "# Формируем предсказание\n",
    "print(np.round(loaded_pipe.predict(features)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дополнение предлагаем вам ознакомиться с примерами использования пайплайнов (на англ. языке):\n",
    "\n",
    "- Sklearn Pipeline Tutorial https://www.kaggle.com/sermakarevich/sklearn-pipelines-tutorial;  \n",
    "- Pipeline Guide (GitHub) https://gist.github.com/amberjrivera/8c5c145516f5a2e894681e16a8095b5c;\n",
    "- A Simple Guide to Scikit-learn Pipelines https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### БИБЛИОТЕКА JOBLIB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, pickle прекрасно справляется со своей задачей: мы можем сериализовать и восстанавливать любые Python-объекты, включая модели и даже пайплайны. Однако иногда массивы данных, на которых обучаются модели, бывают настолько большими, что после загрузки из pickle невозможно восстановить объект полностью.\n",
    "\n",
    "В таких случаях вместо pickle лучше использовать библиотеку joblib. Этот модуль более эффективен и надёжен для работы с объектами, которые содержат большие массивы данных. Пожалуй, единственный минус этого модуля в том, что он может «консервировать» только в файл, поэтому вы не сможете получить объект в виде бинарной строки и работать с ним. В модуле попросту отсутствуют методы для работы с бинарной строкой. Формат файлов для сохранения — .joblib.\n",
    "\n",
    "В остальном работа с joblib полностью идентична работе с pickle: после обучения модели производим сериализацию с помощью функции dump(), а в коде самого приложения, где нужно использовать модель, выполняем десериализацию с помощью функции load(). В каждую из этих функций необходимо передать путь до файла для записи и чтения соответственно.\n",
    "\n",
    "Для иллюстрации работы сохраним полученную линейную регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regr.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Загружаем датасет о диабете\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "# Обучаем модель линейной регрессии\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "# Производим сериализацию и сохраняем результат в файл формата .joblib\n",
    "joblib.dump(regressor, 'regr.joblib')\n",
    "\n",
    "## ['regr.joblib']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим файл заново (загрузка может быть произведена в другом файле с кодом):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Десериализуем модель из файла\n",
    "clf_from_jobliv = joblib.load('regr.joblib') \n",
    "# Сравниваем предсказания\n",
    "all(regressor.predict(X) == clf_from_jobliv.predict(X))\n",
    "\n",
    "## True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Практика: pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_3_1.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом практическом юните этого модуля мы будем учиться работать с модулем pickle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваш коллега Василий обучил модель и теперь просит вас проверить её на ваших данных. Он присылает вам pickle-файл. Загрузите модель https://lms-cdn.skillfactory.ru/assets/courseware/v1/edb336d23fdbf18a919f9dbfad55426a/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/model.pkl, используя модуль pickle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.1**\n",
    "\n",
    "При загрузке вывелся секретный код. Введите его в поле ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret word: skillfactory\n",
      "how is this possible? answer is here: https://youtu.be/xm-A-h9QkXg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('data\\\\model.pkl', 'rb') as pkl_file:\n",
    "    model = pickle.load(pkl_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.2**\n",
    "\n",
    "Проверьте, объект какого типа получился. Какую модель вам прислал коллега?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret word: skillfactory\n",
      "how is this possible? answer is here: https://youtu.be/xm-A-h9QkXg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(positive=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(positive=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(positive=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data\\\\model.pkl', 'rb') as pkl_file:\n",
    "    regressor_from_file = pickle.load(pkl_file)\n",
    "regressor_from_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.3**\n",
    "\n",
    "Теперь необходимо применить модель. Сделайте предсказание для следующего набора фичей: [1, 1, 1, 0.661212487096872]. Введите результат, предварительно округлив его до трёх знаков после точки-разделителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.666]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([[1, 1, 1, 0.661212487096872]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У присланной вам модели есть два поля (атрибута) с именами a и b. Создайте из них словарь с такими же именами ключей и значениями, а затем сохраните его в файл с помощью модуля pickle.\n",
    "\n",
    "Чтобы вы могли проверить правильность решения задания, мы создали специальный проверочный скрипт. Скачайте его здесь https://lms-cdn.skillfactory.ru/assets/courseware/v1/9ece277164851c1c246712a4d3522fa4/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/hw1_check_ol.py.\n",
    "\n",
    "Сохраните его рядом с вашим pickle-файлом (в той же папке) и запустите, передав первым аргументом имя файла. Если вы всё сделали правильно, на экран выведется ответ для следующего задания."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**КАК ЗАПУСТИТЬ СКРИПТ?**\n",
    "\n",
    "В ячейке Jupyter Notebook:\n",
    "\n",
    "*!python hw1_check_ol.py имя_pickle_файла.pkl*\n",
    "\n",
    "В терминале:\n",
    "\n",
    "*cd имя_папки_со_скриптом*  \n",
    "*python hw1_check_ol.py имя_pickle_файла.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd data\n",
    "# python hw1_check_ol.py model.pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.4**\n",
    "\n",
    "Если вы всё сделали правильно, в результате выполнения проверочного скрипта будет выведен секретный код.  \n",
    "Впишите полученный код в окно ниже:  \n",
    "После решения задания проверочный скрипт можно удалить — больше он вам не понадобится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd C:\\Users\\Work\\Documents\\DataScience\\IDE\\DS_PROD-1\\data\n",
    "# python hw1_check_ol.py model.pkl\n",
    "\n",
    "# 3c508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret word: skillfactory\n",
      "how is this possible? answer is here: https://youtu.be/xm-A-h9QkXg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\hw1_check.py\", line 1, in <module>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\hw1_check.py\", line 1, in <lambda>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\hw1_check.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\hw1_check.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\hw1_check.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\hw1_check.py\", line 1, in <lambda>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\hw1_check.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\hw1_check.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "TypeError: 'LinearRegression' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "!python hw1_check.py model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret word: skillfactory\n",
      "how is this possible? answer is here: https://youtu.be/xm-A-h9QkXg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:288: UserWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.2.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\data\\hw1_check_ol.py\", line 1, in <module>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\data\\hw1_check_ol.py\", line 1, in <lambda>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\data\\hw1_check_ol.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\data\\hw1_check_ol.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\data\\hw1_check_ol.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  [Previous line repeated 3 more times]\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\data\\hw1_check_ol.py\", line 1, in <lambda>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\data\\hw1_check_ol.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "  File \"c:\\Users\\anton\\source\\IDE\\DS_PROD-1\\data\\hw1_check_ol.py\", line 1, in <listcomp>\n",
      "    (lambda __g, __print: [[[[[[(lambda __after: [[(f.close(), [(lambda __after: (__print('wrong answer'), __after())[1] if (((14 * a) + b) != ((14 * asd()) + ____asd())) else [(__print(('secret code 2:', h.hexdigest()[:5])), __after())[1] for __g['h'] in [(hashlib.md5((____asd.__name__ + asd.__name__).encode()))]][0])(lambda: __after()) for (__g['a'], __g['b']) in [((load['a'], load['b']))]][0])[1] for __g['load'] in [(pickle.load(f))]][0] for __g['f'] in [(open(sys.argv[1], 'rb'))]][0] if (__name__ == '__main__') else __after())(lambda: None) for __g['asd'], asd.__name__ in [(lambda : (____asd() - 8), 'asd')]][0] for __g['____asd'], ____asd.__name__ in [(lambda : ((int(math.pi) * 4) + 1), '____asd')]][0] for __g['hashlib'] in [(__import__('hashlib', __g, __g))]][0] for __g['sys'] in [(__import__('sys', __g, __g))]][0] for __g['pickle'] in [(__import__('pickle', __g, __g))]][0] for __g['math'] in [(__import__('math', __g, __g))]][0])(globals(), __import__('builtins', level=0).__dict__['print'])\n",
      "TypeError: 'LinearRegression' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "!python data\\\\hw1_check_ol.py data\\\\model.pkl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Сохранение и загрузка моделей: PMML и ONNX-ML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среда или требования к **инференсу** модели для вашего проекта могут быть устроены так, что потребуют реализации на языке программирования, отличном от Python. Например, если компания разрабатывает десктопное приложение, то для внедрения модели её потребуется «перевести» на Java или C++. Как это сделать?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREDICTIVE MODEL MARKUP LANGUAGE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таких случаях используется генерация файла формата PMML (Predictive Model Markup Language).\n",
    "\n",
    "**PMML** — это XML-диалект, который применяется для описания статистических и DS-моделей. PMML-совместимые приложения позволяют легко обмениваться моделями данных между собой. Разработка и внедрение PMML осуществляется IT-консорциумом Data Mining Group.\n",
    "\n",
    "Подробнее с PMML можно ознакомиться на официальном сайте http://dmg.org/pmml/v4-4/GeneralStructure.html.\n",
    "\n",
    "К сожалению, далеко не все библиотеки для машинного обучения (в том числе sklearn) поддерживают возможность сохранения обученной модели в указанном формате. Однако для этого можно использовать сторонние библиотеки, и одной из самых популярных является Nyoka https://nyoka-pmml.github.io/nyoka/.\n",
    "\n",
    "Давайте сохраним модель из предыдущего блока в формат PMML.\n",
    "\n",
    "Для установки можно использовать систему управления пакетами pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nyoka\n",
      "  Downloading nyoka-5.4.0-py3-none-any.whl (303 kB)\n",
      "     ------------------------------------ 303.8/303.8 kB 723.1 kB/s eta 0:00:00\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.2-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 3.8/3.8 MB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lxml, nyoka\n",
      "Successfully installed lxml-4.9.2 nyoka-5.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install nyoka"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "или"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nyoka in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (5.4.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nyoka) (4.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install nyoka"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим пример работы с библиотекой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nyoka import skl_to_pmml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "cols = load_diabetes()['feature_names']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "pipe = Pipeline([  \n",
    "            ('Scaling', MinMaxScaler()),\n",
    "            ('Linear', LinearRegression())\n",
    "        ])\n",
    "# Обучение пайплайна, включающего линейную модель и нормализацию признаков\n",
    "pipe.fit(X, y)\n",
    "# Сохраним пайплайн в формате pmml в файл pipeline.pmml\n",
    "skl_to_pmml(pipeline=pipe, col_names=cols, pmml_f_name=\"pipeline.pmml\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы построили пайплайн обработки данных и обучили модель линейной регрессии. После этого мы с помощью функции skl_to_pmml сохранили модель в файл pipe.pmml."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откройте файл pipe.pmml с помощью любого текстового редактора.\n",
    "\n",
    "Давайте рассмотрим этот файл подробнее:\n",
    "\n",
    "- Секция *< DataDictionary >* содержит информацию о признаках, включая наименование и тип данных, используемых для построения модели.  \n",
    "- Секция *< TransformationDictionary >* содержит информацию о необходимых преобразованиях для каждого признака. Обратите внимание, что в этом блоке также содержится информация для трансформации. Так как мы использовали minMaxScaler(), то в файле записаны минимальное и максимальное значения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, в файле содержится вся информация для того, чтобы пайплайн можно было использовать на любом языке программирования."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPEN NEURAL NETWORK EXCHANGE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разработке моделей на основе нейронных сетей сегодня наиболее распространён формат ONNX (Open Neural Network Exchange).\n",
    "\n",
    "**ONNX (Open Neural Network Exchange)** https://onnx.ai/ — это открытый стандарт для обеспечения совместимости моделей машинного обучения. Он позволяет разработчикам искусственного интеллекта использовать модели с различными инфраструктурами, инструментами, средами исполнения и компиляторами.\n",
    "\n",
    "Стандарт совместно поддерживается компаниями Microsoft, Amazon, Facebook и другими партнёрами как проект с открытым исходным кодом.\n",
    "\n",
    "Часто стандарт ONNX и его библиотеки используют для конвертации из одного фреймворка в другой (например, из PyTorch в TensorFlow для использования в продакшене). Для конвертации различных фреймворков (не только DL) в формат ONNX и обратно существует ряд библиотек https://github.com/onnx:\n",
    "\n",
    "- ONNX-Tensorflow https://github.com/onnx/onnx-tensorflow;\n",
    "- Tensorflow-ONNX https://github.com/onnx/tensorflow-onnx;\n",
    "- Keras-ONNX https://github.com/onnx/keras-onnx;\n",
    "- Sklearn-ONNX https://github.com/onnx/sklearn-onnx.\n",
    "- и другие.  \n",
    "\n",
    "Также в рамках стандарта ONNX есть инструмент ONNX-runtime. Он служит для ускорения инференса Python-моделей, а также инференса на других языках, например Java, C++."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Задание 4.6 (со звёздочкой)**\n",
    "\n",
    "Для выполнения этого задания вам понадобится ознакомиться с документацией здесь http://onnx.ai/sklearn-onnx/api_summary.html и здесь https://onnx.ai/sklearn-onnx/.\n",
    "\n",
    "В задаче ниже мы обучаем модель sklearn, конвертируем ее в ONNX и делаем инференс через ONNX-runtime.\n",
    "\n",
    "Дополните код ниже недостающими элементами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.15.0-cp310-cp310-win_amd64.whl (6.7 MB)\n",
      "     ---------------------------------------- 6.7/6.7 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting flatbuffers\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-4.23.2-cp310-abi3-win_amd64.whl (422 kB)\n",
      "     -------------------------------------- 422.5/422.5 kB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (21.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxruntime) (1.24.1)\n",
      "Collecting coloredlogs\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "     ---------------------------------------- 46.0/46.0 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting humanfriendly>=9.1\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     ---------------------------------------- 86.8/86.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->onnxruntime) (3.0.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy->onnxruntime) (1.2.1)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.4.1)\n",
      "Installing collected packages: flatbuffers, protobuf, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-23.5.26 humanfriendly-10.0 onnxruntime-1.15.0 protobuf-4.23.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting skl2onnx\n",
      "  Downloading skl2onnx-1.14.1-py2.py3-none-any.whl (292 kB)\n",
      "     ------------------------------------ 292.3/292.3 kB 819.8 kB/s eta 0:00:00\n",
      "Collecting onnx>=1.2.1\n",
      "  Downloading onnx-1.14.0-cp310-cp310-win_amd64.whl (13.3 MB)\n",
      "     ---------------------------------------- 13.3/13.3 MB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn<1.3,>=0.19 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from skl2onnx) (1.2.0)\n",
      "Collecting onnxconverter-common>=1.7.0\n",
      "  Downloading onnxconverter_common-1.13.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 83.8/83.8 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx>=1.2.1->skl2onnx) (1.24.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx>=1.2.1->skl2onnx) (4.23.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnx>=1.2.1->skl2onnx) (4.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from onnxconverter-common>=1.7.0->skl2onnx) (21.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn<1.3,>=0.19->skl2onnx) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn<1.3,>=0.19->skl2onnx) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn<1.3,>=0.19->skl2onnx) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->onnxconverter-common>=1.7.0->skl2onnx) (3.0.8)\n",
      "Installing collected packages: onnx, onnxconverter-common, skl2onnx\n",
      "Successfully installed onnx-1.14.0 onnxconverter-common-1.13.0 skl2onnx-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\anton\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13) (127, 13)\n",
      "sklearn model predict:\n",
      " [23.1903541  18.97985889 19.82548836 19.00126197  4.39524325 11.90230303\n",
      " 21.24870187 28.64449553 29.03550064 13.90644782  6.41422339 32.65356658\n",
      " 18.99884691 20.01569489 37.15275422 22.80485488 29.04529555 33.04200949\n",
      " 10.48602033 24.45472284 21.33069324 27.60222354 37.52118276 13.6113556\n",
      "  9.56442243 15.03368415 35.5975585  26.01017573 25.52430154 27.06321433\n",
      " 19.07680237 30.54746571 31.27561168 16.40132981 39.76707419 20.27263903\n",
      " 18.94934061 17.12210014 21.6262832  28.15101424 26.95292863 19.14352801\n",
      " 14.50664721 25.78075705 18.50460146 13.93439214 24.96593139 19.12431756\n",
      " 20.6780475   6.23807397 27.71460362 26.74617711 11.83361779 40.10855118\n",
      " 14.66523328 22.12023896 20.34305401 20.3786179  23.56685605 21.91582872\n",
      " 20.79748126 35.43123681 17.32592458 20.92077502 24.1674162  43.38199388\n",
      " 19.59747681 20.11624895 22.35462757 28.12506906 25.53832602 12.88949504\n",
      " 13.1552648  33.3092473  26.12666965 22.54135443 12.14404271 16.61972119\n",
      " 28.52703363 17.81932988 24.42637646 27.69824683 23.05296655 24.4402857\n",
      " 27.23233855 30.4210596  24.04718434 19.88744242 31.13160771 21.41108091\n",
      " 19.88680529 36.86501486 37.91625512 24.00513438 25.64874538 12.43967316\n",
      " 28.95074601  9.82709099 13.94593323 28.30721693 20.43657045 15.31547598\n",
      " 15.47748826 19.9406056  21.70074992 15.33999115 12.4014992  25.67993384\n",
      " 24.75824916 21.43766149 16.75630786 26.01764392 18.91613898 21.260363\n",
      "  8.95751196 24.86285128 14.20211854 28.98987716 18.37995946 20.40169618\n",
      " 17.11225855 24.55966354 24.81152897 36.53760221 14.72009878 33.43276192\n",
      " 21.59847763]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input must be a list of dictionaries or a single numpy array for input 'float_input'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anton\\source\\IDE\\DS_PROD-1\\DS_PROD-1.ipynb Cell 122\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/source/IDE/DS_PROD-1/DS_PROD-1.ipynb#Y230sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m input_name \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mget_inputs()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/source/IDE/DS_PROD-1/DS_PROD-1.ipynb#Y230sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m label_name \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39mget_outputs()[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/anton/source/IDE/DS_PROD-1/DS_PROD-1.ipynb#Y230sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m test_pred_onnx \u001b[39m=\u001b[39m sess\u001b[39m.\u001b[39;49mrun([label_name],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/source/IDE/DS_PROD-1/DS_PROD-1.ipynb#Y230sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                 \t{input_name:  X_test\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32)})[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anton/source/IDE/DS_PROD-1/DS_PROD-1.ipynb#Y230sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39monnx model predict:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m,test_pred_onnx)\n",
      "File \u001b[1;32mc:\\Users\\anton\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:217\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    215\u001b[0m     output_names \u001b[39m=\u001b[39m [output\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m output \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_meta]\n\u001b[0;32m    216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 217\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess\u001b[39m.\u001b[39;49mrun(output_names, input_feed, run_options)\n\u001b[0;32m    218\u001b[0m \u001b[39mexcept\u001b[39;00m C\u001b[39m.\u001b[39mEPFail \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    219\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input must be a list of dictionaries or a single numpy array for input 'float_input'."
     ]
    }
   ],
   "source": [
    "import onnxruntime as rt \n",
    "# from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# загружаем данные\n",
    "# X, y = load_boston(return_X_y=True)\n",
    "df = pd.read_csv('data\\\\boston_house_prices.csv')\n",
    "X = df.drop(['MEDV'], axis=1)\n",
    "y = df['MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=7)\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# обучаем модель\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# делаем инференс моделью на тесте\n",
    "test_pred = model.predict(X_test)\n",
    "print('sklearn model predict:\\n', test_pred)\n",
    "\n",
    "# конвертируем модель в ONNX-формат\n",
    "initial_type = [('float_input', FloatTensorType([None, 13]))] # Boston has 13 numerical features and a numerical target variable\n",
    "model_onnx = convert_sklearn(model, initial_types=initial_type)\n",
    "\n",
    "# сохраняем модель в файл\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "\tf.write(model_onnx.SerializeToString())\n",
    " \t \n",
    "# Делаем инференс на тесте через ONNX-runtime\n",
    "sess = rt.InferenceSession(\"model.onnx\")\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "test_pred_onnx = sess.run([label_name],\n",
    "                \t{input_name:  X_test.astype(np.float32)})[0].reshape(-1)\n",
    "print('onnx model predict:\\n',test_pred_onnx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Деплой модели. Протоколы сетевого взаимодействия"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помните вашего коллегу Василия — того, что прислал модель в pkl-формате и просил проверить её на ваших данных? Вот, кстати, и ссылка на модель https://lms-cdn.skillfactory.ru/assets/courseware/v1/edb336d23fdbf18a919f9dbfad55426a/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/model.pkl."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Завтра Василию предстоит защищать решение перед руководителями проекта, а для этого нужно показать работающий прототип (в нашем случае — **задеплоить модель на тестовый сервер**) и рассказать об эффективности предлагаемого решения. За деплоем Василий обратился к вам.\n",
    "\n",
    "С чего начнём?\n",
    "\n",
    "- Во-первых, нужно разобраться с тем, как происходит взаимодействие серверов по сети.  \n",
    "- Во-вторых, необходимо узнать, как написать сервер и обернуть в него модель. Какие есть фреймворки? Какой выбрать конкретно в нашем случае? Как его реализовать?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### МОДЕЛИ СЕТЕВОГО ВЗАИМОДЕЙСТВИЯ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с первого вопроса и немного поговорим о том, как происходит взаимодействие между серверами по сети, то есть разберём процесс обмена информацией между компьютерами.\n",
    "\n",
    "Наиболее известные модели сетевого взаимодействия — OSI https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D1%82%D0%B5%D0%B2%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C_OSI и TCP/IP https://ru.wikipedia.org/wiki/TCP/IP."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_1.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эти модели распределяют сетевые протоколы по разным уровням взаимодействия. Что такое протокол?\n",
    "\n",
    "Вообще **протокол** — это некоторый набор правил, определяющий принципы взаимодействия устройств в сети. В нашем случае это правила, по которым программа, получив по сети набор битов, понимает, как его прочитать и что он значит.\n",
    "\n",
    "Для того чтобы обмен информацией между устройствами проходил успешно, все устройства (участники процесса) должны следовать условиям протокола. В сети поддержка протоколов встраивается или в аппаратную (в «железо»), или в программную часть (в код системы), или в обе этих части. \n",
    "\n",
    "На схеме ниже представлены примеры протоколов, а также уровни их распределения в модели TCP/IP:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_2.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С другими протоколами и их назначением вы можете ознакомиться здесь https://selectel.ru/blog/network-protocols/.\n",
    "\n",
    "В процессе сетевого взаимодействия участвуют как минимум два устройства — устройство-отправитель и устройство-получатель. Говоря простым языком, каждая из моделей сетевых взаимодействий устанавливает правила и регламенты по отправке сообщений между компьютерами.\n",
    "\n",
    "Отправленное сообщение проходит все уровни, начиная от прикладного уровня приложений и заканчивая физическим уровнем доступа к сети. Когда сообщение доходит до адресата, оно также проходит все уровни в обратном порядке."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_3.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если привести аналогию из жизни, можно сказать, что обе модели описывают правила, по которым мем, который вы отправляете другу в мессенджере, будет преобразован до битов данных, передаваемых по электрическим проводам, а затем будет восстановлен по этим же битам и отображён на экране устройства вашего друга.\n",
    "\n",
    "Нам как дата-сайентистам не нужно знать все подробности того, как работают и чем отличаются друг от друга разные уровни взаимодействия. Однако для общего развития и понимания того, как устройства обмениваются информацией, вы можете прочитать об уровнях моделей OSI и TCP/IP здесь https://selectel.ru/blog/osi-for-beginners/ и здесь https://zametkinapolyah.ru/servera-i-protokoly/chto-takoe-model-osi-etalonnaya-model-setevogo-vzaimodejstviya-urovni-setevoj-modeli-osi-primery-i-prostoe-obyasneniya-principa-raboty-semiurovnevoj-modeli.html#__OSI-3.\n",
    "\n",
    "Для наших целей (деплой модели в прод) достаточно уметь работать всего с тремя протоколами:\n",
    "\n",
    "**IP** — протокол сетевого уровня. Он определяет путь, по которому передаются данные.  \n",
    "\n",
    "**TCP** — соответствует транспортному уровню, а значит, определяет, как передаются данные.  \n",
    "\n",
    "**HTTP** — относится к прикладному уровню, описывающему взаимодействие приложений с сетью.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_4.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IP**\n",
    "\n",
    "IP (Internet Protocol) — один из главных протоколов сетевого взаимодействия. Он отвечает за маршрутизацию трафика по сети, то есть определяет путь, по которому отправятся данные. Данные передаются пакетами (или датаграммами), которые формирует протокол IP.\n",
    "\n",
    "Важным свойством IP является отсутствие гарантированной доставки пакетов и их цельности: пакеты могут прийти в другой очерёдности (не в той, в которой их отправляли), прийти повреждёнными (тогда они уничтожаются) или вообще не прийти.\n",
    "\n",
    "Путь, по которому отправятся данные, строится на основе IP-адресов.\n",
    "\n",
    "IP-адрес — это уникальный адрес, используемый для связи устройств внутри сети.\n",
    "\n",
    "IP-адрес устроен довольно просто: чаще всего это четыре числа, разделённых точками (такой формат поддерживается в протоколе IPv4). Например, вот один из самых популярных IP-адресов — 192.168.0.1. Вы могли вводить его, чтобы зайти в настройки своего роутера.\n",
    "\n",
    "Каждое из чисел в адресе — это восьмизначное двоичное число, или, правильнее говорить, октет. Оно может принимать значения от 0000 0000 до 1111 1111 в двоичной системе или от 0 до 255 — в десятичной системе счисления, то есть 256 разных значений.\n",
    "\n",
    "Получается, что диапазон IP-адресов стартует с 0.0.0.0 и заканчивается 255.255.255.255. Если посчитать количество всех адресов в этом диапазоне, получится чуть больше четырёх миллиардов.\n",
    "\n",
    "Уникальность IP-адреса может быть глобальной (в рамках всего интернета) или локальной (в рамках локальной подсети). Некоторые IP-адреса не являются общедоступными и зарезервированы для специальных целей, например диапазоны IP-адресов:\n",
    "\n",
    "127.0.0.1–127.255.255.255\tиспользуются для связи внутри локальной машины (localhost)  \n",
    "172.16.0.1–172.31.255.255\tиспользуются для частных подсетей (недоступных из интернета)  \n",
    "198.18.0.1–198.19.255.254\tиспользуются для тестирования производительности  \n",
    "\n",
    "**localhost** — зарезервированное доменное имя для IP-адресов из диапазона 127.0.0.1–127.255.255.255 (в сети из одного компьютера — для 127.0.0.1).\n",
    "\n",
    "В компьютерной сети localhost относится к компьютеру, на котором запущена программа. Компьютер работает как виртуальный сервер. Тем самым создаётся так называемая «внутренняя петля»: обращаясь по IP-адресу localhost, вы, по сути, заставляете компьютер общаться с самим собой (хотя на самом деле внутри всё немного сложнее). Это нужно, например, для разработки и тестирования клиент-серверных приложений на одной машине (то есть и клиент, и сервер находятся на одном компьютере), что позволяет при разработке не использовать сетевое оборудование, дополнительные программные модули и тому подобное."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TCP**\n",
    "\n",
    "TCP (Transmission Control Protocol) — протокол транспортного уровня. Он отвечает за управление передачей данных и гарантирует:\n",
    "\n",
    "доставку пакетов (посылает пакеты повторно, если они не были доставлены);\n",
    "последовательность и целостность доставки пакетов (используя нумерацию и контрольные суммы для проверки);\n",
    "устраняет дубликаты в случае необходимости.\n",
    "Важной особенностью TCP является то, что перед отправкой данных он «устанавливает соединение» с получателем — обменивается управляющей информацией. После отправки пакетов источник ждёт подтверждения от получателя, что пакеты были доставлены.\n",
    "\n",
    "Обычно на одном **узле сети** (сервере, компьютере) работают несколько приложений/процессов одновременно. Для идентификации приложения на источнике и получателе используется порт, который задаётся целым неотрицательным числом. Процесс или приложение могут зарезервировать у ОС определённый **порт**, например, для передачи данных по сети.\n",
    "\n",
    "Порты разделяют на системные (0–1023), и пользовательские (1024–49151). Некоторые номера портов определены для конкретных приложений, например:\n",
    "\n",
    "- 22 — протокол SSH для безопасной передачи данных;  \n",
    "- 25 — протокол SMTP для незащищённой передачи e-mail-сообщений;  \n",
    "- 80 — протокол HTTP.  \n",
    "\n",
    "Например, если приложение доступно по адресу 172.16.0.11:8001, это значит следующее:\n",
    "\n",
    "- 172.16.0.11 — IP-адрес;\n",
    "- 8001 — TCP-порт, отведённый приложению."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HTTP**\n",
    "\n",
    "HTTP — это наиболее широко используемый протокол. Все сайты, на которые вы заходите, работают по этому протоколу. Он был разработан именно для передачи содержимого HTML-страниц в интернете, но впоследствии стал использоваться и для других целей. Например, HTTP применяется для налаживания взаимодействия между сервисами в сложных системах. Этим он нам и интересен.\n",
    "\n",
    "Итак, HTTP — это протокол, который работает по принципу **клиент-сервер**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_5.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это означает, что во взаимодействии участвует **две программы**, причём в разных ролях. Одна из них — **клиент**, или «заказчик услуг», формирует запрос и отправляет его к серверу. **Сервер**, или «поставщик услуг», получив запрос, обрабатывает его, формирует ответ и возвращает его клиенту."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СТРУКТУРА HTTP-ЗАПРОСОВ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_6.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запрос и ответ в HTTP являются строками, составленными в соответствии с протоколом."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Запрос** состоит из трёх частей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_7.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Стартовая строка**, или Request Line — по ней определяется вид запроса.\n",
    "2. **Заголовки запроса**, или Request Headers — дополнительные параметры запроса, в которых обычно передаётся служебная информация, например, в каком формате ожидается ответ или информация о клиенте.\n",
    "3. **Тело запроса**, или Request Message Body — содержит данные для передачи. Эта часть присутствует не всегда.\n",
    "\n",
    "Давайте чуть подробнее разберём первую часть."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_8.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое, что указано в стартовой строке — это **метод**, или тип запроса. Есть набор стандартных методов, но теоретически вы можете создавать и свои.\n",
    "\n",
    "**Основные методы:**\n",
    "\n",
    "- GET — обычно означает получение содержимого ресурса и не содержит тела.\n",
    "\n",
    "Например, когда вы заходите в каталог интернет-магазина, вы получаете страницу с товарами — ваш браузер отправляет GET-запрос на сервер интернет-магазина.\n",
    "\n",
    "- POST — наоборот, передача данных ресурсу.\n",
    "\n",
    "Например, когда вы заполняете форму авторизации на любом сайте и нажимаете кнопку для отправки своих данных, вы совершаете POST-запрос на сервер ресурса.\n",
    "\n",
    "- PUT — обновление ресурса.  \n",
    "- DELETE — удаление ресурса.  \n",
    "\n",
    "В HTTP мы работаем с ресурсами, которые расположены по некоторому адресу на сервере. Изначально под ресурсами понимались HTML-файлы на сайте (вёрстка сайта), но сейчас это уже некоторое абстрактное понятие.\n",
    "\n",
    "Адрес ресурса, или URI (Uniform Resource Identifier) — это то, что вы видите в адресной строке браузера. Он следует за методом в стартовой строке запроса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_9.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чем отличаются URI, URL и URN?**\n",
    "\n",
    "Для начала расшифруем аббревиатуры:\n",
    "\n",
    "- URI — Uniform Resource Identifier (унифицированный идентификатор ресурса);  \n",
    "- URL — Uniform Resource Locator (унифицированный определитель местонахождения ресурса);  \n",
    "- URN — Unifrorm Resource Name (унифицированное имя ресурса).  \n",
    "\n",
    "Большинство считает, что http://google.com или https://skillfactory.ru/ — это просто URL-адреса. Тем не менее, мы можем говорить о них как о URI. URI представляет собой комбинацию URL-адресов и URN. Таким образом, мы можем с уверенностью сказать, что все URL являются URI. Однако обратное неверно.\n",
    "\n",
    "Давайте рассмотрим это на простом примере. \n",
    "\n",
    "Имя «Джон Сноу» — это URN. Место, в котором живёт Джон, например «Улица Вестерос, 13» — это уже URL. Вас можно идентифицировать как уникальное лицо с вашим именем или вашим адресом. Эта уникальная личность — это уже URI. И хотя ваше имя может быть вашим уникальным идентификатором (URI), оно не может быть URL-адресом, поскольку имя не позволяет найти местоположение.\n",
    "\n",
    "Теперь дадим расширенное определение терминам:\n",
    "\n",
    "- URI — имя и адрес ресурса в сети. URI включает в себя URL и URN.\n",
    "\n",
    "Пример: https://wiki.merionet.ru/images/vse-chto-vam-nuzhno-znat-pro-devops/1.png\n",
    "\n",
    "- URL — адрес ресурса в сети. URL определяет местонахождение и способ обращения к нему. \n",
    "\n",
    "Пример: https://wiki.merionet.ru\n",
    "\n",
    "- URN — имя ресурса в сети. URN определяет только название ресурса, но не говорит, как к нему подключиться.\n",
    "\n",
    "Пример: images/vse-chto-vam-nuzhno-znat-pro-devops/1.png\n",
    "\n",
    "Последней идёт версия HTTP-протокола (кстати, последняя актуальная версия, 1.1, появилась ещё в 1999 году)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_10.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ** также состоит из стартовой строки, заголовков и тела."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_11.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное отличие — в стартовой строке: там вместо метода и URI указывается код состояния. Это численное значение, которое показывает результат обработки. Коды задаются протоколом, и вы наверняка встречали «ошибку 404» на сайтах.\n",
    "\n",
    "404 — это как раз код состояния, означающий, что ресурса с заданным URI не существует на сервере.\n",
    "\n",
    "Группы кодов состояния ответа HTTP-сервера делятся на следующие группы:\n",
    "\n",
    "- информационные (100–199);  \n",
    "- успешно (200–299);  \n",
    "- перенаправление (300–399);  \n",
    "- ошибка клиента (400–499);  \n",
    "- ошибка сервера (500–599).  \n",
    "\n",
    "**Примеры**:\n",
    "\n",
    "Код 200 означает, что запрос обработан успешно.  \n",
    "Код 500 означает, что сервер не смог обработать запрос.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REST (REPRESENTATIONAL STATE TRANSFER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_5_13.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cпецификация HTTP не обязывает сервер понимать все методы, а также не указывает серверу, что он должен делать при получении запроса с тем или иным методом. Поэтому был изобретён архитектурный стиль REST.\n",
    "\n",
    "Он даёт более верхнеуровневые указания, чем HTTP-протокол, а именно:\n",
    "\n",
    "- как правильно организовывать адресацию к ресурсам;  \n",
    "- какие методы у этих ресурсов должны быть;  \n",
    "- какой ожидается результат.  \n",
    "\n",
    "Основная концепция философии REST заключается в том, что клиентом RESTful-сервера может быть что/кто угодно: браузер, другое приложение, разработчик. Веб-приложение, спроектированное по правилам REST, предоставляет информацию о себе в форме информации о своих ресурсах.\n",
    "\n",
    "Ресурс может быть любым объектом, о котором сервер предоставляет информацию. Например, в API Instagram ресурсом может быть пользователь, фотография, хэштег. Каждая единица информации (ресурс) однозначно определяется URL.\n",
    "\n",
    "- GET-запрос /rest/users — получение информации обо всех пользователях.  \n",
    "- GET-запрос /rest/users/125 — получение информации о пользователе с id=125.  \n",
    "- POST-запрос /rest/users — добавление нового пользователя.  \n",
    "- PUT-запрос /rest/users/125 — изменение информации о пользователе с id=125.  \n",
    "- DELETE-запрос /rest/users/125 — удаление пользователя с id=125.  \n",
    "\n",
    "Поскольку спецификация REST является общепризнанной и широко распространённой, то следовать ей очень полезно.\n",
    "\n",
    "Если вы говорите, что ваш сервис RESTful (то есть построен по этой спецификации), то любой разработчик сразу поймёт, как примерно устроен сервис, а значит, сможет быстро начать им пользоваться: отправлять правильные запросы и получать тот результат, который ожидает."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРОМЕЖУТОЧНЫЕ ИТОГИ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы наладить взаимодействие по HTTP, на стороне **клиента** вам необходимо сформировать запрос: указать адрес, куда отправится запрос, выбрать метод, а также задать заголовки и тело запроса, если это нужно для выбранного метода.\n",
    "\n",
    "На стороне **сервера** при получении запроса необходимо знать, какой ресурс запрошен, чтобы понять, каким кодом его обрабатывать. Этот код, в зависимости от того, что он должен делать, может проверить значения заголовков и/или прочитать тело запроса.\n",
    "\n",
    "Отлично, со взаимодействием сервисов по сети мы разобрались. Эти теоретические знания обязательно пригодятся вам для построения собственного веб-сервиса. Теперь пора приступать к рассмотрению Python-фреймворков, которые как раз и помогут создать этот веб-сервис."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Деплой модели. Обзор фреймворков"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг в подготовке к деплою — рассмотреть, какие существуют веб-фреймворки Python, которые позволяют реализовать серверную часть приложения и обеспечить к нему клиентский доступ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLASK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask позиционируется как микрофреймворк для написания **легковесных** сервисов, но при этом он достаточно гибкий и кастомизируемый, что позволяет использовать его в проектах любой сложности. Как и все остальные фреймворки, он работает на основе **маршрутизации запросов**, приходящих на сервер, который и должен обработать эти запросы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_6_1.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае с Flask маршрутизация выглядит как обычные функции Python, которые вы помечаете специальным **декоратором** @app.route. Он связывает эту функцию с адресом, на который приходит запрос. В этой функции вы должны разобрать **параметры запроса**, возможно, выполнить какую-то логику и вернуть ответ клиенту.\n",
    "\n",
    "Таким образом, для написания минимально функционального сервера достаточно добавить в скрипт всего несколько строк: необходимые импорты, создание Flask-приложения, декоратор, который свяжет адрес (endpoint, эндпоинт) с функцией, и запуск приложения. Последнее как раз и запустит работу Flask: он будет слушать запросы, маршрутизировать их и возвращать ответ.\n",
    "\n",
    "**Что такое эндпоинт?**\n",
    "\n",
    "Рассмотрим на примере. Сайт почты Mail.ru имеет адрес https://e.mail.ru. Для того чтобы попасть в папку со входящими письмами, необходимо обратиться к соответствующему интерфейсу приложения. Для этого к адресу сайта добавляется /inbox/: https://e.mail.ru/inbox. Интерфейс, который предоставляет доступ к вашим отправленным письмам, находится по адресу https://e.mail.ru/sent/. Получается, что /inbox/ и /sent/ — это и есть эндпоинты.\n",
    "\n",
    "У Flask есть множество продвинутых функций и плагинов, написанных сторонними разработчиками для решения самых разных задач. Однако нам достаточно научиться работать с Flask на минимальном уровне, чтобы вывести свою модель как отдельный маленький сервис (микросервис), решающий одну конкретную задачу — к сервису можно обращаться по сети и получать результаты (предсказания модели).\n",
    "\n",
    "Реализация глобальной структуры сервиса (веб-приложения) и встраивание этой структуры в микросервис — это уже задача других специалистов, например веб-разработчиков."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DJANGO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от Flask, Django нельзя назвать микрофреймворком. Напротив, даже минимальный проект для Django обычно генерируется **специальными скриптами** и включает с десяток файлов и папок."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_6_2.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такая сложная структура нужна для громоздких приложений, чтобы не путаться в коде. Поэтому Django используют, когда нужно что-то **посерьёзней**, например целые сайты с базами данных.\n",
    "\n",
    "**ПРЕИМУЩЕСТВА DJANGO:**\n",
    "\n",
    "- Мощный движок для рендера HTML-страниц, основанный на шаблонах.  \n",
    "- Собственный ORM.  \n",
    "- Огромное количество дополнительных плагинов. Один из них практически так же популярен, как и сам Django — речь о Django Rest Framework. Основываясь на ORM, он позволяет в несколько строк реализовывать эндпоинты протокола RESTful. Сам Django Rest Framework также имеет множество расширений. Благодаря этому написание сложного проекта можно свести в составлению правильной модели данных, установке и настройке подходящих расширений."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLASK VS DJANGO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте более подробно рассмотрим характеристики Flask и Django и узнаем, чем отличаются и чем похожи эти два фреймворка.\n",
    "\n",
    "В Django есть модули для очень широкой функциональности. Чтобы получить к ним доступ, надо просто добавить нужную настройку в конфигурацию. Это отлично перекликается с девизом Django: “The web framework for perfectionists with deadlines” («Веб-фреймворк для перфекционистов, которые придерживаются сроков»).\n",
    "\n",
    "Во Flask всё наоборот: сам фреймворк предоставляет только базовую функциональность. «Из коробки» будет доступно направление по адресам эндпойнтов, обработка запросов и ошибок, дебаггер и некоторые другие функции, явно связанные с сервером. Например, чтобы добавить авторизацию, придётся устанавливать **стороннюю библиотеку**. При этом вы можете выбрать ту, которая лучше подходит текущему проекту, лучше поддерживается или просто более удобна в использовании, а можете вообще не подключать библиотеки.\n",
    "\n",
    "Flask нужен для оборачивания **инференса модели в API**, когда, например, по поступившему запросу запускается предикт модели. Знание Flask пригодится и на этапе создания прототипа, и на этапе тестирования.\n",
    "\n",
    "Также некоторые компании строят весь продакшен на Flask, а значит, знать его основы будет полезно.\n",
    "\n",
    "В связи с тем, что Django выпускается в релиз вместе со всеми сопутствующими модулями, у него достаточно длинные релиз-циклы. С Flask эта проблема менее актуальна: если какой-то функциональности не хватает, часто она есть в какой-то библиотеке. Этот подход жизнеспособен, потому что у Flask большое сообщество разработчиков, которые занимаются поддержкой библиотек для этого фреймворка.\n",
    "\n",
    "Flask приобрёл популярность именно благодаря небольшим приложениям, для которых Django казался избыточным. Однако сегодня Flask используется не только для таких приложений.\n",
    "\n",
    "Для справки приведём инструментарий, используемый в Django и Flask, чтобы продемонстировать, как фреймворки отличаются друг от друга по функциональности. Запоминать таблицу не нужно.\n",
    "\n",
    "**Примечание**. При разработке на Flask список чаще всего не ограничивается перечисленными в таблице библиотеками — здесь собраны только наиболее популярные и известные. Также есть библиотеки, у которых есть специальные расширения для Flask. Чаще всего они не обязательны для работы с библиотекой, но могут быть полезны."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ФУНКЦИОНАЛЬНОСТЬ      | DJANGO      | FLASK      |FLASK EXTENSION     |\n",
    "|:-------------:|:---------------:|:-------------:|:-------------:|\n",
    "|Шаблоны       | Django templates       | Jinja2        |         |\n",
    "| ORM         | Django ORM       | sqlalchemy https://www.sqlalchemy.org/       |         |\n",
    "| Миграции         | Django ORM      | Alembic https://alembic.sqlalchemy.org/en/latest/        | Flask-sqlalchemy https://flask-sqlalchemy.palletsprojects.com/en/2.x/        |\n",
    "| Работа с MongoDB     | Django ORM   | PyMongo https://api.mongodb.com/python/current/, MongoEngine http://mongoengine.org/  | Flask-alembic https://flask-alembic.readthedocs.io/en/stable/        |\n",
    "| Авторизация, аутентификация         | Django Contrib Auth       | Flask-Login https://flask-login.readthedocs.io/en/latest/, Flask-Principal https://pythonhosted.org/Flask-Principal/      | Flask-PyMongo https://flask-pymongo.readthedocs.io/en/latest/, Flask-MongoEngine http://docs.mongoengine.org/projects/flask-mongoengine/en/latest/   |\n",
    "| Админка        | Django Admin     | Flask-Admin https://github.com/flask-admin/flask-admin       |        |\n",
    "| Кэширование         | Django Cache Framework      | Flask-Caching https://docs.djangoproject.com/en/2.2/topics/cache/        |         |\n",
    "| REST         | \tDjango REST https://www.django-rest-framework.org/      | Flask-RESTful https://flask-restful.readthedocs.io/en/latest/, Flask-RESTPlus https://flask-restplus.readthedocs.io/en/stable/       |        |\n",
    "| Сериализация        | \tDjango REST https://www.django-rest-framework.org/   | Marshmallow https://marshmallow.readthedocs.io/        | Flask-marshmallow https://flask-marshmallow.readthedocs.io/en/latest/        |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "КТО ПОБЕДИЛ?\n",
    "\n",
    "Как мы видим, для основной функциональности, реализованной в Django, есть аналоги, которые работают с Flask. Нельзя сказать, что какой-то из фреймворков проигрывает другому по большому числу параметров.\n",
    "\n",
    "Однако стоит понимать, что, выбирая Django, вы оставляете проект со всей экосистемой Django, и что-то изменить впоследствии будет трудно. Выбирая Flask, вы получаете систему, построенную из блоков, каждый из которых проще заменить."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FASTAPI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это относительно молодой фреймворк, однако он уже успел завоевать некоторую популярность. Возможно, через некоторое время он превратится в стандарт индустрии, заменив Flask.\n",
    "\n",
    "**Примечание**. Да-да, именно Flask! FastAPI тоже позиционируется как легковесный фреймворк. Более того, принцип его использования очень похож на Flask. Авторы утверждают, что, вдохновившись Flask, они написали **более быстрый** (за счёт использования более современных протоколов), но при этом не уступающий по функциональности фреймворк.\n",
    "\n",
    "Основное нововведение в FastAPI — интеграция библиотеки pydantic, которая позволяет **декларативно** описывать структуры запросов.\n",
    "\n",
    "Также в FastAPI есть **поддержка асинхронных функций** и реализация парадигмы Dependency Injection."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_6_4.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое асинхронные функции?\n",
    "**Асинхронная функция**, или **асинхронный метод** — это функция, которая может быть приостановлена во время выполнения.\n",
    "\n",
    "Это обычные функции и методы, с которым мы работали ранее. При вызове таких функций (методов) они либо выполняются до завершения, либо вызывают ошибку, либо никогда не завершаются (в функции есть бесконечный цикл).\n",
    "\n",
    "Рассмотрим пример асинхронной функции.\n",
    "\n",
    "Представьте, что вы когда-то поставили будильник на 8:30 и с тех пор он исправно выполняет свою работу. Чтобы понять, когда вставать, вам не нужно непрерывно смотреть на часы всю ночь. Нет нужды и посматривать на них периодически (скажем, с интервалом в пять минут). Асинхронная функция «подъём» находится в режиме ожидания. Как только произойдёт событие «на часах 8:30», она сама даст о себе знать.\n",
    "\n",
    "Подробнее об асинхронных функциях можно прочитать здесь https://habr.com/ru/post/667630/."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ДРУГИЕ ФРЕЙМВОРКИ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фреймворк aiohttp тоже близок к Flask, но основан на асинхронном взаимодействии. Aiohttp добавлен в Python версии 3.4.\n",
    "\n",
    "Tornado — относительно старый и более общий асинхронный фреймворк для написания сетевых приложений, но также он умеет работать с HTTP. По заверениям разработчиков, он очень хорошо держит нагрузку. В 2019 году Tornado занимал третье место по популярности среди разработчиков после Django и Flask.\n",
    "\n",
    "В этом юните мы рассмотрели основные фреймворки для реализации веб-сервисов на Python. Далее в курсе мы будем использовать фреймворк Flask, однако если вы уже знакомы с другими фреймворками, вы можете использовать их"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Пишем сервер на Flask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если бы вы попробовали написать сервер в Jupyter Notebook, то почти сразу поняли бы, что он для этого не предназначен. Как минимум потому, что после запуска вы больше не смогли бы выполнить в ноутбуке ни одной команды — программа сервера переходит в режим прослушки сети и ожидания приходящих запросов. Поэтому разработку нашего веб-сервиса мы будем вести в обычных файлах .py.\n",
    "\n",
    "Итак, давайте напишем простое приложение на Flask."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ЧАСТЬ I. ИНИЦИАЛИЗАЦИЯ ВЕБ-ПРИЛОЖЕНИЯ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. В видео эксперт использует IDE PyCharm. Вы можете установить её самостоятельно по инструкции https://pythonru.com/baza-znanij/poshagovaja-ustanovka-pycharm либо использовать ту IDE, к которой вы привыкли, например VS Code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала необходимо установить Flask. Сделать это можно с помощью pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\work\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\work\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask) (2.2.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\work\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\work\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask) (2.1.2)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\work\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from flask) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\work\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=8.0->flask) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\work\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from Jinja2>=3.0->flask) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь импортируем его и создадим объект Flask-приложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы передаём __name__ при инициализации класса Flask, чтобы определить имя, с которым будет использоваться этот модуль. Flask использует расположение файла как точку, к которой он привязывает ресурсы.\n",
    "\n",
    "**Совет**. В абсолютном большинстве случаев можно передавать аргумент __name__ для инициализации класса — приложение будет настроено верно.\n",
    "\n",
    "Теперь мы можем написать функцию, которая будет обрабатывать запросы, и прикрепить её к какому-то пути (URI). Это делается с помощью специального декоратора route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/hello')\n",
    "def hello_func():\n",
    "    return 'hello!'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша функция пока не делает никакой обработки и просто отвечает строкой с приветствием. Нам осталось запустить приложение. Для этого выполним метод run, не забыв занести его в стандартный main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run('localhost', 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. В блоке if __name__ == '__main__' прописывается код, который не должен выполняться при импорте модуля. Переменная __name__ — это специальная переменная, которая будет равна \"__main__\", только если файл запускается как основная программа, и выставляется равной имени модуля при импорте модуля.\n",
    "\n",
    "Например, если мы захотим импортировать файл server.py как внешний модуль,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from server import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "то код, указанный в блоке if __name__ == '__main__', соответствующий запуску сервера, не будет выполнен.\n",
    "\n",
    "Мы запускаем наш сервис в строке app.run('localhost', 5000), указывая адрес сетевого интерфейса и порт, на котором будет работать сервер. В нашем случае мы работаем на локальной машине по IP-адресу 127.0.0.1, или localhost (то есть доступ к сервису может быть получен только с нашего компьютера), а номер порта, по которому можно отправлять запросы, — 5000.\n",
    "\n",
    "Если вы работаете в Jupyter Notebook, сохраните весь код в файле server.py (не в ноутбуке!) и запустите его из командной строки, выполнив команду python server.py."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы должны увидеть примерно такой текст:\n",
    "\n",
    "* Serving Flask app \"server\" (lazy loading)\n",
    "\n",
    "* Environment: production\n",
    "   WARNING: This is a development server. Do not use it in a production deployment.\n",
    "   Use a production WSGI server instead.\n",
    "* Debug mode: off\n",
    "* Running on http://localhost:5000/ (Press CTRL+C to quit)\n",
    "После запуска программа перейдёт в режим прослушивания сети.\n",
    "\n",
    "Теперь откройте браузер и зайдите по адресу http://localhost:5000/hello.\n",
    "\n",
    "Вы увидите текст hello!, а в логах — строку с кодом обработки вашего запроса.\n",
    "\n",
    "**Примечание**. Чтобы прервать работу программы-сервера в VS Code, нажмите сочетание клавиш CTRL + C, находясь в поле терминала. После этого перезапустите скрипт."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7.3**\n",
    "\n",
    "Напишите новую функцию index(), которая будет возвращать строку \"Test message. The server is running\". Оберните эту функцию в декоратор app.route(), указав в качестве эндпоинта '/'. Данный эндпоинт будет соответствовать обращению к сайту по дефолтному адресу: http://localhost:5000/.\n",
    "\n",
    "Перезапустите веб-сервис и зайдите по этому адресу. В поле для ответа введите код обработки, который вернулся в результате выполнения GET-запроса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flask\n",
    "\n",
    "from flask import Flask\n",
    "app = Flask(__name__)\n",
    "@app.route('/')\n",
    "def hello_index():\n",
    "    return 'Test message. The server is running'\n",
    "if __name__ == '__main__':\n",
    "    app.run('localhost', 5000)\n",
    "from server import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ЧАСТЬ II. ПЕРЕДАЧА ПАРАМЕТРОВ ЗАПРОСА"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте немного усложним логику обработки — создадим функцию, которая принимает какой-то параметр и использует его для вычисления результата.\n",
    "\n",
    "Параметры можно передавать тремя способами:\n",
    "\n",
    "- через адресную строку;\n",
    "- через заголовки;\n",
    "- через тело.\n",
    "\n",
    "В заголовках обычно передают сервисные параметры. Так как у метода GET не бывает тела, остаются только **параметры адресной строки**.\n",
    "\n",
    "Вы наверняка видели параметры на сайтах, когда в конец адреса дописывается что-то вроде ?id=10&page=2. Если поставить в конце адреса вопросительный знак, то после него можно добавлять параметры. Передавать можно любые параметры — они будут перечисляться через & и состоять из имени и значения (id=10). Например, если вы будете что-то искать в Google, ваш запрос будет видно в адресной строке в параметре с названием q (от англ. query).\n",
    "\n",
    "Параметры запроса во Flask находятся в специальном объекте request, который нужно импортировать. Параметры адресной строки можно найти в поле args этого объекта, где args — это словарь.\n",
    "\n",
    "Давайте немного модифицируем наш код — теперь сервер будет здороваться и обращаться по имени. Для этого занесём параметр name, полученный из request, в переменную и воспользуемся этим значением, поставив его в форматированную строку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [13/Jun/2023 20:30:39] \"GET /hello?name=world HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/Jun/2023 20:30:39] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "@app.route('/hello')\n",
    "\n",
    "def hello_func():\n",
    "    name = request.args.get('name')\n",
    "    return f'hello {name}!'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run('localhost', 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перезапустите сервер и зайдите по адресу http://localhost:5000/hello?name=world.\n",
    "\n",
    "В результате выполнения запроса вы должны увидеть в браузере текст \"hello world\".\n",
    "\n",
    "Поменяйте значение параметра name в адресной строке на своё имя и выполните новый запрос к серверу, чтобы проверить, что при изменении параметра адресной строки меняется и возвращаемый результат."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7.4**\n",
    "\n",
    "Напишите функцию current_time, которая будет возвращать словарь, где ключ — 'time', а значение — текущее время.\n",
    "\n",
    "**Примечание.** Текущее время можно узнать с помощью модуля datetime:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оберните эту функцию в декоратор app.route() с эндпоинтом /time.\n",
    "\n",
    "Попробуйте обратиться к сервису по заданному эндпоинту.\n",
    "\n",
    "По какой ссылке вы переходили, чтобы увидеть, правильно ли работает ваш скрипт? В поле ниже вставьте ссылку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [14/Jun/2023 14:27:40] \"GET /time HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [14/Jun/2023 14:27:41] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "import datetime\n",
    "app = Flask(__name__)\n",
    "@app.route('/time')\n",
    "def current_time():\n",
    "    return {'time': datetime.datetime.now()}\n",
    "if __name__ == '__main__':\n",
    "    app.run('localhost', 5000)\n",
    "    \n",
    "# http://localhost:5000/time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ЧАСТЬ III. POST-ЗАПРОСЫ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока что мы написали обработчик GET-запроса.\n",
    "\n",
    "Если мы хотим обрабатывать и другие методы, например POST-запросы, это необходимо указать в декораторе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/add', methods=['POST'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что должна возвращать функция-обработчик? Она будет возвращать объект Response, в котором мы должны были бы задать все компоненты ответа: код обработки, заголовки и тело. К счастью, Flask (а точнее, объект Response) умеет и превращать в ответы другие объекты, и самостоятельно формировать ответ.\n",
    "\n",
    "Например, строка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return f'hello {name}!'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "преобразуется в ответ с кодом 200 и телом, состоящим из этой строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return f'hello {name}!', 200"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно возвращать кортеж из двух элементов, строки и числа. Число используется как код обработки.\n",
    "\n",
    "**Примечание**. Вспомогательная функция jsonify поможет преобразовать обычный питоновский словарь в ответ в формате JSON, который очень часто используется для передачи структурированных данных.\n",
    "\n",
    "Вооружившись этими знаниями, напишем обработчик POST-запроса, который будет читать тело запроса в JSON-формате и составлять ответ на основе его содержимого."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "\n",
    "# app = Flask(__name__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем, что функция обрабатывает метод POST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function flask.scaffold.Scaffold.route.<locals>.decorator(f: 'T_route') -> 'T_route'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @app.route('/add', methods=['POST'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем саму функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add():\n",
    "\n",
    "#     num = request.json.get('num')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры тела доступны в поле data. Но если тело — это JSON-строка, то можно использовать поле json.\n",
    "\n",
    "Напишем проверку и укажем код ошибки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if num > 10:\n",
    "#     return 'too much', 400\n",
    "\n",
    "# return jsonify({\n",
    "#     'result': num + 1\n",
    "# })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда функция-обработчик будет иметь следующий вид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/add', methods=['POST'])\n",
    "def add():\n",
    "    num = request.json.get('num')\n",
    "    if num > 10:\n",
    "        return 'too much', 400\n",
    "    return jsonify({\n",
    "        'result': num + 1\n",
    "    })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [14/Jun/2023 15:25:49] \"POST /add HTTP/1.1\" 400 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    app.run('localhost', 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, браузеры не умеют писать POST-запросы самостоятельно. Это реализуется только через клиентские приложения, поэтому нам не хватит обычного браузера, чтобы проверить сервис.\n",
    "\n",
    "Если вы любите визуальные редакторы запросов, рекомендуем обратить внимание на Postman https://www.postman.com/.\n",
    "\n",
    "Напишем простой сервис в **соседнем скрипте**, используя библиотеку requests https://requests.readthedocs.io/en/master/, которая позволяет отправлять HTTP-запросы. Для этого создадим отдельный файл client.py, в котором опишем работу программы клиента.\n",
    "\n",
    "Чтобы выполнить POST-запрос, нужно просто вызвать соответствующую функцию и передать ей адрес (URL) и содержимое тела запроса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     r = requests.post('http://localhost:5000/add', json={'num': 5})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее выведем статус-код ответа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(r.status_code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь пропишем проверку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if r.status_code == 200:\n",
    "\n",
    "#    print(r.json()['result'])\n",
    "# else:\n",
    "\n",
    "#    print(r.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полный код нашего простейшего клиентского приложения будет выглядеть так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # выполняем POST-запрос на сервер по эндпоинту add с параметром json\n",
    "#     r = requests.post('http://localhost:5000/add', json={'num': 5})\n",
    "#     # выводим статус запроса\n",
    "#     print(r.status_code)\n",
    "#     # реализуем обработку результата\n",
    "#     if r.status_code == 200:\n",
    "#         # если запрос выполнен успешно (код обработки=200),\n",
    "#         # выводим результат на экран\n",
    "#         print(r.json()['result'])\n",
    "#     else:\n",
    "#         # если запрос завершён с кодом, отличным от 200,\n",
    "#         # выводим содержимое ответа\n",
    "#         print(r.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Чтобы запустить код клиентского приложения параллельно работающему серверу в VS Code, создайте новый терминал и запустите файл client.py вручную, написав в терминале команду:\n",
    "\n",
    "python client.py\n",
    "\n",
    "<img src=\"data\\DSPROD_md1_7_1.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "Далее можно переключаться между терминалами и запускать в них необходимые команды.\n",
    "\n",
    "<img src=\"data\\DSPROD_md1_7_2.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнив данный код, мы произведём POST-запрос на локальный сервер по эндпоинту add. Так как переданное значение num < 10, то запрос будет выполнен успешно и в терминале, соответствующему программе-клиенту, будет выведено:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 200\n",
    "## 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7.5**\n",
    "\n",
    "В качестве значения параметра num возьмите число 15. Выполните скрипт клиентского приложения. Что будет выведено после выполнения этого скрипта?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # выполняем POST-запрос на сервер по эндпоинту add с параметром json\n",
    "#     r = requests.post('http://localhost:5000/add', json={'num': 15})\n",
    "#     # выводим статус запроса\n",
    "#     print(r.status_code)\n",
    "#     # реализуем обработку результата\n",
    "#     if r.status_code == 200:\n",
    "#         # если запрос выполнен успешно (код обработки=200),\n",
    "#         # выводим результат на экран\n",
    "#         print(r.json()['result'])\n",
    "#     else:\n",
    "#         # если запрос завершён с кодом, отличным от 200,\n",
    "#         # выводим содержимое ответа\n",
    "#         print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 200\n",
    "## 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ДЕПЛОИМ МОДЕЛЬ НА ВЕБ-СЕРВИС"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы рассмотрели базовые принципы работы с фреймворком Flask и научились писать простейшие веб-сервисы. Этого достаточно, чтобы решить нашу первоначальную задачу — задеплоить модель.\n",
    "\n",
    "Нам необходимо написать веб-сервис, который позволит клиентам делать запросы к нашей модели. В ответ клиенты должны получать ответы — предсказания модели. Формат предсказаний обсудим ниже.\n",
    "\n",
    "Файл с сериализованной моделью вы можете найти здесь https://lms-cdn.skillfactory.ru/assets/courseware/v1/edb336d23fdbf18a919f9dbfad55426a/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/model.pkl.\n",
    "\n",
    "У модели, как всегда, есть метод predict, который принимает на вход numpy-массив размерности (кол-во объектов; кол-во признаков). Всего у нас четыре анонимных признака, и их интерпретация сейчас не имеет значения.\n",
    "\n",
    "Давайте обернём процедуру предсказания модели в обработчик POST-запросов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7.6**\n",
    "\n",
    "Используя только что обретённые знания, напишите Flask-приложение, которое по эндпоинту /predict будет слушать POST-запросы на предсказания.\n",
    "\n",
    "В теле POST-запроса — список из четырёх чисел в формате JSON (один объект, четыре признака). Эти числа можно извлечь из запроса следующим образом:\n",
    "\n",
    "    features = request.json\n",
    "\n",
    "Так как на вход модели необходимо подать numpy-массив определённой размерности, а не список, не забудьте перевести результат в тип np.array() и скорректировать его под размер (1, 4) с помощью reshape():\n",
    "\n",
    "    features = np.array(features).reshape(1, 4)\n",
    "\n",
    "После этого подайте полученный вектор на вход модели и получите результат.\n",
    "\n",
    "Обратите внимание, что результатом предсказания также станет не число, а numpy-массив, пусть и состоящий из одного числа. Нас же интересует именно предсказанное число, поэтому не забудьте извлечь результат из полученного массива (обратившись по индексу 0).\n",
    "\n",
    "Ответом на запрос должен быть JSON-формат {\"prediction\": *число - предсказание модели*}.\n",
    "\n",
    "Для проверки запустите свой сервер на порте 5000 локальной машины и выполните проверочный клиентский скрипт https://lms-cdn.skillfactory.ru/assets/courseware/v1/c7270babbb90fc7424c10414b58d3236/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/hw2_check_ol.py.\n",
    "\n",
    "Если всё в порядке и запросы к серверу выполняются корректно, то после запуска проверочного скрипта вы получите в терминале секретный код. Введите этот год в поле ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret word: skillfactory\n",
      "how is this possible? answer is here: https://youtu.be/xm-A-h9QkXg\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Work\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator LinearRegression from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [14/Jun/2023 16:05:56] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "from sklearn import *\n",
    "import numpy as np\n",
    "\n",
    "with open('model.pkl', 'rb') as pkl_file:\n",
    "    model = pickle.load(pkl_file)\n",
    "app = Flask(__name__)\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    features = np.array(request.json)\n",
    "    features = features.reshape(1, 4)\n",
    "    prediction = model.predict(features)\n",
    "    return jsonify({'prediction': prediction[0]})\n",
    "if __name__ == '__main__':\n",
    "    app.run('localhost', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3298f"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поздравляем — теперь у вас есть рабочий прототип модели, который работает на веб-сервисе и умеет выдавать предсказания в ответ на POST-запросы клиентов. Однако это ещё не всё: в следующем юните мы узнаем, как повысить производительность сервиса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *8. GIL. uWSGI + NGINX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот юнит является дополнительным и предназначен для тех, кто хочет немного углубиться в процесс создания настоящих веб-сервисов. Задания в юните не оцениваются.\n",
    "\n",
    "В предыдущем юните мы познакомились с основами веб-разработки и смогли запустить на локальной машине маленький веб-сервер, который может принимать запросы и обрабатывать их. В этой части модуля мы займёмся оптимизацией работы нашего веб-сервиса и поднимем настоящий, полноценный веб-сервер.\n",
    "\n",
    "Сразу отметим: инструменты, рассматриваемые в этом юните, предназначены **исключительно для UNIX-операционных систем (Linux и MacOS)**.\n",
    "\n",
    "В целом, разработка веб-приложений под Windows — не самая популярная идея. Большая часть серверов в продакшн работает на дистрибутивах ОС Linux. Для этого есть много причин, но сейчас мы не будем на них останавливаться. Важно понимать, что некоторые инструменты, такие как uWSGI, который мы будем рассматривать далее, просто не предназначены для ОС Windows, и попытки развернуть такие инструменты на этой ОС бессмысленны. Для Windows существуют свои решения, о которых мы также упомянем.\n",
    "\n",
    "По упомянутой выше причине рекомендуем вам уже сейчас понемногу «перевозить» свою разработку на ОС Linux, если вы не сделали этого раньше. В качестве дистрибутива Linux советуем использовать Ubuntu (версии не ниже 16.04). Ниже приведены способы установки Ubuntu с подобными инструкциями."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**СПОСОБЫ УСТАНОВКИ UBUNTU:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Самый безопасный, простой и рекомендуемый нами способ — установить виртуальную машину Ubuntu с помощью программы виртуализации VirtualBox. Виртуальную машину можно представить как операционную систему внутри другой операционной системы. Подробную инструкцию по установке вы можете найти здесь.\n",
    "- Пользователям Windows также можно использовать Windows Subsystem for Linux (WSL) — подсистему ОС Windows 10, позволяющую разработчикам и тестировщикам запускать нативные приложения Linux, писать скрипты, выполнять команды непосредственно из Windows.\n",
    "  \n",
    "О том, как установить WSL, вы можете прочитать здесь https://learn.microsoft.com/ru-ru/windows/wsl/install.\n",
    "\n",
    "Стоит отметить, что WSL не поддерживает рабочие столы или приложения с графическим пользовательским интерфейсом. Это обычная командная строка Linux. Однако Microsoft позаботились об этом и в IDE VS Code есть возможность вести разработку прямо в Windows, а выполнение программы (запуск сервера) организовывать непосредственно из WSL. То есть, по сути, вся Python-разработка будет выполняться из-под Windows, а работа приложения — на Linux. Подробнее вы можете почитать об этом здесь https://learn.microsoft.com/ru-ru/windows/python/web-frameworks.\n",
    "\n",
    "Самый продвинутый, но в то же время **опасный** способ — установить Linux в качестве второй системы параллельно Windows. Однако при настройке системы неопытным пользователем возможна потеря файлов на исходной ОС. Поэтому, если вы выберете именно этот способ, настоятельно рекомендуем вам быть предельно внимательными и следовать всем приведённым инструкциям. Подробную инструкцию по установке вы можете найти здесь https://losst.pro/ustanovka-linux-ryadom-s-windows-10.\n",
    "\n",
    "Если вы используете первый или третий способы, вам понадобится установить все необходимые инструменты: язык Python встроен в Ubuntu по умолчанию, однако он поставляется без менеджера пакетов pip. Уставив pip, вы сможете установить все необходимые библиотеки (numpy, sklearn, flask и requests).Также вам понадобится IDE (например, VS Code + Jupyter Notebook). О том, как установить эти инструменты на все самые популярные ОС, мы рассказывали в модуле PY-8. «Инструменты для Data Science» https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/85549162b86d4b9895d9e66975332a00  \n",
    "Итак, если вы установили ОС Linux и готовы повысить производительность своего веб-сервиса, давайте начнём."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GIL. ОГРАНИЧЕНИЕ НА МНОГОПОТОЧНОСТЬ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим ситуацию: мы хотим, чтобы сервер с нашей моделью одновременно обрабатывал **несколько процессов**. Если мы попробуем запустить такой сервер, то либо его производительность будет крайне низкой, либо процессы просто не запустятся. Почему?\n",
    "\n",
    "Дело в механизме под названием GIL — Global Interpreter Lock. Он заключается в том, что в любом процессе Python одновременно может работать только один **тред** (один конкретный поток).\n",
    "\n",
    "**Примечание**. Подробнее об отличиях процесса и потока можно узнать здесь https://codechick.io/tutorials/python/python-processes-and-threads."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_8_1.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, процесс Python не может утилизировать многоядерные системы. Для нашей задачи написания веб-сервера это означает, что сервер на Python одновременно может обрабатывать **только один запрос**, и это очень серьёзное ограничение даже для самых простых сервисов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### КАК РЕШИТЬ ПРОБЛЕМУ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хитрость заключается в том, что, раз один процесс может выполнять только один тред на одном ядре, мы просто запустим несколько процессов, чтобы они работали **параллельно**.\n",
    "\n",
    "Существует несколько специализированных веб-серверов, решающих эту задачу, и все они имеют разную степень совместимости с веб-фреймворками Python. Однако принцип работы у них один: вы запускаете команду старта веб-сервера и передаёте в неё в качестве параметра указание на скрипт, в котором написано ваше приложение. Эта команда запустит несколько рабочих процессов (копий главного скрипта), а сама будет заниматься **прослушиванием** входящих запросов и передавать их на обработку в один из запущенных процессов.\n",
    "\n",
    "Если вам интересно узнать, чем специализированные веб-серверы для Python отличаются друг от друга, прочитайте эту статью http://www.8host.com/blog/sravnenie-veb-serverov-prilozhenij-na-osnove-python/.\n",
    "\n",
    "Для Flask используются веб-серверы Gunicorn, связка NGINX + uWSGI и ещё несколько менее популярных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_8_3.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы разберём связку NGINX + uWSGI. Для вас не составит труда самостоятельно разобраться с любым другим способом, поскольку принцип их работы одинаков.\n",
    "\n",
    "**Важно!** Мы рекомендуем вам всегда выполнять все изложенные шаги при настройке сервера. Игнорируйте это предостережение, только если вы на 100 % уверены, что многопоточность вам не понадобится."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРЕДВАРИТЕЛЬНАЯ ПОДГОТОВКА"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед началом давайте зафиксируем все вводные. Наш проект будет храниться в директории /home/<имя пользователя>/web. В этой папке есть папка models, в которой хранится файл с моделью https://lms-cdn.skillfactory.ru/assets/courseware/v1/edb336d23fdbf18a919f9dbfad55426a/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/model.pkl.   \n",
    "Файл с Flask-приложением будет также располагаться в этой папке и будет называться server.py. Здесь же будет лежать файл с кодом клиентской части client.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ├─web\n",
    "#    ├─models\n",
    "#         └─model.pkl\n",
    "#    └─client.py\n",
    "#    └─server.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веб-приложение будет работать локально на порте с номером 5000. У него будет два эндпоинта ('/' и '/predict'), каждому из которых соответствует свой интерфейс (функция, обёрнутая в декоратор app.route):\n",
    "\n",
    "- Первый интерфейс будет соответствовать эндпоинту по умолчанию ('/') — http://localhost:5000. Он поможет нам в тестировании приложения. В результате выполнения запроса по данному адресу должно быть выведено сообщение о том, что сервер успешно работает.\n",
    "- Второй интерфейс будет соответствовать эндпоинту http://localhost:5000/predict. Он предназначен для обработки поступающих POST-запросов. Это тот самый обработчик, который вы должны были написать в задании 7.6 — вставьте свой код на место пропущенной части."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл server.py:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# загружаем модель из файла\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mmodels/model.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m pkl_file:\n\u001b[0;32m      7\u001b[0m     model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(pkl_file)\n\u001b[0;32m      9\u001b[0m \u001b[39m# создаём приложение\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/model.pkl'"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# загружаем модель из файла\n",
    "with open('model.pkl', 'rb') as pkl_file:\n",
    "    model = pickle.load(pkl_file)\n",
    "\n",
    "# создаём приложение\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    msg = \"Test message. The server is running\"\n",
    "    return msg\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    #ваш код здесь\n",
    "    pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run('localhost', 5000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тестирования выполнения POST-запросов на сервере, которые возвращают предсказания модели, будем использовать следующий клиентский скрипт:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл client.py:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # выполняем POST-запрос на сервер по эндпоинту add с параметром json\n",
    "    r = requests.post('http://localhost:5000/predict', json=[1, 0, 1, 24])\n",
    "    # выводим статус запроса\n",
    "    print('Status code: {}'.format(r.status_code))\n",
    "    # реализуем обработку результата\n",
    "    if r.status_code == 200:\n",
    "        # если запрос выполнен успешно (код обработки=200),\n",
    "        # выводим результат на экран\n",
    "        print('Prediction: {}'.format(r.json()['prediction']))\n",
    "    else:\n",
    "        # если запрос завершён с кодом, отличным от 200,\n",
    "        # выводим содержимое ответа\n",
    "        print(r.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительно протестируйте приложение, запустив файл server.py и перейдя в браузере по адресу http://localhost:5000, а также попробовав выполнить клиентский скрипт, формирующий POST-запрос.\n",
    "\n",
    "Если всё работает корректно, можно приступать к работе с uWSGI и NGINX."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WSGI И UWSGI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберём основную терминологию.\n",
    "\n",
    "Flask-приложению нужен интерфейс, который будет запускать приложение в нескольких процессах, обрабатывать поступающие запросы и возвращать пользователю ответ.\n",
    "\n",
    "Для выполнения этих задач был разработан **WSGI (Web-Server Gateway Interface)** — протокол, стандарт взаимодействия между Python-программами, выполняющимися на веб-сервере и самим веб-сервером. Проще говоря, этот стандарт регламентирует, как Python должен обрабатывать запросы от приложений к веб-серверам и обратно."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_8_4.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во взаимодействии, организованном по WSGI-протоколу, участвуют два компонента:\n",
    "\n",
    "- Веб-сервер, который принимает поступающие запросы (uWSGI, Nginx, Apache и т. д.). На схеме выше обозначен как Server.\n",
    "- Веб-приложение, написанное на языке Python. На схеме выше обозначено как App.\n",
    "\n",
    "**uWSGI** — это веб-сервер, который запускает Python-приложения через протокол WSGI. У этого веб-сервера есть и специальная версия протокола WSGI, которая называется uwsgi.\n",
    "\n",
    "**uwsgi** (не путать с uWSGI!) — это бинарная оптимизированная версия протокола WSGI, которая позволяет достичь ещё большей скорости взаимодействия между сервером и приложением"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**УСТАНОВКА UWSGI**\n",
    "\n",
    "Чтобы запустить сервис в настоящем, боевом режиме, установим веб-сервер uWSGI. Это можно сделать с помощью стандартного менеджера пакетов Python pip.\n",
    "\n",
    "В UNIX-системах (Ubuntu/Mac OS) установка производится довольно легко через выполнение перечисленных ниже команд."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для Ubuntu:**\n",
    "\n",
    "    $ sudo apt-get install build-essential python-dev  \n",
    "    $ pip install uwsgi  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для MacOS:**\n",
    "\n",
    "    $ brew install build-essential python-dev\n",
    "    $ pip install uwsgi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы проверить, что установка прошла успешно, выполните в терминале команду:\n",
    "\n",
    "    $ uwsgi --version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если с установкой возникли проблемы, загляните в инструкцию https://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим сервис (файл сервера server.py, который мы писали в прошлых уроках) с помощью веб-сервера uWSGI. Это довольно просто:\n",
    "\n",
    "    $ uwsgi --http :5000 --module server:app\n",
    "\n",
    "Разберём аргументы.\n",
    "\n",
    "- Аргумент http :5000 указывает, что uWSGI должен обрабатывать HTTP-запросы на порте 5000.\n",
    "При необходимости перед двоеточием можно указать хост — localhost, 127.0.0.1 для локального запуска (он используется по умолчанию, если ничего не указано) или 0.0.0.0, чтобы сервис был доступен по всем сетевым интерфейсам.\n",
    "- Аргумент server:app указывает, какое приложение будет запускать uWSGI: модуль server.py (до двоеточия) и объект app внутри этого модуля (после двоеточия)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате выполнения команды появится большое сообщение с указанием всех параметров организованного соединения (начиная от версии uWSGI и операционной системы, на которой запущено приложение, и заканчивая номером процесса pid, закреплённым за запущенным приложением). Вот финальный фрагмент такого сообщения:\n",
    "\n",
    "<img src=\"data\\DSPROD_md1_8_5.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого uWSGI перейдёт в режим ожидания поступающих запросов — прослушивания сети.\n",
    "\n",
    "Чтобы проверить, что ваш веб-сервер работает, обратитесь по адресу localhost в строке браузера, не забывая указать порт, который мы задали для прослушивания сети — http://localhost:5000. Вы должны увидеть сообщение об успешной работе сервера, которое мы прописали в функции index() при реализации приложения.\n",
    "\n",
    "Давайте проверим количество процессов в системе, ведь нашей целью было с помощью uwsgi создать несколько процессов, каждый из которых занимается прослушиваем сети и обработкой поступающих запросов.\n",
    "\n",
    "Для этого в Linux есть специальные инструменты, похожие на диспетчер задач в Windows, и самый продвинутый из них — утилита htop. Она позволяет отслеживать процессы в режиме реального времени, что очень полезно для администрирования серверов. Давайте установим её."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала создайте ещё один терминал, не прерывая работу сервера. В новом терминале запустите следующую команду для установки:\n",
    "\n",
    "    $ sudo apt-get install htop\n",
    "\n",
    "Теперь запустите утилиту htop, введя в терминал команду:\n",
    "\n",
    "    $ htop -t\n",
    "\n",
    "Ключ -t означает, что процессы будут выводиться в виде дерева (от англ. tree), то есть в иерархии сверху будет находиться родительский процесс, а ниже будут располагаться те процессы, которые он породил (дочерние)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате выполнения данной команды будет выведена огромная таблица со всеми процессами, запущенными в системе. В этой таблице нас будут интересовать следующие поля:\n",
    "\n",
    "- PID — идентификатор процесса;\n",
    "- USER — пользователь, запустивший процесс;\n",
    "- TIME+ — время, измеренное в часах (указывает на то, сколько процесс находился в пользовательском и системном времени);\n",
    "- Command — полная командная строка.\n",
    "  \n",
    "Если вы хотите больше узнать о команде htop и её результатах, загляните сюда https://zalinux.ru/?p=3581."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы отфильтровать только нужные нам процессы из полученной таблицы, мы должны нажать клавишу F4, а затем написать слово, которое мы ищем — uwsgi. В результате должно получиться примерно следующее:\n",
    "\n",
    "<img src=\"data\\DSPROD_md1_8_6.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что мы видим? У нас есть **один основной процесс** (он обозначен идентификатором 6921, но ваш идентификатор может отличаться). Этот процесс порождает один дочерний процесс 6922, который и выполняет прослушивание входящих запросов на нашем сервере.\n",
    "\n",
    "Эта ситуация стандартная и пока что ничем не отличается от обычного запуска скрипта — работает только один процесс.\n",
    "\n",
    "Давайте добавим больше процессов, чтобы увеличить пропускную способность сервера. Для этого завершим работу сервера (в терминале с запущенным сервером нажмите сочетание клавиш CTRL+C) и перезапустим его, увеличив количество работающих одновременно процессов до четырёх. Для этого в используемой ранее команде по запуску сервера необходимо дописать параметр --processes, указав количество процессов, и параметр --master (для чего он нужен — обсудим чуть позже):\n",
    "\n",
    "    $ uwsgi --http :5000 --processes 4 --master --module server:app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В соседнем терминале, где запущена утилита htop, мы увидим следующие изменения:\n",
    "\n",
    "<img src=\"data\\DSPROD_md1_8_7.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вновь есть главный (родительский) мастер-процесс с идентификатором 13402, который в свою очередь породил пять дочерних процессов. Четыре из пяти дочерних процессов рабочие — они занимаются прослушиваем сети, а о том, занимается пятый процесс, мы поговорим ниже.\n",
    "\n",
    "Таким образом, мы **увеличили** число рабочих процессов до четырёх. Сделайте несколько запросов к своему веб-сервису и посмотрите на количество Python-процессов в системе.\n",
    "\n",
    "Итак, мы увеличили пропускную способность нашего сервиса.\n",
    "\n",
    "**Обратите внимание!** Это не значит, что сами запросы будут обрабатываться быстрее — в этом смысле код не изменился, и на его выполнение тратится столько же времени. Зато мы получили возможность параллельно обрабатывать до четырёх запросов.\n",
    "\n",
    "Отметим ещё одну возможность, которая позволит облегчить работу с uWSGI. Ранее мы запускали веб-сервер, указывая параметры непосредственно в команде для его запуска. Однако когда параметров становится слишком много, то каждый раз набирать в терминале команду для запуска сервера становится проблематичным. В таком случае лучше определить конфигурацию в отдельном файле. Давайте назовём этот файл \"uwsgi.ini\" и разместим его в директории проекта.\n",
    "\n",
    "Содержимое этого файла похоже на обычный код: слева от \"=\" пишется имя параметра, а справа от него — значение."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начало файла добавим заголовок [uwsgi], чтобы указать uWSGI на необходимость применения настроек, а далее перечислим нужные нам параметры:\n",
    "\n",
    "**Файл uwsgi_config.ini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [uwsgi]\n",
    "# module = server:app\n",
    "\n",
    "# http = 127.0.0.1:5000\n",
    "\n",
    "# processes = 4\n",
    "# master = true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, чтобы запустить uWSGI с указанной в файле конфигурацией, необходимо просто передать путь до файла в параметре --ini:\n",
    "\n",
    "    $ uwsgi --ini uwsgi_config.ini\n",
    "\n",
    "В результате выполнения данной команды в терминале вы увидите то же самое сообщение, что и ранее при запуске uWSGI.\n",
    "\n",
    "Но и это ещё не всё. Как мы уже отметили, на скриншотах, полученных с помощью htop и после запуска uwsgi, видно, что процессов не четыре, а пять. Откуда взялся ещё один? Этот последний процесс является HTTP-роутером, который слушает HTTP-трафик и отправляет его на воркеры (рабочие процессы), то есть он выступает в роли пункта-распределителя.\n",
    "\n",
    "Однако uWSGI — это не самая оптимальная реализация HTTP-роутера. Она существует скорее для отладки веб-разработчиками, что не является нашей зоной компетенции, поэтому сами авторы uWSGI советуют использовать полноценный веб-сервер. И тут появляется NGINX."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NGINX"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NGINX** — это веб-сервер, который оптимизирует нагрузку за счёт **асинхронной архитектуры**, управляемой событиями. Говоря простым языком, архитектура использует одно ядро на один процесс. При этом в одном процессе могут быть сотни тысяч входящих запросов от каждого пользователя. Совместная параллельная обработка позволяет не создавать новые потоки для каждого соединения — это быстро и удобно. Такая высокая производительность делает NGINX самым популярным веб-сервером в мире.\n",
    "\n",
    "На сегодняшний день NGINX поддерживает протокол uwsgi, что позволяет приложениям WSGI, запущенным на uWSGI, лучше взаимодействовать с NGINX. Благодаря этому развёртывание приложений становится очень простым в настройке, чрезвычайно гибким, функциональным, а также может пользоваться преимуществами поставляемых оптимизаций. Всё это делает сочетание uWSGI + NGINX великолепным вариантом для многих сценариев"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЧТО МЫ ХОТИМ УВИДЕТЬ В ИТОГЕ?**\n",
    "\n",
    "Мы хотим, чтобы входящие HTTP-запросы, которые поступают на наш сервис, принимал NGINX, так как у него очень высокая производительность. Далее необходимо, чтобы поступающие запросы по протоколу uwsgi передавались на uWSGI, в котором запущены процессы-воркеры, выполняющие обработку запросов на Flask."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_8_8.png\" alt=\"drawing\" width=\"800\"/>\n",
    "\n",
    "Для того чтобы подключить сервер NGINX к нашему приложению, сначала нужно его установить."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**УСТАНОВКА NGINX**\n",
    "\n",
    "В Linux-системах установка NGINX происходит с помощью одной команды в терминале:\n",
    "\n",
    "    $ sudo apt install nginx  \n",
    "    \n",
    "Для MacOS установка NGINX идентична установке в Linux с той лишь разницей, что вместо менеджера пакетов apt используется homebrew:\n",
    "\n",
    "    $ brew install nginx  \n",
    "\n",
    "Существует и версия для Windows https://nginx.org/ru/docs/windows.html, но некоторые важные функции не поддерживаются в Windows, что лишает веб-сервер значительной части производительности, и его использование под этой ОС как таковое вызывает сомнения.\n",
    "\n",
    "После установки сервер NGINX запускается автоматически. Чтобы проверить, что установка была выполнена успешно, достаточно зайти в браузер и в поисковой строке написать http://localhost (без указания порта). В результате вы должны увидеть примерно следующий результат:\n",
    "\n",
    "<img src=\"data\\DSPROD_md1_8_9.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно отследить, что процесс nginx запущен в системе. Для этого опять же воспользуемся утилитой htop и с помощью фильтрации таблицы с процессами (клавиша F4) найдём нужный нам процесс:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_8_10.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте свяжем uWSGI и NGINX. Чтобы это сделать, нам нужно запустить uWSGI без роутера — место роутера должен занят NGINX, который будет пересылать поступающий трафик, а uWSGI будет слушать трафик прямиком из сокета.\n",
    "\n",
    "Сокет — это программный интерфейс для взаимодействия между двумя процессами (в нашем случае между NGINX и uWSGI). Можно представить себе сокет как специальный файл в памяти, в который один процесс пишет, а другой из него читает. Тогда наша схема организации взаимодействия между клиентами и веб-приложением будет выглядеть следующим образом:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_8_11.jpeg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Если вы всё ещё на Windows, то, к сожалению, сокетов у вас нет и придётся использовать один из TCP-портов по этой инструкции.\n",
    "\n",
    "Итак, чтобы запустить взаимодействие через сокеты, нам достаточно лишь изменить параметр http на socket и указать в нём путь до файла-сокета, через который мы хотим организовать обмен информацией.\n",
    "\n",
    "Файл с названием socket и расширением .sock будет находиться в специальной директории /tmp, которая в UNIX-системах предназначена для хранения временных объектов (/tmp — от англ. “temporary” — «временный»). Создавать его самим не нужно — за нас это автоматически сделает uWSGI при запуске.\n",
    "\n",
    "Также мы выполним очистку сокета после остановки процесса uWSGI. Для этого будем использовать параметр vacuum — благодаря этой опции файл будет самостоятельно удаляться после отключения сервера. Отредактируем наш файл с конфигурацией uWSGI (uwsgi_confug.ini):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл uwsgi_config.ini**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [uwsgi]\n",
    "# module = server:app\n",
    "\n",
    "# socket = /tmp/socket.sock\n",
    "# vacuum = true\n",
    "\n",
    "# processes = 4\n",
    "# master = true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы готовы перезапустить uWSGI:\n",
    "\n",
    "    $ uwsgi --ini uwsgi_config.ini\n",
    "\n",
    "Убедитесь, что в директории /tmp был создан файл socket.sock. Для этого в соседнем терминале выполните команду:\n",
    "\n",
    "    $ ls /tmp/socket.sock\n",
    "\n",
    "Если команда была выполнена без ошибок, то файл существует.\n",
    "\n",
    "Последний большой шаг — настроить NGINX на передачу приходящих HTTP-запросов в созданный сокет-файл. Для этого нам нужно сначала немного изменить глобальную конфигурацию NGINX, а именно дать ему права на запуск от имени суперпользователя (root). Так NGINX сможет иметь доступ на чтение, изменение и исполнение всех файлов в системе, в том числе для файлов сокетов.\n",
    "\n",
    "Открываем во встроенном редакторе nano (или любом другом редакторе) файл с конфигурацией nginx.conf — он находится в директории /etc/nginx:\n",
    "\n",
    "    $ sudo nano /etc/nginx/nginx.conf\n",
    "    \n",
    "В этом файле находим строку user и изменяем имя пользователя на root:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md1_8_12.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем изменения в файле (в nano — CTRL+S) и закрываем его (в nano — CTRL+X).\n",
    "\n",
    "Формально у NGINX есть только один файл конфигурации — тот, который мы только отредактировали. Теоретически конфигурации для каждого приложения можно было бы прописывать именно в нём. Однако так делать не рекомендуется. Для этого уже существуют папки /etc/nginx/sites-available/ и /etc/nginx/sites-enabled.\n",
    "\n",
    "- Первая просто содержит файлы конфигурации, в каждом из которых находится отдельный виртуальный хост.  \n",
    "- Вторая папка содержит ссылки на файлы из sites-available и подключена к основному конфигурационному файлу.  \n",
    "- \n",
    "Чтобы составить конфигурацию nginx для нового приложения, мы сначала должны создать файл конфигурации в папке sites-available, а затем создать ссылку на него в папке sites-enabled. В результате таких неочевидных, но очень важных для безопасности манипуляций мы добавим в глобальную конфигурацию работы NGINX конфигурацию, нужную для нашего приложения.\n",
    "\n",
    "Итак, создадим и откроем на редактирование файл server.conf в папке sites-available:\n",
    "\n",
    "    $ sudo nano /etc/nginx/sites-available/server.conf\n",
    "    \n",
    "Затем введём в него следующее содержимое:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл /etc/nginx/sites-available/server.conf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# server {\n",
    "#     listen 80;\n",
    "#     server_name localhost;\n",
    "#     location / {\n",
    "#         uwsgi_pass unix:/tmp/socket.sock;\n",
    "#         include uwsgi_params;\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте разберёмся, что мы тут прописали. Структура файла очень напоминает JSON-формат. Корневой заголовок server указывает на то, что мы создаём конфигурацию нового сервера NGINX.\n",
    "\n",
    "Внутри этого блока через \";\" указываются следующие поля:\n",
    "\n",
    "- listen — номер порта, который будет прослушивать сервер NGINX. По умолчанию протокол HTTP работает на порте 80. То есть по умолчанию обращение через браузер по любому IP-адресу (например, http://198.102.103.8) — это на самом деле обращение к нему по порту 80 (например, http://198.102.103.8:80). В параметре listen мы указали, что наш сервер NGINX будет слушать адрес 127.0.0.1 (адрес внутренней петли) на порте 80. То есть для обращения к нему будет достаточно ввести в поисковую строку браузера 127.0.0.1 или localhost без указания хоста. Если указать, другой порт, то в адресной строке браузера его также придётся прописывать.\n",
    "- server_name — доменное имя. Так как у нас нет зарегистрированного доменного имени, то в качестве него мы указываем localhost.\n",
    "\n",
    "- В блоке location мы указываем эндпоинт (по умолчанию всегда обращаемся к корневому эндпоинту \"/\"), а также параметры, соответствующие этому блоку:\n",
    "    - uwsgi_pass — команда, указывающая на то, что поступающие запросы будут передаваться на uwsgi. В аргументах этой команды мы отметили, что взаимодействие организовано через UNIX-сокеты, и указали путь до сокета (/tmp/socket.sock), по которому происходит обмен данными между NGINX и uWSGI.\n",
    "    - include — команда для подключения файлов. Мы подключаем файл uwsgi_params, в котором указаны общие параметры работы uWSGI.\n",
    "  \n",
    "После завершения редактирования файл server.conf сохраняем его содержимое (CTRL+S) и выходим из редактора (CTRL+X)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда файл с конфигурацией готов, создаём на него символическую ссылку (аналог ярлыков в Windows) в папке sites-enabled. В Linux за это отвечает команда ln. Её синтаксис выглядит следующим образом:\n",
    "\n",
    "ln опции файл_источник файл_ссылки\n",
    "Для создания символических ссылок используется ключ -s.\n",
    "\n",
    "Подробнее о команде ln вы можете прочитать здесь.\n",
    "\n",
    "Тогда команда в терминале будет выглядеть следующим образом:\n",
    "\n",
    "    $ sudo ln -s /etc/nginx/sites-available/server.conf /etc/nginx/sites-enabled\n",
    "\n",
    "Теперь наша конфигурация активирована.\n",
    "\n",
    "Проверим, не было ли обнаружено ошибок при сборке конфигурации. Для этого используется команда nginx с ключом -t (test).\n",
    "\n",
    "    $ sudo nginx -t\n",
    "\n",
    "Если ошибок не будет обнаружено, перезапустим процесс nginx для чтения новой конфигурации и для управления процессами (запуска/остановки и т. д.). Для этого в UNIX-системах есть утилита systemctl:\n",
    "\n",
    "    $ sudo systemctl restart nginx\n",
    "\n",
    "Чтобы проверить результат, откройте браузер и сделайте запрос http://localhost. Если всё прошло успешно и в браузере вам было выведено отладочное сообщение, поздравляем — вы успешно запустили NGINX и связали его работу с uWSGI.\n",
    "\n",
    "**Обратите внимание**, что для доступа к серверу нам теперь не нужно указывать номер порта, ведь мы запустили NGINX на порте 80 (указали это в файле server.conf), а он используется по умолчанию."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Что происходит?**\n",
    "\n",
    "При поступлении запроса на порт 80 NGINX транслирует его в обозначенный сокет по протоколу uwsgi. Процесс uWSGI, подключенный к этому сокету, обработает его на одном из запущенных процессов с нашим кодом, и ответ уйдёт тем же путём в обратной последовательности.\n",
    "\n",
    "Таким образом, наш сервис стал **производительнее**, ведь он может параллельно обрабатывать несколько запросов.\n",
    "\n",
    "**А что дальше?**\n",
    "\n",
    "Мы проделали большую работу. Однако, как вы могли заметить, наш веб-сервис сейчас работает только локально, то есть доступ к нему можно получить только с вашего компьютера. В рамках нашего курса заводить полноценный веб-сервис, доступный в интернете, нам не нужно — нам было достаточно лишь прикоснуться к веб-программированию и потренироваться разворачивать собственный веб-сервис на локальной машине, поэтому мы смело можем закончить на этом этапе.\n",
    "\n",
    "В реальности, как вы понимаете, доступ к сервису должен быть у всех компьютеров. Для того чтобы организовать возможность обращения к вашему серверу через интернет, вам нужно получить доменное имя (купить или получить бесплатно https://www.reg.ru/blog/kak-zaregistrirovat-besplatnyj-domen-3-sposoba/), привязанное к IP-адресу вашего сервера. После этого в конфигурации NGINX вашего веб-сервера (server.conf) нужно будет заменить параметр server_name с localhost на доменное имя или IP-адрес вашего сервера:\n",
    "\n",
    "    server_name your_domain www.your_domain;  \n",
    "Так ваш сервер сможет обрабатывать запросы, поступающие от внешних пользователей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Итоги"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⭐ Поздравляем с прохождением первого модуля, посвящённого машинному обучению в продакшене!\n",
    "\n",
    "В ЭТОМ МОДУЛЕ ВЫ:\n",
    "\n",
    "Узнали:\n",
    "\n",
    "- как сохранять обученные модели в файлы и обмениваться ими;  \n",
    "- как использовать обученные модели в приложениях, реализованных на языках программирования, отличных от Python;  \n",
    "- основные концепции межсетевого взаимодействия;  \n",
    "- несколько самых популярных веб-фреймворков Python и сравнили их между собой;  \n",
    "- как решать проблему GIL для Python с помощью протокола uwsgi;  \n",
    "\n",
    "Научились:\n",
    "\n",
    "- отличать сериализацию от десериализации;  \n",
    "- реализовывать простейшие веб-сервисы на Flask;  \n",
    "- разворачивать свой сервер на NGINX.  \n",
    "\n",
    "Стоит отметить, что в процессе разработки нашего сервиса мы не учли одну очень важную особенность — воспроизводимость и изолированность. В чём сейчас состоит проблема? Когда мы передадим исходный код своему коллеге Василию, может оказаться так, что он у него попросту не запустится. Этому может быть множество причин: разница в версиях библиотек, в установленных путях до файлов, в конце концов — в операционных системах. Как же тогда быть?\n",
    "\n",
    "Забегая вперёд, скажем, что для поддержки принципа воспроизводимости кода используются изоляция, виртуализация и контейнеризация. О них мы как раз и поговорим в следующем модуле.\n",
    "\n",
    "Дополнительные материалы:\n",
    "\n",
    "- документация по работе с Pickle https://docs.python.org/3/library/pickle.html;\n",
    "- документация по работе с Joblib https://joblib.readthedocs.io/en/latest/;\n",
    "- список фреймворков для разработки HTTP-серверов на странице https://wiki.python.org/moin/WebFrameworks;\n",
    "- обновляемый список ресурсов и плагинов для Flask https://github.com/humiaozuzu/awesome-flask;\n",
    "- описание различных уровней взаимодействия сетей по сетевой модели OSI https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D1%82%D0%B5%D0%B2%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C_OSI;\n",
    "- исчерпывающий список кодов состояния протокола HTTP https://ru.wikipedia.org/wiki/%D0%A1%D0%BF%D0%B8%D1%81%D0%BE%D0%BA_%D0%BA%D0%BE%D0%B4%D0%BE%D0%B2_%D1%81%D0%BE%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D1%8F_HTTP;\n",
    "- подробное описание REST-архитектуры https://medium.com/@andr.ivas12/rest-%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%8B%D0%BC-%D1%8F%D0%B7%D1%8B%D0%BA%D0%BE%D0%BC-90a0bca0bc78;\n",
    "- Postman (для любителей визуальных редакторов запросов) https://www.postman.com/."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
