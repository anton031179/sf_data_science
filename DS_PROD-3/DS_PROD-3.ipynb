{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Введение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добро пожаловать в заключительный модуль из раздела «ML в Production»!\n",
    "\n",
    "В предыдущих модулях мы научились производить сериализацию и десериализацию моделей, разворачивать собственные простейшие веб-сервисы, создавать для них виртуальные окружения и контейнеризировать их.\n",
    "\n",
    "В этом модуле нам понадобятся полученные ранее знания, поэтому давайте освежим их, выполнив несколько заданий."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот модуль будет посвящён трём глобальным темам, одна из которых — основная, а остальные — бонусные.\n",
    "\n",
    "**Микросервисная архитектура приложения**.\n",
    "\n",
    "В основной части модуля мы поговорим о двух подходах к построению архитектуры приложения (**монолитный** и **микросервисный**), рассмотрим их плюсы и минусы и обсудим, когда нужно использовать тот или иной подход.\n",
    "\n",
    "Затем мы перейдём к обсуждению микросервисного подхода и разберём, какие существуют варианты организации взаимодействия между сервисами и какие инструменты помогают решать эти задачи.\n",
    "\n",
    "В качестве практики мы организуем вокруг модели машинного обучения несколько микросервисов, которые будут взаимодействовать через очередь RabbitMQ.\n",
    "\n",
    "После этого мы разместим наши сервисы в docker-контейнерах и придём к понятию оркестрации. С помощью инструмента оркестрации Docker Compose мы создадим небольшое микросервисное приложение, в котором каждый сервис будет работать внутри контейнера.\n",
    "\n",
    "**Инструменты управления жизненным циклом модели**.\n",
    "\n",
    "В этой части модуля мы поговорим о современных инструментах, которые можно использовать для управления жизненным циклом модели, а именно о DVC и MLflow.\n",
    "\n",
    "**Оценка бизнес-эффективности**.\n",
    "\n",
    "В заключительной части модуля мы поговорим о том, как можно оценить эффективность построенных нами моделей машинного обучения с точки зрения бизнеса, какие существуют бизнес-метрики, и обсудим, какие трудности могут нас ожидать."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЦЕЛИ МОДУЛЯ:**\n",
    "\n",
    "- узнать, какие виды сервисной архитектуры существуют и в чём их особенности;  \n",
    "- научиться настраивать взаимодействие между сервисами с помощью очередей;\n",
    "- узнать, что такое брокер сообщений и для чего он нужен;  \n",
    "- понять, как можно отслеживать работу сервиса или группы сервисов;  \n",
    "- познакомиться с термином «оркестрация» и узнать, почему она необходима при микросервисной архитектуре;  \n",
    "- научиться работать с Docker Compose;  \n",
    "- рассмотреть несколько инструментов, которые могут помочь на различных этапах жизненного цикла модели;  \n",
    "- узнать, как оценивать эффективность полученных моделей с точки зрения бизнес-эффекта.  \n",
    "\n",
    "Давайте приступим."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Монолитная и микросервисная архитектуры. Брокеры и очереди"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требования продакшн-среды влияют и на выбор архитектуры. Существует два её основных типа: **монолитная** и **микросервисная**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Монолитная** <img src=\"data\\DSPROD_md3_2_1.png\" alt=\"drawing\" width=\"200\"/>  **Микросервисная** <img src=\"data\\DSPROD_md3_2_1.png\" alt=\"drawing\" width=\"200\"/> \n",
    "\n",
    "При **монолитной архитектуре** контексты приложения запускаются на сервере с помощью внутрипроцессных взаимодействий.\n",
    "\n",
    "Таким образом, приложение включает в себя все функции, и они взаимодействуют в одной запущенной программе, написанной на одном конкретном языке программирования."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Микросервисная архитектура** — это подход, позволяющий инкапсулировать определённые контексты приложения: то есть каждая функция приложения вынесена в отдельную небольшую программу или сервис.\n",
    "\n",
    "Приложение разделено на небольшие, не зависящие друг от друга компоненты — микросервисы. У каждого из них своя задача, например управлять каталогом, хранить и обновлять содержимое корзины или проводить оплату заказа."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание.** Впервые о микросервисах заговорили ещё в 2000‑х, но концепция архитектуры сформировалась только к началу 2010‑х. К 2014 году технологию внедрили такие крупные компании, как Netflix, Amazon и Twitter. Сегодня микросервисы используют гораздо активнее. В 2020 году в отчёте Cloud Microservices Market Research https://www.researchandmarkets.com/reports/4787543/cloud-microservices-market-growth-trends рынок облачных микросервисов оценили в 831,45 млн долларов США. К 2026 году его масштабы могут увеличиться более чем в три раза."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРЕИМУЩЕСТВА И НЕДОСТАТКИ МИКРОСЕРВИСНОГО ПОДХОДА В РАЗРАБОТКЕ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\happy-icon.png\" alt=\"drawing\" width=\"50\"/>  \n",
    " \n",
    "- Повышение автономности различных частей продукта. Мы можем разрабатывать их раздельно и разными командами (при этом отслеживая версионность).  \n",
    "- Гибкость и масштабируемость. За счёт модульности приложения мы можем масштабировать только ту часть, которая требует дополнительных ресурсов. Подробнее об этом мы поговорим ниже.  \n",
    "- Повышение стабильности. Если что-то перестало работать, будет недоступен только один функционал, а не приложение целиком.  \n",
    "- Горизонтальная масштабируемость. Микросервисы позволяют запускать приложение на разных серверах.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\sad-icon.png\" alt=\"drawing\" width=\"50\"/>   \n",
    "\n",
    "- Сложность разработки из-за наличия различных технологий.  \n",
    "- Накладные расходы на сериализацию и десериализацию сообщений.  \n",
    "- Время работы напрямую зависит от взаимодействия сервисов.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### МАСШТАБИРУЕМОСТЬ СИСТЕМЫ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По мере роста и развития приложения, увеличения числа пользователей и данных у команды неизбежно возникают вопросы:\n",
    "\n",
    "1. Как обрабатывать N запросов в секунду? Как уменьшить время обработки одного запроса?\n",
    "2. Как и в чём хранить постоянно увеличивающийся в объёме поток данных от пользователей?\n",
    "3. Как подстраховаться от падения БД (ведь это трата времени и, следовательно, потеря денег)?\n",
    "4. Как добиться высокой степени доступности приложения для всех пользователей?\n",
    "5. Что делать с тяжёлыми запросами, которые могут выполняться часами?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обобщая эти и подобные вопросы, говорят о **масштабируемости** системы — её способности выдерживать рост нагрузки по мере добавления ресурсов.\n",
    "\n",
    "Давайте разберёмся в этом подробнее. При создании действительно крупных приложений существует два подхода:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_2_3.png\" alt=\"drawing\" width=\"500\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Вертикальное масштабирование** (scale up): заменить сервер сервером с большей вместимостью и мощностью. Как вы понимаете, у всего есть предел.\n",
    "- **Горизонтальное масштабирование** (scale out): добавить ещё один сервер и объединить серверы в кластер.\n",
    "\n",
    "Идеальный вариант — добиться **линейной зависимости**, то есть сделать так, чтобы при добавлении ресурсов приложение выдерживало прямо пропорциональный рост нагрузки. Однако такое встречается редко из-за неоптимальной работы разных частей системы: так, добавление дополнительного сервера, обрабатывающего запросы, может увеличить параметр максимальной нагрузки в два раза, а вот добавление ещё двух серверов вряд ли увеличит этот параметр в четыре раза."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ЧТО МЫ МОЖЕМ СДЕЛАТЬ ДЛЯ ЛУЧШЕГО МАСШТАБИРОВАНИЯ СИСТЕМЫ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Добавить **балансировщики нагрузки** перед дублирующими друг друга серверами. Эти балансировщики будут отправлять запросы на те серверы, на которых нагрузка меньше, чем на остальных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_2_4.png\" alt=\"drawing\" width=\"500\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Добавить кэш** — быстрый «буфер» между базой данных и приложением. В таком случае диспетчер сначала проверит в кэше, не выполнялся ли аналогичный запрос раньше, и только потом направит его на сервер."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_2_5.png\" alt=\"drawing\" width=\"500\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Оптимизировать работу БД**:\n",
    "\n",
    "- скопировать БД, чтобы застраховаться от её падения;\n",
    "- денормализовать данные, чтобы все поля содержались в одной таблице — так мы избежим дополнительной нагрузки на объединение данных;\n",
    "- оптимизировать SQL-запросы, повысив скорость их обработки.\n",
    "\n",
    "4. **Добавить асинхронные очереди сообщений** между частями системы. Подробнее об асинхронном взаимодействии сервисов мы поговорим в следующем блоке."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_2_6.png\" alt=\"drawing\" width=\"500\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### КОГДА ИСПОЛЬЗОВАТЬ МИКРОСЕРВИСНУЮ АРХИТЕКТУРУ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбор архитектуры должен основываться на понимании всех требований к разрабатываемому приложению.\n",
    "\n",
    "Разработчики Яндекс составили небольшой перечень критериев https://cloud.yandex.ru/blog/posts/2022/03/microservice-architecture, по которым вы можете понять, подходит ли вашему проекту микросервисная архитектура. Если ваш проект соответствует хотя бы одному пункту из этого списка, задумайтесь об использовании микросервисов.\n",
    "\n",
    "- **Большие коллективы**.\n",
    "\n",
    "Микросервисы позволяют группам разработчиков не задумываться о синхронизации каждого шага: каждая команда может работать над одним или несколькими микросервисами и использовать свои инструменты.\n",
    "\n",
    "Новые фичи можно разрабатывать параллельно и запускать по мере готовности.\n",
    "\n",
    "- **Объёмные проекты со сложной архитектурой**.\n",
    "\n",
    "Обновлять и поддерживать отдельные модули крупных систем намного проще, чем контролировать, как изменения скажутся на системе в целом.\n",
    "\n",
    "- **Продукты с резко меняющимся трафиком**.\n",
    "\n",
    "Если вашим продуктом начинают чаще пользоваться в период праздников или распродаж, микросервисы позволят вам быстро масштабироваться и уменьшить риск отказа системы. Кроме того, вам не придётся платить за дополнительную инфраструктуру, которая нужна только в периоды пиковых нагрузок.\n",
    "\n",
    "- **Приложения, требующие частых обновлений**.\n",
    "\n",
    "Достаточно изменить и отладить только тот модуль, который вы хотите обновить. Это существенно сокращает время разработки и приближает релиз.\n",
    "\n",
    "Однако главный вопрос, который вам стоит задать себе, прежде чем погружаться в мир микросервисов: можно ли разделить ваш продукт на простые независимые части? Хороший микросервис должен быть легковесным, автономным, обходиться собственной изолированной базой данных и решать одну конкретную бизнес-задачу.\n",
    "\n",
    "Если ваш проект можно разделить на такие самостоятельные составные части, то вы можете смело выбирать микросервисы в качестве архитектуры своего приложения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ВЗАИМОДЕЙСТВИЕ МЕЖДУ СЕРВИСАМИ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-1.png\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже поняли, при создании микросервисной архитектуры требуется **организация обмена данными между сервисами**.\n",
    "\n",
    "Давайте разберёмся, какие существуют типы организации взаимодействия сервисов:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Синхронный**\n",
    "\n",
    "Один сервис обращается к другому и ожидает ответа.\n",
    "\n",
    "Для организации синхронного взаимодействия используется протокол HTTP или HTTPS. Сервисы обмениваются данными через HTTP-запросы.\n",
    "\n",
    "Разработка и отладка просты, однако сервис должен быть постоянно доступен — в противном случае обмен сообщениями остановится."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Асинхронный**\n",
    "\n",
    "Сервисы взаимодействуют между собой путём передачи сообщений. Таким образом, сервис не ожидает ответ, а продолжает работу. Нужный сервис принимает сообщение и начинает его обработку.\n",
    "\n",
    "Для организации асинхронного взаимодействия используются очереди сообщений. О них мы поговорим ниже."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_2_7.png\" alt=\"drawing\" width=\"600\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### БРОКЕРЫ СООБЩЕНИЙ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Брокеры сообщений (также их называют **диспетчеры очереди**) помогают организовать межсистемный обмен сообщениями и являются связующим звеном между различными процессами в приложениях.\n",
    "\n",
    "Как правило, в таких системах используется паттерн проектирования **«издатель → очередь → подписчик»** (producer → queue → consumer). Под издателем и подписчиком здесь можно понимать всё что угодно (например, микросервисы или целые приложения), то есть это абстрактные понятия, не привязанные к конкретной реализации.\n",
    "\n",
    "Издатель отправляет сообщение на брокер сообщений, который помещает полученное сообщение в очередь. На одном брокере может быть запущено несколько очередей, например очередь запросов, очередь ответов и служебная очередь, в которую записываются служебные сообщения (логи). После этого сообщение извлекается из очереди и передаётся подписчику.\n",
    "\n",
    "Издателей и подписчиков может быть несколько, и они могут взаимодействовать друг с другом через очереди в асинхронном режиме, то есть им не нужно останавливать свой процесс работы в ожидании ответного сообщения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_2_8.png\" alt=\"drawing\" width=\"600\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благодаря брокерам сообщений отправителю не нужно ничего знать о потребителе или потребителях, поэтому связь между сервисами значительно упрощается. Однако поддержка инфраструктуры с участием очереди становится немного сложнее.\n",
    "\n",
    "Чтобы обеспечить хранение сообщений в очереди до момента их прочтения получателем, доступ к очереди должен быть **асинхронным**.\n",
    "\n",
    "Структура данных очереди представлена следующими правилами:\n",
    "\n",
    "- первым «читается» сообщение, пришедшее первым;\n",
    "- новые элементы добавляются только в конец очереди;\n",
    "- чтение и удаление происходит только из начала очереди."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_2_9.png\" alt=\"drawing\" width=\"200\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, для организации очереди необходимо определиться с форматом сообщений (например, XML или JSON). Однако это сильно зависит от типа реализации очереди — бывают случаи, когда определять формат нет необходимости."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРИМЕР, КОГДА МОЖЕТ ПОНАДОБИТЬСЯ ИСПОЛЬЗОВАНИЕ ОЧЕРЕДЕЙ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На веб-сервере функционирует огромная нейронная сеть или другая крупная модель. Если клиенты будут отправлять свои данные (например, изображения), а сервер будет принимать эти запросы и обрабатывать данные, подавая их в модель, то время задержки на обработку каждого запроса будет очень большим.\n",
    "\n",
    "Поэтому идея следующая: пусть сервер — это отдельный микросервис. Назовём его server (это обычное веб-приложение, реализованное, например, через стек Flask + uWSGI + NGINX). Этот микросервис решает одну задачу: принимает сообщения от клиентов, присваивает им идентификаторы, но не обрабатывает их, а помещает в очередь обработки (назовём её data).\n",
    "\n",
    "Для прогона данных через модель будет реализован отдельный микросервис (назовём его model). Внутри него тоже может быть что угодно, например нейронная сеть, которая проводит сегментацию изображений. Этот микросервис извлекает сообщения с данными от пользователя из очереди, обрабатывает их моделью и отправляет в другую очередь (назовём её predictions).\n",
    "\n",
    "Сервер в фоновом режиме просматривает очередь predictions и, если в ней появилось новое сообщение (предсказание модели), извлекает его и отправляет нужному клиенту"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_2_10.png\" alt=\"drawing\" width=\"500\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наиболее популярны следующие программные реализации очереди:\n",
    "\n",
    "- RabbitMQ https://www.rabbitmq.com/,\n",
    "- Apache Kafka https://kafka.apache.org/,\n",
    "- ActiveMQ https://activemq.apache.org/.\n",
    "  \n",
    "Чтобы понять принципы работы с очередями сообщений и сериализацией, мы разберём диспетчер сообщений RabbitMQ https://www.rabbitmq.com/. Он прост в использовании, максимально эффективен, работает на разных системах и пользуется большой популярностью.\n",
    "\n",
    "**Примечание**. Также стоит отметить, что с помощью протокола HTTP возможно организовать не только синхронное, но и асинхронное взаимодействие, однако эта тема выходит за рамки нашего курса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Организация взаимодействия через очереди. RabbitMQ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы рассмотрим основные концепции работы с брокером очередей RabbitMQ: мы создадим несколько микросервисов на Python и организуем их асинхронное взаимодействие через этот брокер.\n",
    "\n",
    "Сначала мы рассмотрим основную терминологию, которая пригодится нам в работе с RabbitMQ, а затем перейдём к реализации взаимодействия сервисов.\n",
    "\n",
    "Как вы помните, объект из памяти одного процесса нельзя напрямую перенести в память другого, поскольку объект может иметь сложную структуру и быть разбит на фрагменты в оперативной памяти. Чтобы сохранить целостность объекта, применяется **сериализация**.\n",
    "\n",
    "При сохранении и загрузке моделей мы проводим эти операции один раз, поэтому это не увеличивает нагрузку на процессы. Для организации взаимодействия сервисов необходимо **сериализовывать** каждое сообщение (например, вектор входных данных) при его отправке, **десериализовывать** его после получения в сервисе для подачи в модель и уже после преобразовывать его в поток битов предсказания. Это требует ресурсов.\n",
    "\n",
    "**Совет**. Если добавить сжатие данных, то потребуется больше ресурсов CPU на их чтение и запись, но сам объём данных будет меньше. Таким образом мы уменьшим нагрузку на сеть и диск.\n",
    "\n",
    "Для взаимодействия между сервисами чаще всего используется уже знакомый вам формат JSON.\n",
    "\n",
    "Вы можете освежить свои знания по формату JSON модуле «PY-16. Как выгружать данные из различных форматов» https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/063b87d3d34d4617abd6de967a7fc132. Для работы с этим форматом используется библиотека json https://python-scripts.com/json, которая очень похожа на pickle.\n",
    "\n",
    "Для примера работы с брокером очередей мы возьмём интеграцию RabbitMQ и Docker https://www.docker.com/why-docker. Для подключения наших процессов к очереди будем использовать библиотеку pika. Давайте разберёмся, как это работает."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ОСНОВЫ РАБОТЫ С RABBITMQ. AMQP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RabbitMQ — это брокер сообщений, основная цель которого — принимать и отдавать сообщения.\n",
    "\n",
    "Можете представить себе RabbitMQ как почтовое отделение: когда вы опускаете письмо в ящик, вы можете быть уверены, что рано или поздно почтальон доставит его адресату. В этой аналогии RabbitMQ является одновременно и почтовым ящиком, и почтовым отделением, и почтальоном.\n",
    "\n",
    "Отличие RabbitMQ от почтового отделения в том, что он не имеет дела с бумажными конвертами, а принимает, хранит и отдаёт сообщения в бинарном (сериализованном) виде.\n",
    "\n",
    "RabbitMQ использует протокол AMQP (Advanced Message Queuing Protocol) https://www.rabbitmq.com/tutorials/amqp-concepts.html.\n",
    "\n",
    "**Протокол AMQP** — открытый стандарт передачи сообщений. Он позволяет подсистемам/независимым приложениям обмениваться сообщениями через AMQP-брокер, отвечающий за маршрутизацию, доставку сообщений, распределение нагрузки и так далее.\n",
    "\n",
    "Основная терминология AMQP:\n",
    "\n",
    "- **Message** (сообщение) — передаваемые данные.\n",
    "- **Exchange** (точка обмена) — механизм маршрутизации сообщений. Точка обмена получает сообщения и распределяет их по очередям (одно сообщение может уйти в одну или несколько очередей), но при этом сама она не хранит сообщения. В самом простом случае для маршрутизации сообщений используется ключ (routing key), равный названию очереди, в которую нужно отправить сообщение. Иными словами, routing key — это виртуальный адрес очереди.\n",
    "- **Bindings** (правила распределения) — правила, по которым точка обмена определяет, куда именно нужно отправить пришедшее сообщение.\n",
    "Queue (очередь) хранит сообщения до тех пор, пока какой-нибудь AMQP-клиент не заберёт их.\n",
    "- **Producer** (издатель) — клиент, публикующий сообщения в exchange.\n",
    "- **Consumer** (подписчик) — клиент, получающий сообщения из очередей.\n",
    "- **Connection** (соединение) — служит для физического сетевого соединения между клиентом и брокером и объединения нескольких каналов.\n",
    "- **Channel** (канал) — используется для логического соединения между клиентом и брокером."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_3_2.png\" alt=\"drawing\" width=\"600\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание. Более подробно о принципах работы протокола AMQP можно узнать здесь https://habr.com/post/62502/.\n",
    "\n",
    "Чтобы реализовать AMQP на Python, мы воспользуемся библиотекой pika https://pika.readthedocs.io/en/stable/. Мы выбрали эту библиотеку, поскольку она подойдёт для любого брокера, который работает по протоколу AMQP."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные функции библиотеки, с которыми мы будем работать:\n",
    "\n",
    "- BlockingConnection — объявление соединения;\n",
    "- channel — объявление канала;\n",
    "- queue_declare — объявление очереди;\n",
    "- basic_publish — отправка сообщения;\n",
    "- basic_consume — получение сообщения;\n",
    "- callback — метод, вызываемый при получении сообщения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### УСТАНОВКА ИНСТРУМЕНТОВ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 0**. Установка Docker.\n",
    "\n",
    "Этот шаг вы выполняли ещё в прошлом модуле https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/4ebdc9f22f0b4598a7f943455e0a01c8."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 1**. Установка RabbitMQ.\n",
    "\n",
    "Теперь, когда Docker уже есть в нашей системе, достаточно просто включить брокер сообщений RabbitMQ — он находится в Docker Registry в виде образа rabbitmq. Мы будем пользоваться версией 3-management. Давайте запустим docker-контейнер на основе этого образа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3-management"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь:\n",
    "\n",
    "- p 5672:5672 — порт для доступа к очереди;   \n",
    "- p 15672:15672 — порт для доступа к пользовательскому интерфейсу RabbitMQ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После выполнения команды на экране появится большое информационное сообщение и брокер уйдёт в режим ожидания сообщений.\n",
    "\n",
    "Наша очередь работает и готова к приёму сообщений — к ней можно обратиться по адресу localhost:5672.\n",
    "\n",
    "**Примечание**. Вы можете войти в режим графического интерфейса управления RabbitMQ. Для этого перейдите по адресу http://localhost:15672. В результате откроется окно графического интерфейса RabbitMQ, с помощью которого вы можете управлять очередями и другими компонентами RabbitMQ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_3_3.png\" alt=\"drawing\" width=\"900\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 3**. Установка библиотеки pika.\n",
    "\n",
    "Установим её через pip-команду, сразу зафиксировав нужную нам версию (1.1.0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ pip install pika==1.1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, всё готово к работе. Давайте обсудим план наших действий."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЧЕМ БУДЕМ ЗАНИМАТЬСЯ?**\n",
    "\n",
    "Мы реализуем несколько сервисов:\n",
    "\n",
    "1. Первый будет отправлять признаки в одну очередь и истинный ответ — в другую.\n",
    "2. Второй сервис будет читать признаки, делать предсказание и отправлять его в очередь с предсказаниями.\n",
    "3. Третий сервис будет читать очереди с истинными ответами и предсказаниями.\n",
    "\n",
    "Схематично описанную архитектуру можно представить в следующем виде:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_3_4.png\" alt=\"drawing\" width=\"500\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте заранее организуем директорию нашего проекта. Это нужно для дальнейшего удобства, когда мы будем помещать каждый из сервисов в отдельный контейнер.\n",
    "\n",
    "Рабочую папку проекта назовём microservice_architecture. В этой папке будут три другие папки: features, model и metric. Внутри каждой из этих папок будет по папке src, в которой хранится исходный код для каждого сервиса: features.py, model.py и metric.py. Также в папке model/src/ будет находиться файл с сериализованной моделью — что это за модель, мы посмотрим чуть позже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# microservice_architecture\n",
    "#     └─features\n",
    "#         └─src\n",
    "#             └─features.py\n",
    "#     └─model\n",
    "#         └─src\n",
    "#             └─model.py\n",
    "#             └─myfile.pkl\n",
    "#     └─metric\n",
    "#         └─src\n",
    "#             └─metric.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После создания рабочей директории можно переходить к разработке самих микросервисов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**СЕРВИС I. СЕРВИС ОТПРАВКИ ПРИЗНАКОВ**\n",
    "\n",
    "Приступим к созданию первого сервиса — сервиса для отправки признаков в одну очередь, а истинных ответов — в другую.\n",
    "\n",
    "Создадим файл features/src/features.py, в котором будем реализовывать сервис. Этот сервис будет брать случайную строку из датасета и отправлять полученные признаки объекта в очередь.\n",
    "\n",
    "Сначала импортируем необходимые библиотеки, загрузим датасет (используем знакомый нам датасет о диабете) и создадим переменную random_row, значение которой будет соответствовать случайному числу от 0 до N - 1, где N — количество объектов в выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pika\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "# Загружаем датасет о диабете\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "# Формируем случайный индекс строки\n",
    "random_row = np.random.randint(0, X.shape[0]-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, в нашем скрипте можно будет получить случайный вектор признаков X[random_row] и истинный ответ для него — y[random_row].\n",
    "\n",
    "Давайте подключимся к брокеру и попробуем отправлять в очередь y_true случайную метку y[random_row]. Для организации соединения следует создать объект BlockingConnection. В его инициализатор необходимо передать объект с параметрами организуемого соединения — ConnectionParameters. Наши сервисы будут взаимодействовать через localhost. После того как мы создали объект соединения, необходимо создать канал, по которому сервисы будут обмениваться данными.\n",
    "\n",
    "Итоговый код для создания подключения к серверу брокера будет выглядеть так:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый код для создания подключения к серверу брокера будет выглядеть так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Подключение к серверу на локальном хосте:\n",
    "# connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n",
    "# channel = connection.channel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Если вы хотите подключиться к удалённому серверу, то есть ваш брокер сообщений работает на удалённом компьютере, вместо localhost укажите его IP-адрес."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее объявим в канале соединения очередь сообщений с помощью метода queue_declare(). Назовём очередь \"y_true\" (параметр queue)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Создаём очередь y_true\n",
    "# channel.queue_declare(queue='y_true')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если при выполнении скрипта очередь на брокере ещё не была создана, то она будет создана, иначе мы будем работать с уже имеющейся очередью.\n",
    "\n",
    "Далее наш микросервис должен отправить сообщение в очередь. Для этого используется метод basic_publish(). В нём необходимо указать следующие параметры:\n",
    "\n",
    "- exchange — определяет, в какую очередь отправляется сообщение.  \n",
    "\n",
    "Как мы знаем, в RabbitMQ сообщения не отправляются сразу в очередь, а проходят через точку обмена (exchange). Сейчас нам достаточно знать, что точку обмена по умолчанию можно определить, указав пустую строку.\n",
    "\n",
    "- routing_key — указывает имя очереди.  \n",
    "- body — тело самого сообщения, которое мы хотим поместить в очередь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Публикуем сообщение\n",
    "# channel.basic_publish(exchange='',\n",
    "#                       routing_key='y_true',\n",
    "#                       body=y[random_row])\n",
    "# print('Сообщение с правильным ответом отправлено в очередь')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим ещё одну очередь — features. В неё мы будем отправлять признаки, соответствующие случайно выбранному объекту из данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Создаём очередь features\n",
    "# channel.queue_declare(queue='features')\n",
    "# # Публикуем сообщение\n",
    "# channel.basic_publish(exchange='',\n",
    "#                       routing_key='features',\n",
    "#                       body=json.dumps(list(X[random_row])))\n",
    "# print('Сообщение с вектором признаков отправлено в очередь')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После отправки сообщения мы должны закрыть подключение с помощью метода close()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Закрываем подключение \n",
    "# connection.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При запуске кода возникает ошибка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TypeError: object of type 'numpy.float64' has no len()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка произошла потому, что объект, который мы отправляем в очередь, не был сериализован. Мы уже говорили, что сообщения в RabbitMQ должны быть представлены в формате JSON, поэтому давайте выполним сериализацию."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся стандартной библиотекой json, чтобы сериализовать истинные метки объектов и вектор признаков в этот формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Напомним**, что сериализовать объект можно с помощью метода json.dumps().\n",
    "\n",
    "**Обратите внимание**, что в случае отправки вектора признаков в очередь features у нас не получится сериализовать объект array — его необходимо перевести в список с помощью функции list():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel.basic_publish(exchange='',\n",
    "#                       routing_key='y_true',\n",
    "#                       body=json.dumps(y[random_row]))\n",
    "# channel.basic_publish(exchange='',\n",
    "#                       routing_key='features',\n",
    "#                       body=json.dumps(list(X[random_row])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, в качестве параметра body мы будем передавать байт-строку вектора признака в формате JSON.\n",
    "\n",
    "Для тестирования наших микросервисов, в том числе скрипта features.py, давайте зафиксируем датчик случайных чисел:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый код в файле features.py будет выглядеть так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pika\n",
    "# import numpy as np\n",
    "# import json\n",
    "# from sklearn.datasets import load_diabetes\n",
    "\n",
    "# np.random.seed(42)\n",
    "# # Загружаем датасет о диабете\n",
    "# X, y = load_diabetes(return_X_y=True)\n",
    "# # Формируем случайный индекс строки\n",
    "# random_row = np.random.randint(0, X.shape[0]-1)\n",
    "\n",
    "# # Подключение к серверу на локальном хосте:\n",
    "# connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))\n",
    "# channel = connection.channel()\n",
    "\n",
    "# # Создаём очередь y_true\n",
    "# channel.queue_declare(queue='y_true')\n",
    "# # Создаём очередь features\n",
    "# channel.queue_declare(queue='features')\n",
    "\n",
    "# # Публикуем сообщение в очередь y_true\n",
    "# channel.basic_publish(exchange='',\n",
    "#                       routing_key='y_true',\n",
    "#                       body=json.dumps(y[random_row]))\n",
    "# print('Сообщение с правильным ответом отправлено в очередь')\n",
    "\n",
    "# # Публикуем сообщение в очередь features\n",
    "# channel.basic_publish(exchange='',\n",
    "#                       routing_key='features',\n",
    "#                       body=json.dumps(list(X[random_row])))\n",
    "# print('Сообщение с вектором признаков отправлено в очередь')\n",
    "\n",
    "# # Закрываем подключение\n",
    "# connection.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните скрипт. Если всё прошло успешно, в результате вы должны увидеть на экране следующие сообщения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Сообщение с правильным ответом отправлено в очередь\n",
    "## Сообщение с вектором признаков отправлено в очередь"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте заглянем в RabbitMQ и посмотрим, пришло ли наше сообщение. Для этого в соседнем терминале выполните команду для запуска командной оболочки bash RabbitMQ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker exec -it rabbitmq bash "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате выполнения этой команды вы попадёте внутрь контейнера, где функционирует брокер. Давайте заглянем в очередь y_true и посмотрим, появилось ли в ней сообщение. Для этого внутри контейнера выполните команду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ rabbitmqadmin get queue=y_true count=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная команда позволит вывести десять (вы можете указать любое другое число) последних сообщений в очереди с именем 'y_true' в виде таблицы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.2**\n",
    "\n",
    "В качестве ответа введите истинную метку, которая поступила в очередь 'y_true' (столбец payload)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 302"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, наш ответ попал в очередь 'y_true'. Аналогично вы можете просмотреть содержимое очереди features. Для этого, находясь внутри командной оболочки контейнера, выполните команду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ rabbitmqadmin get queue=features count=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Иногда при отладке сервисов возникает необходимость очистить очередь, так как в неё были отправлены ненужные сообщения. Это можно сделать тремя способами:\n",
    "\n",
    "- Из самого RabbitMQ. Для этого, находясь в командной оболочке контейнера, выполните команду:\n",
    "\n",
    "*$ rabbitmqctl purge_queue y_true*\n",
    "\n",
    "- C помощью pika. Для этого используется метод queue_purge():\n",
    "\n",
    "*channel.queue_purge(queue='имя очереди')*\n",
    "\n",
    "- Можно просто остановить работу контейнера rabbimq и перезапустить его. Так как при запуске контейнера мы указали ключ --rm, все данные, создаваемые контейнером, в том числе очереди, будут удалены по завершении его работы.\n",
    "\n",
    "*$ docker stop rabbitmq*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СЕРВИС II. СЕРВИС ДЛЯ ПРЕДСКАЗАНИЯ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим к написанию второго сервиса — он прочитает признаки из очереди features, сделает предсказание и отправит его в очередь y_pred.\n",
    "\n",
    "Создадим второй файл model.py и добавим в него необходимые импорты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pika\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы уже создавали модель для решения поставленной задачи регрессии. Давайте возьмём наш файл с обученной моделью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('myfile.pkl', 'rb') as pkl_file:\n",
    "#     regressor = pickle.load(pkl_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключимся к серверу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\n",
    "# channel = connection.channel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажем, с какой очередью будем работать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel.queue_declare(queue='Features')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию callback(), определяющую, как работать с полученным сообщением. Эта функция в дальнейшем будет передана для обработки очереди, поэтому у неё должен быть шаблонный синтаксис: стандартные аргументы ch, method, properties и body. В данный момент нас интересует только аргумент body — тело сообщения из очереди. Наша функция-обработчик будет просто выводить на экран сообщение из очереди features (вектор признаков)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def callback(ch, method, properties, body):\n",
    "#     print(f'Получен вектор признаков {body}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На следующем шаге микросервис должен будет извлечь сообщение из очереди features с помощью метода basic_consume(). В аргументах данного метода укажем:\n",
    "\n",
    "- queue — имя очереди;\n",
    "- on_message_callback — функцию-обработчик очереди, которая устанавливает, какие действия должны быть произведены с полученным из очереди сообщением;\n",
    "- auto_ack — параметр, определяющий, использовать ли режим автоматического подтверждения (подробнее об этом — здесь http://www.rabbitmq.com/confirms.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Извлекаем сообщение из очереди features\n",
    "# # on_message_callback показывает, какую функцию вызвать при получении сообщения\n",
    "# channel.basic_consume(\n",
    "#     queue='features',\n",
    "#     on_message_callback=callback,\n",
    "#     auto_ack=True\n",
    "# )\n",
    "# print('...Ожидание сообщений, для выхода нажмите CTRL+C')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы указали все параметры, необходимые для работы микросервиса. Осталось запустить его в режиме ожидания прихода сообщений. Для этого используется метод start_consuming(). Скрипт будет работать до принудительной остановки (CTRL+C) — так мы не пропустим ни одного сообщения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Запускаем режим ожидания прихода сообщений\n",
    "# channel.start_consuming()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно!** Обратите внимание, что после того как сообщение будет получено из очереди и обработано функцией-обработчиком, оно удаляется по правилам очереди.\n",
    "\n",
    "Второй сервис готов. На данный момент код в файле model.py выглядит так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pika\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "\n",
    "# # Читаем файл с сериализованной моделью\n",
    "# with open('myfile.pkl', 'rb') as pkl_file:\n",
    "#     regressor = pickle.load(pkl_file)\n",
    "\n",
    "# # Создаём подключение к серверу на локальном хосте:\n",
    "# connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\n",
    "# channel = connection.channel()\n",
    "\n",
    "# # Объявляем очередь features\n",
    "# channel.queue_declare(queue='features')\n",
    "\n",
    "# # Создаём функцию callback для обработки данных из очереди y_pred\n",
    "# def callback(ch, method, properties, body):\n",
    "#     print(f'Получен вектор признаков {body}')\n",
    "\n",
    "# # Извлекаем сообщение из очереди features\n",
    "# # on_message_callback показывает, какую функцию вызвать при получении сообщения\n",
    "# channel.basic_consume(\n",
    "#     queue='features',\n",
    "#     on_message_callback=callback,\n",
    "#     auto_ack=True\n",
    "# )\n",
    "# print('...Ожидание сообщений, для выхода нажмите CTRL+C')\n",
    "\n",
    "# # Запускаем режим ожидания прихода сообщений\n",
    "# channel.start_consuming()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустите оба скрипта одновременно. Для этого откройте два терминала.\n",
    "\n",
    "- В одном из них перейдите в директорию features/src и запустите скрипт:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd features/src\n",
    "# $ python3 features.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WINDOWS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd features/src\n",
    "# $ python features.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В другом перейдите в директорию model/src и запустите скрипт:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd model/src\n",
    "# $ python3 model.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WINDOWS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd model/src\n",
    "# $ python model.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы увидите, что после отработки features.py в терминале работающего model.py принимаются сериализованные сообщения. На это указывает b' в начале строки.\n",
    "\n",
    "Для завершения работы второго микросервиса не хватает одной маленькой детали, а именно предсказания.\n",
    "\n",
    "После того как мы извлекли вектор признаков из очереди features, нам необходимо сделать для него предсказание моделью regressor и отправить результат в очередь y_pred. Помним о том, что сообщения приходят в бинарном виде, а значит, следует выполнить десериализацию."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.3**\n",
    "\n",
    "В функции callback с помощью функции loads библиотеки json десериализуйте пришедшее сообщение (переменная body) и сделайте предсказание расконсервированной моделью regressor. Полученный ответ модели отправьте в очередь y_pred, предварительно объявив её (объявление очереди происходит вне функции callback).\n",
    "\n",
    "Обратите внимание на три нюанса:\n",
    "\n",
    "- Десериализованный список необходимо будет привести обратно к numpy-массиву размерности , где  — количество признаков (у нас их десять). Пример:\n",
    "\n",
    "shaped_features = np.array(features).reshape(1, -1)\n",
    "- Предсказание модели также находится в numpy-массиве — для получения числа обратитесь по индексу 0: pred[0].\n",
    "- Перед отправкой сообщения в очередь его необходимо сериализовать с помощью функции dumps.\n",
    "\n",
    "После отправки предсказания в очередь y_pred скрипт должен выводить на экран фразу 'Предсказание {prediction} отправлено в очередь y_pred'.\n",
    "\n",
    "Для проверки работы микросервиса очистите очереди features и y_true от имеющихся сообщений (если они там есть).\n",
    "\n",
    "После этого одновременно запустите скрипты features.py и model.py. В результате выполнения скриптов в очереди y_pred должно появиться предсказание модели.\n",
    "\n",
    "В качестве ответа на задание введите это **предсказание**. В файле features.py должен быть зафиксирован датчик случайных чисел (seed=42), чтобы получать воспроизводимые результаты. Полученное число округлите до целого."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлена часть скрипта, которая меняется:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /* … */\n",
    "# # Объявляем очередь features\n",
    "# channel.queue_declare(queue='features')\n",
    "# # Объявляем очередь y_pred\n",
    "# channel.queue_declare(queue='y_pred')\n",
    " \n",
    "# # Создаём функцию callback для обработки данных из очереди y_pred\n",
    "# def callback(ch, method, properties, body):\n",
    "#     print(f'Получен вектор признаков {body}')\n",
    "#     features = json.loads(body)\n",
    "#     pred = regressor.predict(np.array(features).reshape(1, -1))\n",
    "#     channel.basic_publish(exchange='',\n",
    "#                       routing_key='y_pred',\n",
    "#                       body=json.dumps(pred[0]))\n",
    "#     print(f'Предсказание {pred[0]} отправлено в очередь y_pred')\n",
    "# /* … */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: 150 или 151 или 151.0 или 150.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обратите внимание**, что сервис features.py при запуске отправляет одно сообщение в очередь и прекращает свою работу. Сервис model.py, напротив, постоянно принимает сообщения после запуска.\n",
    "\n",
    "**Примечание**. После завершения работы скрипта удалите строку с фиксацией датчика случайных чисел — больше она нам не понадобится."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СЕРВИС III. САМОСТОЯТЕЛЬНАЯ РАБОТА"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последний микросервис, который нам осталось реализовать, должен извлекать сообщения из очередей y_true и y_pred и выводить их на экран."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.4**\n",
    "\n",
    "Напишите сервис metric.py, который будет читать очереди y_true и y_pred с истинными ответами и предсказаниями. Сообщения из очередей должны выводиться на экран в следующем формате:\n",
    "\n",
    "\"Из очереди {имя очереди} получено значение {сообщение}\"\n",
    "Примечание. Узнать, из какой очереди получено сообщение, можно с помощью атрибута method.routing_key, где method — второй аргумент функции callback()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pika\n",
    "import json\n",
    " \n",
    "# Создаём подключение к серверу на локальном хосте\n",
    "connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\n",
    "channel = connection.___3___\n",
    " \n",
    "# Объявляем очередь y_true\n",
    "channel.queue_declare(queue='channel')\n",
    "# Объявляем очередь y_pred\n",
    "channel.queue_declare(queue='y_pred')\n",
    " \n",
    "# Создаём функцию callback для обработки данных из очереди\n",
    "def callback(ch, method, properties, body):\n",
    "    print(f'Из очереди {method.routing_key} получено значение {json.loads(body)}')\n",
    " \n",
    "# Извлекаем сообщение из очереди y_true\n",
    "channel.basic_consume(\n",
    "    queue='y_true',\n",
    "    on_message_callback=callback,\n",
    "    auto_ack=True\n",
    ")\n",
    "# Извлекаем сообщение из очереди y_pred\n",
    "channel.basic_consume(\n",
    "    queue='y_pred',\n",
    "    on_message_callback=callback,\n",
    "    auto_ack=True\n",
    ")\n",
    " \n",
    "# Запускаем режим ожидания прихода сообщений\n",
    "print('...Ожидание сообщений, для выхода нажмите CTRL+C')\n",
    "channel.start_consuming()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После запуска сервис metric.py уйдёт в режим ожидания поступления сообщений в прослушиваемые очереди. Если в очереди уже были данные, он извлечёт их оттуда и выведет на экран. После этого очереди будут очищены до ожидания новых данных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте обмен данных в вашем микросервисном приложении, запустив три сервиса одновременно. Для этого откройте три терминала.\n",
    "\n",
    "- В первом перейдите в директорию features/src и запустите скрипт features.py:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd features/src\n",
    "# $ python3 features.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WINDOWS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd features/src\n",
    "# $ python features.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во втором перейдите в директорию model/src и запустите скрипт model.py:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd model/src\n",
    "# $ python3 model.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WINDOWS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd model/src\n",
    "# $ python model.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В третьем перейдите в директорию model/src и запустите скрипт metric.py:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UNIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd metric/src\n",
    "# $ python3 metric.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WINDOWS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ cd metric/src\n",
    "# $ python metric.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обратите внимание**, что сервисы model.py и metric.py работают в фоновом режиме, ожидая поступающих в очереди сообщений, а сервис features.py прекращает работу после запуска. Если вы хотите несколько раз протестировать работу микросервисного приложения, несколько раз запустите скрипт features.py.\n",
    "\n",
    "В результате запуска сервиса features в терминале, соответствующем сервису model, должно появляться сообщение, что получен вектор признаков из очереди features и отправлено предсказание модели в очередь y_pred, а в терминале, соответствующем сервису metric, появятся сообщения из очередей y_pred и y_true."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**РЕЗЮМИРУЕМ**\n",
    "\n",
    "В итоге мы получили три микросервиса, которые обмениваются между собой данными через очередь в брокере сообщений RabbitMQ.\n",
    "\n",
    "- Сервис features имитирует клиентскую часть ML-приложения, которая отправляет данные об объекте на сервис, на котором функционирует модель.\n",
    "- Сервис model выполняет функцию обработки данных моделью и отправки результата.\n",
    "- Сервис metric имитирует подсистему логирования работы нашей модели. С её помощью мы можем фиксировать результаты работы модели и сравнивать их с истинными показателями: например, мы можем определять абсолютную ошибку между истиной и предсказанием, следить за изменением этой ошибки во времени, усреднять её и так далее.\n",
    "  \n",
    "Конечно, полученные микросервисы «игрушечные» — в реальных условиях всё устроено несколько сложнее: например, микросервис с клиентской частью приложения должен содержать хотя бы минимальный графический интерфейс, на микросервисе с моделью должна быть предусмотрена предобработка данных перед подачей в модель (она может быть зашита в виде pipeline в pickle-файле с моделью) и ещё много нюансов.\n",
    "\n",
    "Самое главное — в настоящих микросервисных приложениях всегда должна быть предусмотрена защита от возникающих при работе сервисов ошибок, ведь если, например, из-за неверного формата переданных данных перестанет работать скрипт сервиса с моделью, приложение потеряет свою основную функциональность.\n",
    "\n",
    "Однако вручную отслеживать работу всех микросервисов — неблагодарное дело. Для этого должна быть предусмотрена система автоматического логирования и мониторинга работы сервисов. В следующем юните мы рассмотрим инструменты, которые можно использовать для таких целей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЕСЛИ У ВАС ОСТАЛИСЬ ВОПРОСЫ ПО РАБОТЕ С RABBITMQ**\n",
    "\n",
    "- Официальное руководство от создателей RabbitMQ (англ.) https://www.rabbitmq.com/tutorials/tutorial-one-python.html.\n",
    "- То же руководство на русском языке (рус.) https://habr.com/ru/post/149694/.\n",
    "- Официальная документация библиотеки pika (англ.) https://pika.readthedocs.io/en/stable/intro.html."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Логирование, мониторинг, Service Discovery"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разных компаниях логирование, мониторинг и обнаружение сервисов (service discovery) устроены по-разному и зависят от решаемых бизнес-задач. Некоторые компании и вовсе используют самописные решения. В этом юните мы обсудим лишь наиболее популярные сейчас сервисы для логирования и мониторинга сервисов. В этой сфере часто появляются новинки — старайтесь их отслеживать.\n",
    "\n",
    "Наша задача — расширить своё понимание микросервисной архитектуры и выяснить, как микросервисы работают в реальных крупных компаниях.\n",
    "\n",
    "Конечно, в обязанности дата-сайентиста не входит настройка логирования и мониторинга работы всей системы — это задачи других специалистов, однако общее понимание того, как это работает, должно быть у каждого, кто участвует в разработке приложения или системы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\pic-2.png\" alt=\"drawing\" width=\"700\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мониторинг микросервисов** — задача непростая: в режиме реального времени нужно отслеживать состояние как отдельных компонентов, так и системы в целом. Задача усложняется, если нужно следить не только за техническими показателями, но и за метриками, значимыми для бизнеса.\n",
    "\n",
    "Если посмотреть на микросервисную архитектуру со стороны, можно увидеть, что каждый микросервис, по сути, живёт своей жизнью, и зачастую они поддерживаются разными командами. Поэтому при организации их взаимодействия что-то обязательно идёт не так.\n",
    "\n",
    "Конечно, в хорошо продуманной микросервисной архитектуре каждый сервис в случае ошибки отправит вызывающему сервису подробности произошедшего, а тот, в свою очередь, завернёт это в ответ с указанием причины. Однако, чтобы всегда быть в курсе событий, нам необходимо постоянно отслеживать все цепочки взаимодействия.\n",
    "\n",
    "В идеале каждый сервис хранит логи сообщений независимо от других, а затем логи всех сервисов собираются специальным агрегатором."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СТЕК ELK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пожалуй, самый известный вариант среди инструментов логирования — стек ELK: Elasticsearch, Logstash и Kibana.\n",
    "\n",
    "- Elasticsearch https://www.elastic.co/elasticsearch/ — это не только база данных NoSQL, но и полноценный движок полнотекстового поиска и аналитики. Написан на языке Java.\n",
    "- Logstash https://www.elastic.co/logstash — это инструмент для сбора данных с открытым исходным кодом и возможностью конвейерной обработки данных в реальном времени. Logstash позволяет динамически идентифицировать данные из различных источников и нормализовать их с помощью выбранных фильтров.\n",
    "- Kibana https://www.elastic.co/kibana — это панель визуализации данных. Данные представляются в виде различных диаграмм.\n",
    "- \n",
    "Все указанные инструменты работают в связке:\n",
    "\n",
    "- Logstash отвечает за агрегацию логов для каждого микросервиса и поставляет входящий поток данных в Elasticsearch для хранения, классификации и поиска.\n",
    "- Kibana получает доступ к данным Elasticsearch для их визуализации в различных форматах, например в виде дашборда."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_4_1.png\" alt=\"drawing\" width=\"700\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Помимо стека ELK, существует связка Prometheus и Grafana.\n",
    "\n",
    "Prometheus выступает в качестве системы агрегации логов и базы данных временных рядов для хранения метрик, а Grafana помогает построить дашборд для визуализации данных."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SERVICE DISCOVERY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что у нас есть десятки тысяч сервисов, распределённых по тысячам серверов. Как сервисы будут находить друг друга? Как один сервис будет определять состояние другого? Конечно, хотелось бы, чтобы это происходило автоматически, например с помощью журнала, в который сервисы вносили бы своё состояние и адреса.\n",
    "\n",
    "Для решения этой задачи используются протоколы обнаружения сервисов (Service Discovery). Их дополняет ряд инструментов, например:\n",
    "\n",
    "- Consul http://www.consul.io/,\n",
    "- etcd https://etcd.io/,\n",
    "- ZooKeeper http://zookeeper.apache.org/.\n",
    "  \n",
    "Consul от компании HashiCorp — один из самых популярных сервисов в современной разработке. Он позволяет не только обнаруживать, но и конфигурировать сервисы."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логирование — полезный инструмент не только в разработке микросервисов.\n",
    "\n",
    "Существует готовая библиотека на Python для логирования работы сервисов — logging. Использование этой библиотеки уже давно стало правилом хорошего тона при любой разработке.\n",
    "\n",
    "Мы рекомендуем вам ознакомиться с пошаговыми руководствами по работе с библиотекой logging:\n",
    "\n",
    "- Инструкция на Хабре (рус.) https://habr.com/ru/post/144566/.\n",
    "- Официальная документация (англ.) https://docs.python.org/3/howto/logging.html."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вы знаете, какими инструментами можно пользоваться для мониторинга работы микросервисов, чтобы обеспечить их надёжность.\n",
    "\n",
    "Нам осталось рассмотреть последнюю тему по работе с сервисами — оркестрация контейнеров при микросервисной разработке. Давайте перейдём к ней."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Оркестрация. Docker Compose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда у нас есть микросервисное приложение, наша следующая цель — поместить каждый сервис в собственный docker-контейнер. Для этого нам нужно прописать последовательность сборки и запуска этих контейнеров, а также указать, как они взаимодействуют друг с другом.\n",
    "\n",
    "Процесс управления несколькими контейнерами (микросервисами) называется **оркестрацией**, а инструменты, с помощью которых можно организовать этот процесс, называются **оркестраторами** или **системами оркестрации**.\n",
    "\n",
    "Термин не зря происходит из музыки — такие системы можно сравнить с дирижёрами оркестра: они организуют расположение и координируют взаимосвязь инструментов в одном проекте, распределяют задачи между ними и контролируют их выполнение.\n",
    "\n",
    "Давайте научимся пользоваться такими системами."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOCKER COMPOSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При разработке приложений на основе **микросервисной архитектуры** появляется множество сервисов, каждый из которых живёт в отдельном контейнере. Нам небходимо автоматизировать или максимально облегчить процессы сборки, запуска и остановки таких контейнеров.\n",
    "\n",
    "К счастью, для решения этой задачи уже придумана масса инструментов.\n",
    "\n",
    "Один из них — Docker Compose https://docs.docker.com/compose/, входящий в состав Docker. Его основная задача — помогать разворачивать проекты, состоящие из нескольких контейнеров, и эффективно управлять ими.\n",
    "\n",
    "Проще говоря, Docker Compose нужен, когда есть несколько контейнеров, которые обмениваются между собой данными. Это как раз пример нашей микросервисной архитектуры."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_5_2.png\" alt=\"drawing\" width=\"400\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с Compose предполагает несколько этапов:\n",
    "\n",
    "1. Предварительная подготовка: создание Dockerfile для каждого сервиса, чтобы их можно было воспроизвести где угодно.\n",
    "2. Создание описания всех сервисов, которые требуется запускать вместе, в специальном файле docker-compose.yml.\n",
    "3. Сборка и запуск проекта через docker-compose, чтобы приложение развернулось автоматически.\n",
    "\n",
    "Давайте посмотрим, как реализуется каждый из этих этапов на практике.\n",
    "\n",
    "В этой части мы будем практиковаться управлять сервисами, которые писали в практике по RabbitMQ (скрипты features.py, metric.py, model.py) https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/28dabdc1a504416b802beca24189575d."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРЕДВАРИТЕЛЬНАЯ ПОДГОТОВКА"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Первый шаг** — подготовить наши микросервисы для контейнеризации, создать файлы с зависимостями, а затем создать Dockerfile для каждого сервиса.\n",
    "\n",
    "Начнём с небольшой модернизации файлов.\n",
    "\n",
    "- Во-первых, теперь взаимодействие сервисов на базе RabbitMQ будет происходить не через localhost, а средствами docker-compose, поэтому необходимо задать другую точку взаимодействия. Подробнее о том, почему так происходит, мы поговорим ниже, когда будем реализовывать сам compose-файл.  \n",
    "Пока что договоримся, что адрес, через который сервисы будут подключаться к очереди, будет называться rabbitmq. Это означает, что во всех трёх сервисах при инициализации параметров соединения в ConnectionParameters нам необходимо будет поменять 'localhost' на 'rabbitmq'.\n",
    "\n",
    "- Во-вторых, мы хотим, чтобы все наши сервисы работали в фоновом режиме.  \n",
    "Например, сервисы model и metric постоянно мониторят поступление сообщений в очереди, а вот сервис features завершает свою работу сразу после отправки сообщения в очередь. Поэтому давайте модернизируем features так, чтобы он в бесконечном цикле выбирал случайные объекты из выборки и отправлял вектор признаков в соответствующую очередь.\n",
    "\n",
    "- В-третьих, давайте обернём код каждого сервиса в конструкцию try-except, чтобы в случае, если при исполнении скрипта сервиса произошла ошибка, он не остановил свою работу, а вывел эту ошибку на экран.\n",
    "\n",
    "Итоговый код будет иметь примерно следующий вид:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл ./features/src/features.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pika\n",
    "# import numpy as np\n",
    "# import json\n",
    "# from sklearn.datasets import load_diabetes\n",
    " \n",
    "# # Создаём бесконечный цикл для отправки сообщений в очередь\n",
    "# while True:\n",
    "#     try:\n",
    "#         # Загружаем датасет о диабете\n",
    "#         X, y = load_diabetes(return_X_y=True)\n",
    "#         # Формируем случайный индекс строки\n",
    "#         random_row = np.random.randint(0, X.shape[0]-1)\n",
    " \n",
    "#         # Создаём подключение по адресу rabbitmq:\n",
    "#         connection = pika.BlockingConnection(pika.ConnectionParameters('rabbitmq'))\n",
    "#         channel = connection.channel()\n",
    " \n",
    "#         # Создаём очередь y_true\n",
    "#         channel.queue_declare(queue='y_true')\n",
    "#         # Создаём очередь features\n",
    "#         channel.queue_declare(queue='features')\n",
    " \n",
    "#         # Публикуем сообщение в очередь y_true\n",
    "#         channel.basic_publish(exchange='',\n",
    "#                             routing_key='y_true',\n",
    "#                             body=json.dumps(y[random_row]))\n",
    "#         print('Сообщение с правильным ответом отправлено в очередь')\n",
    " \n",
    "#         # Публикуем сообщение в очередь features\n",
    "#         channel.basic_publish(exchange='',\n",
    "#                             routing_key='features',\n",
    "#                             body=json.dumps(list(X[random_row])))\n",
    "#         print('Сообщение с вектором признаков отправлено в очередь')\n",
    " \n",
    "#         # Закрываем подключение\n",
    "#         connection.close()\n",
    "#     except:\n",
    "#         print('Не удалось подключиться к очереди')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл ./model/src/model.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pika\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# import json\n",
    " \n",
    "# # Читаем файл с сериализованной моделью\n",
    "# with open('myfile.pkl', 'rb') as pkl_file:\n",
    "#     regressor = pickle.load(pkl_file)\n",
    " \n",
    "# try:\n",
    "#     # Создаём подключение по адресу rabbitmq:\n",
    "#     connection = pika.BlockingConnection(pika.ConnectionParameters(host='rabbitmq'))\n",
    "#     channel = connection.channel()\n",
    " \n",
    "#     # Объявляем очередь features\n",
    "#     channel.queue_declare(queue='features')\n",
    "#     # Объявляем очередь y_pred\n",
    "#     channel.queue_declare(queue='y_pred')\n",
    " \n",
    "#     # Создаём функцию callback для обработки данных из очереди\n",
    "#     def callback(ch, method, properties, body):\n",
    "#         print(f'Получен вектор признаков {body}')\n",
    "#         features = json.loads(body)\n",
    "#         pred = regressor.predict(np.array(features).reshape(1, -1))\n",
    "#         channel.basic_publish(exchange='',\n",
    "#                         routing_key='y_pred',\n",
    "#                         body=json.dumps(pred[0]))\n",
    "#         print(f'Предсказание {pred[0]} отправлено в очередь y_pred')\n",
    " \n",
    "#     # Извлекаем сообщение из очереди features\n",
    "#     # on_message_callback показывает, какую функцию вызвать при получении сообщения\n",
    "#     channel.basic_consume(\n",
    "#         queue='features',\n",
    "#         on_message_callback=callback,\n",
    "#         auto_ack=True\n",
    "#     )\n",
    "#     print('...Ожидание сообщений, для выхода нажмите CTRL+C')\n",
    " \n",
    "#     # Запускаем режим ожидания прихода сообщений\n",
    "#     channel.start_consuming()\n",
    "# except:\n",
    "#     print('Не удалось подключиться к очереди')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл ./metric/src/metric.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pika\n",
    "# import json\n",
    " \n",
    "# try:\n",
    "#     # Создаём подключение к серверу на локальном хосте\n",
    "#     connection = pika.BlockingConnection(pika.ConnectionParameters(host='rabbitmq'))\n",
    "#     channel = connection.channel()\n",
    "   \n",
    "#     # Объявляем очередь y_true\n",
    "#     channel.queue_declare(queue='y_true')\n",
    "#     # Объявляем очередь y_pred\n",
    "#     channel.queue_declare(queue='y_pred')\n",
    " \n",
    "#     # Создаём функцию callback для обработки данных из очереди\n",
    "#     def callback(ch, method, properties, body):\n",
    "#         print(f'Из очереди {method.routing_key} получено значение {json.loads(body)}')\n",
    " \n",
    "#     # Извлекаем сообщение из очереди y_true\n",
    "#     channel.basic_consume(\n",
    "#         queue='y_true',\n",
    "#         on_message_callback=callback,\n",
    "#         auto_ack=True\n",
    "#     )\n",
    "#     # Извлекаем сообщение из очереди y_pred\n",
    "#     channel.basic_consume(\n",
    "#         queue='y_pred',\n",
    "#         on_message_callback=callback,\n",
    "#         auto_ack=True\n",
    "#     )\n",
    " \n",
    "#     # Запускаем режим ожидания прихода сообщений\n",
    "#     print('...Ожидание сообщений, для выхода нажмите CTRL+C')\n",
    "#     channel.start_consuming()\n",
    "# except:\n",
    "#     print('Не удалось подключиться к очереди')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее нам необходимо подготовить модернизированные сервисы к контейнеризации. Для этого внутри каждой директории микросервиса создадим Dockerfile и файлы с зависимостями — requirements.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# microservice_architecture\n",
    "#     └─features\n",
    "#         └─src\n",
    "#             └─features.py\n",
    "#         └─Dockerfile\n",
    "#         └─requirements.txt\n",
    "#     └─model\n",
    "#         └─src\n",
    "#             └─model.py\n",
    "#             └─myfile.pkl\n",
    "#         └─Dockerfile\n",
    "#         └─requirements.txt\n",
    "#     └─metric\n",
    "#         └─src\n",
    "#             └─metric.py\n",
    "#         └─Dockerfile\n",
    "#         └─requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с файлов с зависимостями."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже представлены примеры файлов requirements.txt с зависимостями для каждого сервиса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл ./features/requirements.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy == 1.23.4;\n",
    "# scikit-learn==1.1.3;\n",
    "# pika==1.1.0;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл ./model/requirements.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy == 1.23.4;\n",
    "# scikit-learn==1.1.3;\n",
    "# pika==1.1.0;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл ./metric/requirements.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pika==1.1.0;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- pika==1.1.0; -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание.** Строго говоря, устанавливать библиотеку numpy для сервисов features и model было необязательно, так как она поставляется вместе с библиотекой scikit-learn.\n",
    "\n",
    "**Следующий шаг** — создать Dockerfile. Мы неслучайно создали типизированные папки для каждого микросервиса — благодаря этому будет удобно составлять шаблонный Dockerfile."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ШАГИ СБОРКИ ОБРАЗА КОНТЕЙНЕРА:**\n",
    "\n",
    "1. Подключить базовый образ. Мы будем использовать образ Python версии 3.9.\n",
    "2. Задать рабочую директорию контейнера. Назовём её /app.\n",
    "3. Скопировать содержимое папки src в рабочую директорию контейнера.\n",
    "4. Скопировать файл с зависимостями в рабочую директорию контейнера.\n",
    "5. Установить все необходимые зависимости.\n",
    "6. Запустить скрипт для работы сервиса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.4**\n",
    "\n",
    "На основе описанных выше шагов заполните пропущенные директивы в Dockerfile для сервиса features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM python:3.9\n",
    "# WORKDIR /usr/src/app\n",
    "# COPY ./src ./ \n",
    "# COPY ./requirements.txt ./\n",
    "# RUN pip install --no-cache-dir -r requirements.txt\n",
    "# CMD [ \"python\", \"./features.py\" ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Файлы Dockerfile для сервисов model и metric будут выглядеть аналогично, за тем исключением, что в директиве CMD указываются соответствующие скрипты (model.py и metric.py). Составьте инструкции по сборке образа для этих двух сервисов самостоятельно.\n",
    "\n",
    "Вы сами можете протестировать свои Dockerfile, собрав их образы с помощью команды docker build. Однако это не обязательно — мы укажем процедуру сборки в docker-compose.\n",
    "\n",
    "Обратите внимание, что при вызове команды для создания образа (docker_build) из корневой директории проекта (у нас она называется microservice_architecture) необходимо указать путь до папки, где находится Dockerfile. Например, команда для сборки образа сервиса features будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker build -t feature_image ./features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Важно!** Запускать сами контейнеры пока не нужно, так как мы ещё не прописали логику взаимодействия между сервисами — за это как раз и будет отвечать docker-compose.\n",
    "\n",
    "Предварительная подготовка завершена — инструкции по сборке образов контейнеров готовы. Переходим к описанию регламентов взаимодействия наших сервисов — иначе говоря, давайте знакомиться с оркестрацией."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СОЗДАЁМ ОПИСАНИЕ ВСЕХ СЕРВИСОВ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание.** Перед тем как приступить к изучению Docker Compose, убедитесь, что он установлен на вашем компьютере, введя в терминале или командной строке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker-compose version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если Docker Compose не установлен, сделайте это с помощью официального руководства https://docs.docker.com/compose/install/."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее мы запускали очередь RabbitMQ и ещё три сервиса на Python. Как вы помните, мы рекомендовали использовать docker для запуска очереди с помощью команды:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:3-management"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако теперь, помимо образа rabbitmq:3-management, который можно воспринимать как отдельный микросервис для управления очередями, у нас есть ещё три почти контейнеризированных сервиса. Запускать каждый сервис отдельной командой и открывать десятки терминалов, в которых выводятся сообщения от контейнера, крайне неудобно. Поэтому хотелось бы написать некоторую инструкцию по сборке и запуску всех контейнеров с возможностью задавать последовательность. Такие инструкции прописываются в файлах docker-compose.yml. Давайте рассмотрим синтаксис такого файла.\n",
    "\n",
    "Создайте в корневой директории проекта (у нас она называется microservice_architecture) файл docker-compose.yml с помощью любого текстового редактора и напишите в нём:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл ./docker-compose.yml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version: '3.7'\n",
    "# services:\n",
    "#   rabbitmq:\n",
    "#     image: rabbitmq:3-management\n",
    "#     container_name: rabbitmq\n",
    "#     hostname: rabbitmq\n",
    "#     restart: always\n",
    "#     ports:\n",
    "#        - 5672:5672\n",
    "#        - 15672:15672"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните содержимое файла docker-compose.yml с docker-командой для запуска RabbitMQ. Много сходств, не так ли?\n",
    "\n",
    "Поясним, что мы написали:\n",
    "\n",
    "- version: '3.7' — версия docker-compose;\n",
    "- services — начало блока, в котором будут описаны все сервисы;\n",
    "- rabbitmq — имя сервиса (контейнера) rabbitmq;\n",
    "- image — образ, на основе которого будет запускаться контейнер;\n",
    "- restart: always — в случае падения контейнер должен перезапускаться автоматически;\n",
    "- hostname — имя хоста;\n",
    "\n",
    "Почему нельзя указать в качестве хоста localhost?  \n",
    "Дело в том, что при работе с docker-compose создаётся собственная сеть, и, чтобы один сервис мог обратиться к другому, необходимо использовать имя хоста, а не стандартный localhost (хотя это тоже возможно — см. официальную документацию https://docs.docker.com/compose/networking/).\n",
    "\n",
    "- ports — TCP-порты, которые использует контейнер."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Можно задать и другие условия перезапуска:\n",
    "\n",
    "- restart: \"no\" — контейнер не будет перезапускаться ни при каких обстоятельствах (опция по умолчанию);\n",
    "\n",
    "- restart: on-failure — перезапуск контейнера, если предыдущий запуск завершился ошибкой.\n",
    "\n",
    "**Обратите внимание**. В docker-compose.yml важны отступы. Для того чтобы обозначить вложенность настроек друг в друга, используются два или более пробелов. Например, в видео выше эксперт использует четыре и даже шесть пробелов для наглядности."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_5_3.png\" alt=\"drawing\" width=\"300\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Следующий шаг** — прописать сборку и запуск наших «самописных» сервисов.\n",
    "\n",
    "Разберём структуру описания compose-инструкций на примере сервиса features. Снова откроем файл docker-compose и добавим в него описание features (ещё раз обратите внимание на отступы)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл ./docker-compose.yml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version: '3.7'\n",
    "# version: '3.7'\n",
    "# services:\n",
    "#   rabbitmq:\n",
    "#     image: rabbitmq:3-management\n",
    "#     container_name: rabbitmq\n",
    "#     hostname: rabbitmq\n",
    "#     restart: always\n",
    "#     ports:\n",
    "#        - 5672:5672\n",
    "#        - 15672:15672\n",
    "#   features:\n",
    "#     build:\n",
    "#       context: ./features\n",
    "#     restart: always\n",
    "#     depends_on:\n",
    "#       - rabbitmq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы дописали следующее:\n",
    "\n",
    "- Директива build указывает, что образ требуется собрать перед запуском контейнера. При этом context указывает путь на размещение Dockerfile относительно файла docker-compose.yml.\n",
    "- Директива depends_on указывает на зависимость от других сервисов и означает, что compose не будет запускать сервис features без запущенного rabbitmq.\n",
    "\n",
    "Настройка оставшихся сервисов производится аналогично."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЗАДАНИЕ 5.5 (САМОПРОВЕРКА)**\n",
    "\n",
    "Самостоятельно добавьте в файл docker-compose.yml описание работы двух оставшихся двух сервисов — model и metric.\n",
    "\n",
    "Перед тем как перейти к составлению инструкций, поразмышляйте над следующими вопросами:\n",
    "\n",
    "- Должны ли docker-образы для данных сервисов собираться заранее? Если да, то где лежат их Dockerfile?\n",
    "- Когда должен перезапускаться каждый из сервисов?\n",
    "- Наконец, самое главное: какие сервисы должны быть запущены предварительно? От каких сервисов зависит рассматриваемый сервис?\n",
    "\n",
    "После того как вы самостоятельно составите файл docker-compose.yml, загляните в ответ.\n",
    "\n",
    "**Ответ**\n",
    "Сервис model:\n",
    "\n",
    "- Необходима предварительная сборка образа на основе Dockerfile, который лежит в директории ./models.\n",
    "- Сервис должен автоматически перезапускаться при возникновении в нём ошибок.\n",
    "- Сервис не должен запускаться раньше, чем запускается сервисы rabbitmq и features.\n",
    "\n",
    "Сервис metric:\n",
    "\n",
    "- Необходима предварительная сборка образа на основе Dockerfile, который лежит в директории ./metric.\n",
    "- Сервис должен автоматически перезапускаться при возникновении в нём ошибок.\n",
    "- Сервис не должен запускаться раньше, чем запускается сервисы rabbitmq, features и model.\n",
    "\n",
    "Файл docker-compose.yml будет иметь следующий вид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version: '3.7'\n",
    "# services:\n",
    "#   rabbitmq:\n",
    "#     image: rabbitmq:3-management\n",
    "#     container_name: rabbitmq\n",
    "#     hostname: rabbitmq\n",
    "#     restart: always\n",
    "#     ports:\n",
    "#        - 5672:5672\n",
    "#        - 15672:15672\n",
    "#   features:\n",
    "#     build:\n",
    "#       context: ./features\n",
    "#     restart: always\n",
    "#     depends_on:\n",
    "#       - rabbitmq\n",
    "#   model:\n",
    "#     build:\n",
    "#       context: ./model\n",
    "#     restart: always\n",
    "#     depends_on:\n",
    "#       - rabbitmq\n",
    "#       - features\n",
    "#   metric:\n",
    "#     build:\n",
    "#       context: ./metric\n",
    "#     restart: always\n",
    "#     depends_on:\n",
    "#       - rabbitmq\n",
    "#       - features\n",
    "#       - model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### СБОРКА И ЗАПУСК ПРИЛОЖЕНИЯ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обратите внимание**, что перед запуском приложения необходимо остановить все запущенные ранее docker-контейнеры, в частности контейнер с rabbitmq, который мы запускали в прошлом юните. Сделайте это самостоятельно.\n",
    "\n",
    "После того как в docker-compose.yml внесены все необходимые инструкции, проект необходимо собрать. Этот шаг напоминает использование команды docker build, но соответствующая команда имеет отношение к нескольким сервисам. Перейдите в терминале в корневую директорию вашего проекта и запустите в нём команду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker-compose build"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого запустится сборка всех необходимых образов — дождитесь её завершения.\n",
    "\n",
    "Когда всё будет готово, останется лишь запустить проект. Этот шаг аналогичен шагу, на котором при работе с отдельными контейнерами выполняется команда docker run.\n",
    "\n",
    "Для запуска проекта используется команда up. Однако если просто запустить её, терминал будет бесконечно обновляться, так как в него будут постоянно выводиться логи сервисов. Чтобы отвязать логи от терминала и запустить сервисы в фоновом режиме, воспользуемся ключом -d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker-compose up -d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё сделано верно, после запуска команды вы увидите примерно следующее сообщение:\n",
    "\n",
    "<img src=\"data\\DSPROD_md3_5_4.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оно говорит, что все сервисы запущены. Вы можете удостовериться в этом и вывести список активных контейнеров, воспользовавшись командой docker ps:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_5_5.png\" alt=\"drawing\" width=\"1000\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичная команда есть и в docker-compose — она выводит информацию о запущенных сервисах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker-compose ps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data\\DSPROD_md3_5_6.png\" alt=\"drawing\" width=\"900\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примечание**. Содержимое таблицы, получаемой в результате выполнения команды docker ps, мы обсуждали в предыдущем модуле https://lms.skillfactory.ru/courses/course-v1:SkillFactory+DSPR-2.0+14JULY2021/jump_to_id/bf9210f7903d48cbad2148cccfa00be2#dockerps, когда изучали docker-команды."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ЕЩЁ НЕСКОЛЬКО ПОЛЕЗНЫХ КОМАНД"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C помощью команды docker logs <ID контейнера> можно посмотреть логи контейнера. Вместо ID необходимо подставить идентификатор запущенного контейнера. Например, следующая команда запускает контейнер, соответствующий сервису metric (ваш ID контейнера может отличаться):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker logs faef4f322b52"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогичная команда есть в docker-compose, только вместо ID контейнера нужно указать имя сервиса. Например, следующая команда позволяет отследить логи сервиса metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker-compose logs -f metric"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы остановить запущенные сервисы, следует воспользоваться командой down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker-compose down"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда требуется пересобирать образы, например при изменении кода. Для этого удобно пользоваться ключом --build. В таком случае команда запуска будет выглядеть следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ docker-compose up -d --build"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ЗАДАНИЕ 5.6 (САМОПРОВЕРКА)**\n",
    "\n",
    "В функцию callback в файле metric.py добавьте код, который будет записывать логи, содержащие информацию о том, из какой очереди было получено сообщение, в файл labels_log.txt. Пример формата логов:\n",
    "\n",
    "*'Из очереди <имя очереди> получено значение <тело сообщения>'*\n",
    "\n",
    "Файл с логами разместите в директории logs рядом с вашим compose-файлом. В итоге у вас должна получиться примерно следующая структура директории:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# microservice_architecture\n",
    "#     └─features\n",
    "#         └─src\n",
    "#             └─features.py\n",
    "#         └─Dockerfile\n",
    "#         └─requirements.txt\n",
    "#     └─model\n",
    "#         └─src\n",
    "#             └─model.py\n",
    "#             └─myfile.pkl\n",
    "#         └─Dockerfile\n",
    "#         └─requirements.txt\n",
    "#     └─metric\n",
    "#         └─src\n",
    "#             └─metric.py\n",
    "#         └─Dockerfile\n",
    "#         └─requirements.txt\n",
    "#     └─logs\n",
    "#         └─labels_log.txt\n",
    "#     └─docker_compose.yml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы файл был доступен из локальной файловой системы, в compose-файле в разделе сервиса metric необходимо прописать нужную папку с помощью директивы volumes, которая является аналогом -v в команде docker run. Чтобы связать локальную директорию и директорию контейнера, используется следующий формат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volumes:\n",
    "#       - ./logs/:/usr/src/app/logs/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы захотите поближе познакомиться с директивой volumes, посмотрите пример её использования в официальной документации https://docs.docker.com/compose/compose-file/compose-file-v3/ по синтаксису compose-файла.\n",
    "\n",
    "О том, как организовать запись в файл, вы можете почитать здесь https://pythonru.com/osnovy/fajly-v-python-vvod-vyvod."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ**  \n",
    "\n",
    "**Файл ./metric/src/metric.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# …\n",
    "\n",
    "# def callback(ch, method, properties, body):\n",
    "#     answer_string = f'Из очереди {method.routing_key} получено значение {json.loads(body)}'\n",
    "#     with open('./logs/labels_log.txt', 'a') as log:\n",
    "#         log.write(answer_string +'\\n')\n",
    "\n",
    "# …"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Файл docker-compose.yml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /*Описание сервисов*/\n",
    "# …\n",
    "#   metric:\n",
    "#     build:\n",
    "#       context: ./metric\n",
    "#     restart: always\n",
    "#     depends_on:\n",
    "#       - rabbitmq\n",
    "#       - features\n",
    "#       - model\n",
    "#     volumes:\n",
    "#       - ./logs/:/usr/src/app/logs/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для завершения темы оркестрации нам осталось лишь упомянуть инструменты оркестрации, которыми пользуются профессиональные DevOps-специалисты, занимающиеся автоматизацией развёртывания приложений."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы подробно разобрали Docker Compose — достаточно мощный и эффективный инструмент для запуска нескольких сервисов на одной машине. Однако он имеет пусть один, но весьма существенный недостаток: по умолчанию в нём **нет средств для горизонтального масштабирования**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таких случаях больше подойдёт Docker Swarm, созданный специально для развёртывания контейнеров на кластере. По сути, он преобразует набор хостов Docker в один последовательный виртуальный хост под названием Swarm. Docker Swarm обеспечивает высокую производительность работы, равномерно распределяя нагрузку внутри кластера. \n",
    "\n",
    "<img src=\"data\\DSPROD_md3_5_7.png\" alt=\"drawing\" width=\"200\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако наиболее популярным средством для оркестрации контейнеров в кластере является Kubernetes. В литературе можно встретить акроним K8s.\n",
    "\n",
    "Kubernetes — инструмент с открытым исходным кодом. Его начали разрабатывать в Google, а сейчас сервис поддерживается многими компаниями, среди которых Microsoft, RedHat, IBM и, конечно, сам Docker.\n",
    "\n",
    "<img src=\"data\\DSPROD_md3_5_8.png\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes упрощает управление развёртыванием, сетевой маршрутизацией, расходом ресурсов, балансировкой нагрузки и отказоустойчивостью запускаемых приложений.\n",
    "\n",
    "На этом мы завершаем знакомство с оркестрацией контейнеров. Итак, в этом юните мы:\n",
    "\n",
    "- познакомились с инструментом оркестрации контейнеров Docker Compose;\n",
    "- посмотрели, как выглядит простейший файл docker-compose с настройками сборки, запуска и взаимодействия между сервисами;\n",
    "- научились запускать оркестратор Docker Compose и просматривать логи каждого сервиса;\n",
    "- узнали, какие ещё существуют сервисы для оркестрации.\n",
    "\n",
    "Также рекомендуем вам заглянуть в **дополнительные источники**:\n",
    "\n",
    "- Ещё один пример оркестрации микросервисного приложения с двумя сервисами (клиентская и серверная части приложения) https://habr.com/ru/company/ruvds/blog/450312/.\n",
    "- Официальная документация по синтаксису compose-файла https://docs.docker.com/compose/compose-file/compose-file-v3/.\n",
    "- Официальная документация по командам docker-compose https://docs.docker.com/compose/reference/."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Итоги"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот и подошёл к концу заключительный модуль по выведению модели в Production — поздравляем!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе «Data Science в Production» вы:\n",
    "\n",
    "- научились:\n",
    "    - nправильно сохранять модели, используя библиотеки pika и joblib;\n",
    "    - реализовывать простейшие веб-сервисы с помощью фреймворка Flask;\n",
    "    - заворачивать сервисы и приложения в контейнеры, чтобы быстро их разворачивать и соблюдать требования воспроизводимости;\n",
    "- узнали, как создавать сервисы, какими они бывают и как их подбирать в зависимости от своих задач;\n",
    "- познакомились с различными инструментами, которые позволяют отслеживать логи и оркестрировать запуск контейнеров, а также помогают создать свой DS-пайплайн, начиная от сбора данных и заканчивая деплоем моделей."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конечно, в каждой компании все эти инструменты используются в различных комбинациях, а за каждый этап могут отвечать разные команды. Однако мы надеемся, что наш курс дал вам представление о жизненном цикле модели и теперь вы сможете увереннее управлять им в любой команде."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ДОПОЛНИТЕЛЬНО**\n",
    "\n",
    "Подробнее о масштабируемости (англ.):\n",
    "\n",
    "- Цикл ёмких и простых заметок “Scalability for Dummies” https://www.lecloud.net/tagged/scalability.  \n",
    "- Видео “Scaling up to your first 10 million users” https://www.youtube.com/watch?v=kKjm4ehYiMs (возможности, которые предоставляет AWS для масштабирования приложения от одного до десятков миллионов пользователей).\n",
    "- Примеры паттернов архитектуры для масштабирования системы (первый http://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html и второй https://lethain.com/introduction-to-architecting-systems-for-scale/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9.3**\n",
    "\n",
    "Вы хотите с помощью Docker Compose запустить приложение, состоящее из нескольких сервисов:\n",
    "\n",
    "\"model\" — делает инференс ML-модели;  \n",
    "\"worker\" — собирает данные для обучения ML-модели и переобучает её;  \n",
    "\"database\" — база данных, в которой хранятся данные.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполните пропущенные инструкции в конфигурационном файле docker-compose.yml:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version: '3.7'\n",
    "#   services:\n",
    "#     database:\n",
    "#       image: postgres:11-alpine\n",
    "#       container_name: database\n",
    "#       restart: always\n",
    "#       ports:  \n",
    "#         - 5432:5432\n",
    "#       volumes:\n",
    "#         - /home/user/app/database/:/opt/app/database/\n",
    "#       environment:\n",
    "#             - POSTGRES_PASSWORD=topsecret\n",
    "#             - POSTGRES_USER=tophacker\n",
    "#     model:\n",
    "#       build:\n",
    "#         context: ./model\n",
    "#         container_name: model\n",
    "#       ports:\n",
    "#         - 80:80\n",
    "#       restart: always\n",
    "#       volumes:\n",
    "#         - /home/user/app/model/:/opt/app/model/\n",
    "#       environment:    \n",
    "#         - MODEL_PARAMETER1=True\n",
    "#         - MODEL_PARAMETER2=100\n",
    "#       depends_on:\n",
    "#         - database\n",
    "#         - worker\n",
    "#     worker:\n",
    "#       build:\n",
    "#         context: ./worker\n",
    "#         container_name: worker\n",
    "#         restart: on_failure\n",
    "#         volumes:\n",
    "#           - /home/user/app/worker/:/opt/app/worker/\n",
    "#         depends_on:\n",
    "#           - database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
